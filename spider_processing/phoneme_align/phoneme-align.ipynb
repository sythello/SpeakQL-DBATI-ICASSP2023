{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "from pydub import AudioSegment\n",
    "from textgrid import TextGrid\n",
    "\n",
    "import epitran\n",
    "from phonemizer import phonemize\n",
    "from ipapy.arpabetmapper import ARPABETMapper\n",
    "from arpabetandipaconvertor.phoneticarphabet2arpabet import PhoneticAlphabet2ARPAbetConvertor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare parallel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_base_dir = '/path/to/spider/my'\n",
    "dev_audio_dir = os.path.join(in_base_dir, 'dev', 'speech_wav')\n",
    "dev_json = os.path.join(in_base_dir, 'dev', 'dev_rewriter(full).json')\n",
    "train_audio_dir = os.path.join(in_base_dir, 'train', 'speech_wav')\n",
    "train_json = os.path.join(in_base_dir, 'train', 'train_rewriter.json')\n",
    "\n",
    "align_data_dir = '/path/to/Prosodylab-Aligner/data/spider/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set = json.load(open(dev_json, 'r'))\n",
    "len(dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in tqdm(enumerate(dev_set), total=len(dev_set)):\n",
    "    for j, c in enumerate(s):\n",
    "        # sp[-1] == 0 --> sp is (0, 0), t is punct\n",
    "        _tokens = [t.upper() for t, sp in zip(c['question_toks'], c['span_ranges']) if sp[-1] != 0]\n",
    "        for k in range(len(_tokens)):\n",
    "            if _tokens[k][0].isnumeric():\n",
    "                _tokens[k] = '*' + _tokens[k] + '*'\n",
    "        \n",
    "        _align_txt_path = os.path.join(align_data_dir, f'dev-{i}.{j}.lab')\n",
    "        with open(_align_txt_path, 'w') as f:\n",
    "            f.write(' '.join(_tokens))\n",
    "        \n",
    "        _align_wav_path = os.path.join(align_data_dir, f'dev-{i}.{j}.wav')\n",
    "        _src_wav_path = os.path.join(dev_audio_dir, f'{i}.wav')\n",
    "        shutil.copyfile(_src_wav_path, _align_wav_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dev_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = json.load(open(train_json, 'r'))\n",
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in tqdm(enumerate(train_set), total=len(train_set)):\n",
    "    for j, c in enumerate(s):\n",
    "        # sp[-1] == 0 --> sp is (0, 0), t is punct\n",
    "        _tokens = [t.upper() for t, sp in zip(c['question_toks'], c['span_ranges']) if sp[-1] != 0]\n",
    "        for k in range(len(_tokens)):\n",
    "            if _tokens[k][0].isnumeric():\n",
    "                _tokens[k] = '*' + _tokens[k] + '*'\n",
    "        \n",
    "        _align_txt_path = os.path.join(align_data_dir, f'train-{i}.{j}.lab')\n",
    "        with open(_align_txt_path, 'w') as f:\n",
    "            f.write(' '.join(_tokens))\n",
    "        \n",
    "        _align_wav_path = os.path.join(align_data_dir, f'train-{i}.{j}.wav')\n",
    "        _src_wav_path = os.path.join(train_audio_dir, f'{i}.wav')\n",
    "        shutil.copyfile(_src_wav_path, _align_wav_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### token-level parallel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_base_dir = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my'\n",
    "dev_audio_dir = os.path.join(in_base_dir, 'dev', 'speech_wav')\n",
    "dev_json = os.path.join(in_base_dir, 'dev', 'dev_rewriter(full).json')\n",
    "train_audio_dir = os.path.join(in_base_dir, 'train', 'speech_wav')\n",
    "train_json = os.path.join(in_base_dir, 'train', 'train_rewriter.json')\n",
    "\n",
    "align_data_dir = '/Users/mac/Desktop/syt/Deep-Learning/Repos/Prosodylab-Aligner/data/spider-tokens/'\n",
    "os.makedirs(align_data_dir, exist_ok=True)\n",
    "\n",
    "proso_dict_path = '/Users/mac/Desktop/syt/Deep-Learning/Repos/Prosodylab-Aligner/eng.dict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proso_word_set = set()\n",
    "with open(proso_dict_path, 'r') as f:\n",
    "    for l in f:\n",
    "        w, prons = l.split(' ', 1)\n",
    "        proso_word_set.add(w)\n",
    "\n",
    "# len(cmu_word_set)\n",
    "len(proso_word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set = json.load(open(dev_json, 'r'))\n",
    "len(dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in tqdm(enumerate(dev_set), total=len(dev_set)):\n",
    "    _src_wav_path = os.path.join(dev_audio_dir, f'{i}.wav')\n",
    "    _speech = AudioSegment.from_wav(_src_wav_path)\n",
    "    \n",
    "    os.makedirs(os.path.join(align_data_dir, f'dev-{i}'), exist_ok=True)\n",
    "    for j, c in enumerate(s):\n",
    "        # sp[-1] == 0 --> sp is (0, 0), t is punct\n",
    "        _token_spans = [(t.upper(), sp) for t, sp in zip(c['question_toks'], c['span_ranges']) if sp[-1] != 0]\n",
    "        \n",
    "        for k, (_t, _sp) in enumerate(_token_spans):\n",
    "            if _t not in proso_word_set:\n",
    "                continue\n",
    "            \n",
    "            _st = int(float(_sp[0]) * 1000)\n",
    "            _ed = int(float(_sp[1]) * 1000)\n",
    "            _speech_token = _speech[_st:_ed]\n",
    "            \n",
    "            _align_txt_path = os.path.join(align_data_dir, f'dev-{i}/{j}.{k}.lab')\n",
    "            with open(_align_txt_path, 'w') as f:\n",
    "                f.write(_t)\n",
    "\n",
    "            _align_wav_path = os.path.join(align_data_dir, f'dev-{i}/{j}.{k}.wav')\n",
    "            _speech_token.export(_align_wav_path, format='wav')\n",
    "        \n",
    "#         _align_txt_path = os.path.join(align_data_dir, f'dev-{i}.{j}.lab')\n",
    "#         with open(_align_txt_path, 'w') as f:\n",
    "#             f.write(' '.join(_tokens))\n",
    "        \n",
    "#         _align_wav_path = os.path.join(align_data_dir, f'dev-{i}.{j}.wav')\n",
    "#         _src_wav_path = os.path.join(dev_audio_dir, f'{i}.wav')\n",
    "#         shutil.copyfile(_src_wav_path, _align_wav_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = json.load(open(train_json, 'r'))\n",
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in tqdm(enumerate(train_set), total=len(train_set)):\n",
    "    _src_wav_path = os.path.join(train_audio_dir, f'{i}.wav')\n",
    "    _speech = AudioSegment.from_wav(_src_wav_path)\n",
    "    \n",
    "    os.makedirs(os.path.join(align_data_dir, f'train-{i}'), exist_ok=True)\n",
    "    for j, c in enumerate(s):\n",
    "        # sp[-1] == 0 --> sp is (0, 0), t is punct\n",
    "        _token_spans = [(t.upper(), sp) for t, sp in zip(c['question_toks'], c['span_ranges']) if sp[-1] != 0]\n",
    "\n",
    "        for k, (_t, _sp) in enumerate(_token_spans):\n",
    "            if _t not in proso_word_set:\n",
    "                continue\n",
    "            \n",
    "            _st = int(float(_sp[0]) * 1000)\n",
    "            _ed = int(float(_sp[1]) * 1000)\n",
    "            _speech_token = _speech[_st:_ed]\n",
    "            \n",
    "            _align_txt_path = os.path.join(align_data_dir, f'train-{i}/{j}.{k}.lab')\n",
    "            with open(_align_txt_path, 'w') as f:\n",
    "                f.write(_t)\n",
    "\n",
    "            _align_wav_path = os.path.join(align_data_dir, f'train-{i}/{j}.{k}.wav')\n",
    "            _speech_token.export(_align_wav_path, format='wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_audio_dir = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/db/speech_wav'\n",
    "db_vocab_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/db/schema_vocab.txt'\n",
    "\n",
    "align_data_dir = '/Users/mac/Desktop/syt/Deep-Learning/Repos/Prosodylab-Aligner/data/spider-db-tokens/'\n",
    "os.makedirs(align_data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proso_dict_path = '/Users/mac/Desktop/syt/Deep-Learning/Repos/Prosodylab-Aligner/eng.dict'\n",
    "\n",
    "proso_word_set = set()\n",
    "with open(proso_dict_path, 'r') as f:\n",
    "    for l in f:\n",
    "        w, prons = l.split(' ', 1)\n",
    "        proso_word_set.add(w)\n",
    "\n",
    "# len(cmu_word_set)\n",
    "len(proso_word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(db_vocab_path, 'r') as f:\n",
    "    db_vocab = f.read().split('\\n')\n",
    "len(db_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in db_vocab:\n",
    "    if w.upper() not in proso_word_set:\n",
    "        continue\n",
    "        \n",
    "    _align_txt_path = os.path.join(align_data_dir, f'{w}.lab')\n",
    "    with open(_align_txt_path, 'w') as f:\n",
    "        f.write(w.upper())\n",
    "\n",
    "    _align_wav_path = os.path.join(align_data_dir, f'{w}.wav')\n",
    "    _src_wav_path = os.path.join(db_audio_dir, f'{w}.wav')\n",
    "    shutil.copyfile(_src_wav_path, _align_wav_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add phoneme alignments to data file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_base_dir = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my'\n",
    "dev_audio_dir = os.path.join(in_base_dir, 'dev', 'speech_wav')\n",
    "dev_json = os.path.join(in_base_dir, 'dev', 'dev_rewriter(full).json')\n",
    "dev_out_json = os.path.join(in_base_dir, 'dev', 'dev_rewriter(full)+phonemes.json')\n",
    "train_audio_dir = os.path.join(in_base_dir, 'train', 'speech_wav')\n",
    "train_json = os.path.join(in_base_dir, 'train', 'train_rewriter.json')\n",
    "train_out_json = os.path.join(in_base_dir, 'train', 'train_rewriter+phonemes.json')\n",
    "\n",
    "proso_base_dir = '/Users/mac/Desktop/syt/Deep-Learning/Repos/Prosodylab-Aligner/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = TextGrid.fromFile(os.path.join(proso_base_dir, 'data/spider-tokens/dev-0/0.0.TextGrid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tg[0])\n",
    "print(tg[0][0])\n",
    "print(tg[0][0].minTime)\n",
    "print(tg[0][0].maxTime)\n",
    "print(tg[0][0].mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set = json.load(open(dev_json, 'r'))\n",
    "len(dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in tqdm(enumerate(dev_set), total=len(dev_set)):\n",
    "    for j, c in enumerate(s):\n",
    "        ## c: cand \n",
    "        token_phonemes = []\n",
    "        token_phoneme_spans = []\n",
    "        \n",
    "        for k, t in enumerate(c['question_toks']):\n",
    "            phonemes_align_path = os.path.join(proso_base_dir, f'data/spider-tokens/dev-{i}/{j}.{k}.TextGrid')\n",
    "            try:\n",
    "                phonemes_tg = TextGrid.fromFile(phonemes_align_path) # tg[0] is phonemes, [1] is words \n",
    "            except FileNotFoundError:\n",
    "                ## skipped token \n",
    "                token_phonemes.append(None)\n",
    "                token_phoneme_spans.append(None)\n",
    "                continue\n",
    "            \n",
    "            _phs = [_intv.mark for _intv in phonemes_tg[0]]\n",
    "            _ph_spans = [(_intv.minTime, _intv.maxTime) for _intv in phonemes_tg[0]]\n",
    "            token_phonemes.append(_phs)\n",
    "            token_phoneme_spans.append(_ph_spans)\n",
    "        \n",
    "        c['token_phonemes'] = token_phonemes\n",
    "        c['token_phoneme_spans'] = token_phoneme_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dev_out_json, 'w') as f:\n",
    "    json.dump(dev_set, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = json.load(open(train_json, 'r'))\n",
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in tqdm(enumerate(train_set), total=len(train_set)):\n",
    "    for j, c in enumerate(s):\n",
    "        ## c: cand \n",
    "        token_phonemes = []\n",
    "        token_phoneme_spans = []\n",
    "        \n",
    "        for k, t in enumerate(c['question_toks']):\n",
    "            phonemes_align_path = os.path.join(proso_base_dir, f'data/spider-tokens/train-{i}/{j}.{k}.TextGrid')\n",
    "            try:\n",
    "                phonemes_tg = TextGrid.fromFile(phonemes_align_path) # tg[0] is phonemes, [1] is words \n",
    "            except FileNotFoundError:\n",
    "                ## skipped token \n",
    "                token_phonemes.append(None)\n",
    "                token_phoneme_spans.append(None)\n",
    "                continue\n",
    "            \n",
    "            _phs = [_intv.mark for _intv in phonemes_tg[0]]\n",
    "            _ph_spans = [(_intv.minTime, _intv.maxTime) for _intv in phonemes_tg[0]]\n",
    "            token_phonemes.append(_phs)\n",
    "            token_phoneme_spans.append(_ph_spans)\n",
    "        \n",
    "        c['token_phonemes'] = token_phonemes\n",
    "        c['token_phoneme_spans'] = token_phoneme_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_out_json, 'w') as f:\n",
    "    json.dump(train_set, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_base_dir = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/db/'\n",
    "db_audio_dir = os.path.join(db_base_dir, 'speech_wav')\n",
    "db_out_json = os.path.join(db_base_dir, 'schema_phonemes.json')\n",
    "\n",
    "proso_base_dir = '/Users/mac/Desktop/syt/Deep-Learning/Repos/Prosodylab-Aligner/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_ph_dict = dict()\n",
    "\n",
    "for w in db_vocab:\n",
    "    phonemes_align_path = os.path.join(proso_base_dir, f'data/spider-db-tokens/{w}.TextGrid')\n",
    "    try:\n",
    "        phonemes_tg = TextGrid.fromFile(phonemes_align_path) # tg[0] is phonemes, [1] is words \n",
    "    except FileNotFoundError:\n",
    "        ## skipped token \n",
    "        continue\n",
    "\n",
    "    _phs = [_intv.mark for _intv in phonemes_tg[0]]\n",
    "    _ph_spans = [(_intv.minTime, _intv.maxTime) for _intv in phonemes_tg[0]]\n",
    "    db_ph_dict[w] = {\n",
    "        'phonemes': _phs,\n",
    "        'phoneme_spans': _ph_spans,\n",
    "    }\n",
    "\n",
    "len(db_ph_dict), db_ph_dict['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(db_out_json, 'w') as f:\n",
    "    json.dump(db_ph_dict, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp: token-to-phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi = epitran.Epitran('eng-Latn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_converter = PhoneticAlphabet2ARPAbetConvertor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'swimming'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipa_phonemes = epi.transliterate(word)\n",
    "# ipa_phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipa_phonemes = phonemize(\n",
    "    word,\n",
    "    language='en-us',\n",
    "#     backend='festival',\n",
    "#     separator=Separator(phone=None, word='', syllable=''),\n",
    "    strip=True,\n",
    "#     with_stress=True,\n",
    "    preserve_punctuation=True,\n",
    "#     njobs=4\n",
    ").replace('ː',':')\n",
    "ipa_phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amapper = ARPABETMapper()\n",
    "# s_a = amapper.map_unicode_string(ipa_phonemes, ignore=True, return_as_list=True)\n",
    "# s_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_converter.convert(ipa_phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
