{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10dd0e730>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Iterator, List, Dict, Optional\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn import MSELoss\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import ModuleList\n",
    "\n",
    "import numpy as np\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.fields import TextField, SequenceLabelField, ArrayField, MetadataField, ListField\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding, TokenEmbedder\n",
    "from allennlp.modules.token_embedders.pretrained_transformer_embedder import PretrainedTransformerEmbedder\n",
    "from allennlp.modules.token_embedders.pretrained_transformer_mismatched_embedder import PretrainedTransformerMismatchedEmbedder\n",
    "# from allennlp.modules.seq2seq_encoders.multi_head_self_attention import MultiHeadSelfAttention\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n",
    "from allennlp.modules.seq2vec_encoders.cnn_encoder import CnnEncoder\n",
    "from allennlp.modules.attention import Attention\n",
    "from allennlp.modules.matrix_attention.matrix_attention import MatrixAttention\n",
    "from allennlp.modules.matrix_attention.linear_matrix_attention import LinearMatrixAttention\n",
    "from allennlp.modules.matrix_attention.cosine_matrix_attention import CosineMatrixAttention\n",
    "\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits, \\\n",
    "    get_device_of, masked_softmax, weighted_sum, \\\n",
    "    get_mask_from_sequence_lengths, get_lengths_from_binary_sequence_mask, tensors_equal\n",
    "\n",
    "from allennlp.training.metrics import CategoricalAccuracy, MeanAbsoluteError\n",
    "from allennlp.data.samplers import BucketBatchSampler\n",
    "from allennlp.data.dataloader import DataLoader\n",
    "from allennlp.training.trainer import GradientDescentTrainer\n",
    "# from allennlp.predictors import Predictor, Seq2SeqPredictor, SimpleSeq2SeqPredictor, SentenceTaggerPredictor\n",
    "from allennlp.predictors import Predictor, SentenceTaggerPredictor\n",
    "from allennlp.nn.activations import Activation\n",
    "from allennlp.common.tqdm import Tqdm\n",
    "from allennlp.common.params import Params\n",
    "from allennlp.common.util import JsonDict, sanitize\n",
    "\n",
    "from allennlp_models.generation.predictors import Seq2SeqPredictor\n",
    "from allennlp_models.generation.models.simple_seq2seq import SimpleSeq2Seq\n",
    "\n",
    "# from spacy.tokenizer import Tokenizer as SpacyTokenizer\n",
    "# from spacy.lang.en import English\n",
    "# nlp = English()\n",
    "# Create a blank Tokenizer with just the English vocab\n",
    "# tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pyAudioAnalysis import audioBasicIO\n",
    "from pyAudioAnalysis import ShortTermFeatures\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from inspect import signature\n",
    "import warnings\n",
    "import pickle\n",
    "import importlib\n",
    "from copy import deepcopy\n",
    "\n",
    "from transformers import BertPreTrainedModel, BertModel, BertConfig, BertTokenizer\n",
    "\n",
    "from utils.spider import process_sql, evaluation\n",
    "from utils.schema_gnn.spider_utils import Table, TableColumn, read_dataset_schema\n",
    "from utils.misc_utils import EvaluateSQL\n",
    "\n",
    "from dataset_readers.reranker_reader import extractAudioFeatures, extractAudioFeatures_NoPooling, dbToTokens, \\\n",
    "    SpiderASRRerankerReaderV2_Siamese\n",
    "from dataset_readers.reranker_reader_legacy import SpiderASRRerankerReaderV1, SpiderASRRerankerReaderV2\n",
    "from modules.encoder import SpeakQLEncoderV1\n",
    "from models.reranker import SpiderASRRerankerV2, SpiderASRReranker_Siamese\n",
    "from models.reranker_legacy import SpiderASRRerankerV0, SpiderASRRerankerV1\n",
    "from predictors.reranker_predictor import SpiderASRRerankerPredictor, SpiderASRRerankerPredictor_Siamese\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For future, first implement things here, but when finished move to python files and import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIM = 136\n",
    "AUDIO_DIM_NO_POOLING = 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_json_fname = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/tables.json'\n",
    "dataset_reranker_dir = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my'\n",
    "token_indexers = {'bert': TokenIndexer.by_name('pretrained_transformer_mismatched')('bert-base-uncased')}\n",
    "\n",
    "dataset_reader = SpiderASRRerankerReaderV2_Siamese(tables_json_fname=tables_json_fname,\n",
    "                                         dataset_reranker_dir=dataset_reranker_dir,\n",
    "                                         token_indexers=token_indexers,\n",
    "                                         debug=True)\n",
    "\n",
    "train_dataset = dataset_reader.read('train')\n",
    "\n",
    "dev_dataset = dataset_reader.read('dev')\n",
    "# test_dataset = dataset_reader.read('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0].fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset[0].fields['sentence_1']), \\\n",
    "train_dataset[0].fields['text_mask_1'].array.shape, \\\n",
    "train_dataset[0].fields['text_mask_1'].array.sum(), \\\n",
    "train_dataset[0].fields['schema_mask_1'].array.shape, \\\n",
    "train_dataset[0].fields['schema_mask_1'].array.sum(), \\\n",
    "train_dataset[0].fields['audio_mask_1'].array.shape, \\\n",
    "train_dataset[0].fields['audio_mask_1'].array.sum(axis=-1), \\\n",
    "train_dataset[0].fields['metadata_1'].metadata, \\\n",
    "len(train_dataset[0].fields['audio_feats_1'].field_list), \\\n",
    "train_dataset[0].fields['audio_feats_1'].field_list[0].array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset[0].fields['sentence_2']), \\\n",
    "train_dataset[0].fields['text_mask_2'].array.shape, \\\n",
    "train_dataset[0].fields['text_mask_2'].array.sum(), \\\n",
    "train_dataset[0].fields['schema_mask_2'].array.shape, \\\n",
    "train_dataset[0].fields['schema_mask_2'].array.sum(), \\\n",
    "train_dataset[0].fields['audio_mask_2'].array.shape, \\\n",
    "train_dataset[0].fields['audio_mask_2'].array.sum(axis=-1), \\\n",
    "train_dataset[0].fields['metadata_2'].metadata, \\\n",
    "len(train_dataset[0].fields['audio_feats_2'].field_list), \\\n",
    "train_dataset[0].fields['audio_feats_2'].field_list[0].array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audio_shapes = [train_dataset[0].fields['audio_feats_1'].field_list[i].array.shape for i in range(len(train_dataset[0].fields['audio_feats_1'].field_list))]\n",
    "tokens = list(train_dataset[0].fields['sentence_1'])\n",
    "list(zip(audio_shapes, tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embedder = BasicTextFieldEmbedder(\n",
    "#         embedder_to_indexer_map={\n",
    "#             \"bert\": [\"bert\", \"bert-offsets\"],\n",
    "#         },\n",
    "        token_embedders={\n",
    "            \"bert\": TokenEmbedder.by_name(\"pretrained_transformer_mismatched\")(\"bert-base-uncased\")\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embedder.token_embedder_bert.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_bert_indexer = token_indexers['bert']\n",
    "_bert_indexer\n",
    "# vocab = Vocabulary({'token_bert': vocab_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary.from_instances(train_dataset + dev_dataset)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 768\n",
    "AUDIO_DIM_NO_POOLING = 68\n",
    "AUDIO_ENC_DIM = 128\n",
    "LSTM_DIM = 32\n",
    "SA_HEADS = 3\n",
    "SA_DIM = 3 * 32\n",
    "\n",
    "margin = 0.25\n",
    "\n",
    "# sa_layer = MultiHeadSelfAttention(num_heads = SA_HEADS,\n",
    "#                                   input_dim = EMBEDDING_DIM + AUDIO_DIM,\n",
    "#                                   attention_dim = SA_DIM,\n",
    "#                                   values_dim = SA_DIM,\n",
    "#                                   output_projection_dim = SA_DIM,\n",
    "#                                   attention_dropout_prob = 0.0)\n",
    "\n",
    "audio_s2v = CnnEncoder(embedding_dim = AUDIO_DIM_NO_POOLING,\n",
    "                       num_filters = 4,\n",
    "                       ngram_filter_sizes = (2, 3, 4, 5),\n",
    "                       output_dim = AUDIO_ENC_DIM)\n",
    "\n",
    "lstm_s2v = PytorchSeq2VecWrapper(torch.nn.LSTM(EMBEDDING_DIM + AUDIO_ENC_DIM, LSTM_DIM, batch_first=True))\n",
    "\n",
    "model = SpiderASRRerankerV2(word_embeddings=bert_embedder,\n",
    "                          bert_pretrained_model='bert-base-uncased',\n",
    "                          audio_seq2vec_encoder=audio_s2v,\n",
    "                          audio_attention_layer=CosineMatrixAttention(),\n",
    "                          audio_attention_residual='+',\n",
    "                          seq2seq_encoders=None,\n",
    "                          seq2vec_encoder=lstm_s2v,\n",
    "                          ff_dimension=8,\n",
    "                          concat_audio=True,\n",
    "                          vocab=vocab)\n",
    "\n",
    "siamese_model = SpiderASRReranker_Siamese(model,\n",
    "                                          margin=margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence_1': <allennlp.data.fields.text_field.TextField at 0x183998a00>,\n",
       " 'text_mask_1': <allennlp.data.fields.array_field.ArrayField at 0x183998690>,\n",
       " 'schema_mask_1': <allennlp.data.fields.array_field.ArrayField at 0x183998640>,\n",
       " 'audio_feats_1': <allennlp.data.fields.list_field.ListField at 0x13f5cfe10>,\n",
       " 'audio_mask_1': <allennlp.data.fields.array_field.ArrayField at 0x183998050>,\n",
       " 'metadata_1': <allennlp.data.fields.metadata_field.MetadataField at 0x140d85450>,\n",
       " 'sentence_2': <allennlp.data.fields.text_field.TextField at 0x18399a0f0>,\n",
       " 'text_mask_2': <allennlp.data.fields.array_field.ArrayField at 0x18399a1e0>,\n",
       " 'schema_mask_2': <allennlp.data.fields.array_field.ArrayField at 0x18399ae10>,\n",
       " 'audio_feats_2': <allennlp.data.fields.list_field.ListField at 0x1406866d0>,\n",
       " 'audio_mask_2': <allennlp.data.fields.array_field.ArrayField at 0x18399ae60>,\n",
       " 'metadata_2': <allennlp.data.fields.metadata_field.MetadataField at 0x13ddd12d0>}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tokens', '_token_indexers', '_indexed_tokens']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['sentence_1'].__slots__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f649f1fbb04ab5a71452438229e0c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e778c1b13b41d88fc2482aa01398f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 0,\n",
       " 'peak_worker_0_memory_MB': 1681.453056,\n",
       " 'training_duration': '0:01:19.082855',\n",
       " 'training_start_epoch': 0,\n",
       " 'training_epochs': 0,\n",
       " 'epoch': 0,\n",
       " 'training_loss': 0.24971853467551144,\n",
       " 'training_reg_loss': 0.0,\n",
       " 'training_worker_0_memory_MB': 1681.453056,\n",
       " 'validation_loss': 0.2497857684890429,\n",
       " 'validation_reg_loss': 0.0,\n",
       " 'best_validation_loss': 0.2497857684890429,\n",
       " 'best_validation_reg_loss': 0.0}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "# iterator = BucketIterator(batch_size=8, sorting_keys=[(\"sentence_1\", \"num_tokens\")])\n",
    "# iterator.index_with(vocab)\n",
    "\n",
    "# train_dataset_indexed = train_dataset.index_with(vocab)\n",
    "# dev_dataset_indexed = dev_dataset.index_with(vocab)\n",
    "\n",
    "train_dataset.index_with(vocab)\n",
    "dev_dataset.index_with(vocab)\n",
    "\n",
    "# train_sampler = BucketBatchSampler(train_dataset_indexed, batch_size=8, sorting_keys=[(\"sentence_1\", \"num_tokens\")])\n",
    "# dev_sampler = BucketBatchSampler(dev_dataset_indexed, batch_size=8, sorting_keys=[(\"sentence_1\", \"num_tokens\")])\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "dev_data_loader = DataLoader(dev_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "trainer = GradientDescentTrainer(model=siamese_model,\n",
    "                  optimizer=optimizer,\n",
    "                  data_loader=train_data_loader,\n",
    "                  validation_data_loader=dev_data_loader,\n",
    "                  patience=10,\n",
    "                  num_epochs=1,\n",
    "                  cuda_device=-1)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vars(train_dataset[0]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(train_dataset[0]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "_iter = iterator._create_batches(dev_dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_batch = next(_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "_batch_tensor_dict = _batch.as_tensor_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sentence', 'text_mask', 'schema_mask', 'audio_feats', 'audio_mask', 'metadata', 'score'])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_batch_tensor_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([15, 14, 15, 15, 11, 12,  7, 15]),\n",
       " tensor([63, 63, 63, 63, 63, 63, 63, 63]))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lengths_from_binary_sequence_mask(_batch_tensor_dict['text_mask']), \\\n",
    "get_lengths_from_binary_sequence_mask(_batch_tensor_dict['schema_mask'])\n",
    "# Why 63 ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 79])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_batch_tensor_dict['schema_mask'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 79])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_field_mask(_batch_tensor_dict['sentence']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 79, 68])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_batch_tensor_dict['audio_mask'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_instance_fields_and_types = [{k: v.__class__.__name__ for k, v in x.fields.items()} for x in train_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_instance_fields_and_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpiderASRRerankerPredictor(Predictor):\n",
    "    def predict_instance(self, instance: Instance) -> JsonDict:\n",
    "        outputs = self._model.forward_on_instance(instance)\n",
    "        outputs['question'] = ' '.join([str(tok) for tok in instance.fields['sentence']]).split(' [SEP] ')[0]\n",
    "        outputs['original_id'] = instance.fields['metadata']['original_id']\n",
    "        return sanitize(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpiderASRRerankerPredictor_Siamese(Predictor):\n",
    "    def predict_instance(self, instance: Instance) -> JsonDict:\n",
    "        outputs = self._model.regression_model.forward_on_instance(instance)\n",
    "        outputs['question'] = ' '.join([str(tok) for tok in instance.fields['sentence']]).split(' [SEP] ')[0]\n",
    "        outputs['original_id'] = instance.fields['metadata']['original_id']\n",
    "        return sanitize(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2e52fa71e3401ab7adec740267c8f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_reader_test = SpiderASRRerankerReaderV2(tables_json_fname=tables_json_fname,\n",
    "                                         dataset_reranker_dir=dataset_reranker_dir,\n",
    "                                         token_indexers=token_indexers,\n",
    "                                         debug=True)\n",
    "test_dataset = dataset_reader_test.read('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = SpiderASRRerankerPredictor_Siamese(siamese_model, dataset_reader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score_preds': 0.43298661708831787,\n",
       " 'loss': 0.3215041756629944,\n",
       " 'question': 'find the number of pets whose weight is heavier than 10 .',\n",
       " 'original_id': 45}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict_instance(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(_batch.instances[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _inst in _batch.instances:\n",
    "    print(_inst.fields['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate (moved to ratsql-infer.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 712, 712, 100)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Evaluate for comparing groups (FIRST, ORACLE, RANDOM)\n",
    "\n",
    "# gold_scores_list = [] # List[List]: gold scores for each ASR candidate \n",
    "\n",
    "hyp_first_list = []\n",
    "hyp_oracle_list = [] # Oracle for rat-sql score, not bleu \n",
    "hyp_all_list = []\n",
    "ref_list = []\n",
    "ref_all_list = []\n",
    "\n",
    "eval_ids = []\n",
    "\n",
    "first_corr = 0\n",
    "expect_corr = 0\n",
    "\n",
    "first_score_sum = 0\n",
    "expect_score_sum = 0\n",
    "oracle_score_sum = 0\n",
    "\n",
    "first_exact_sum = 0\n",
    "expect_exact_sum = 0\n",
    "oracle_exact_sum = 0\n",
    "\n",
    "for i, curr_golds in enumerate(golds):\n",
    "\n",
    "    if len(curr_golds) == 0:\n",
    "        # skipped \n",
    "        continue\n",
    "        \n",
    "    o_id = curr_golds[0]['original_id']\n",
    "    eval_ids.append(o_id)\n",
    "    \n",
    "    # eval \n",
    "    g = [_g['ratsql_pred_score'] for _g in curr_golds]\n",
    "    g_ex = [_g['ratsql_pred_exact'] for _g in curr_golds]\n",
    "    \n",
    "    gold_max = np.max(g)\n",
    "    if np.isclose(g[0], gold_max):\n",
    "        first_corr += 1\n",
    "    expect_corr += (sum([np.isclose(s, gold_max) for s in g]) / len(g))\n",
    "    \n",
    "    first_score_sum += g[0]\n",
    "    expect_score_sum += np.mean(g)\n",
    "    oracle_score_sum += np.max(g)\n",
    "    \n",
    "    first_exact_sum += g_ex[0]\n",
    "    expect_exact_sum += np.mean(g_ex)\n",
    "    oracle_exact_sum += np.max(g_ex)\n",
    "\n",
    "    # keep track of selected & ref (original) sentences \n",
    "    oracle_c_id = np.argmax(g)\n",
    "\n",
    "    curr_hyps = [[w.lower() for w in curr_golds[i]['question_toks']] for i in range(len(curr_golds))]\n",
    "    ref = [w.lower() for w in curr_golds[0]['gold_question_toks']]\n",
    "    \n",
    "    hyp_first_list.append(curr_hyps[0])\n",
    "    hyp_oracle_list.append(curr_hyps[oracle_c_id])\n",
    "    ref_list.append([ref])\n",
    "    hyp_all_list.extend(curr_hyps)\n",
    "    ref_all_list.extend([[ref] for _ in range(len(curr_golds))])\n",
    "\n",
    "len(hyp_first_list), len(hyp_oracle_list), len(ref_list), len(hyp_all_list), len(ref_all_list), len(eval_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_first = corpus_bleu(list_of_references=ref_list, hypotheses=hyp_first_list)\n",
    "bleu_oracle = corpus_bleu(list_of_references=ref_list, hypotheses=hyp_oracle_list)\n",
    "bleu_all = corpus_bleu(list_of_references=ref_all_list, hypotheses=hyp_all_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Selection @1 accuracy]\n",
      "First: 70/100 = 0.7000\n",
      "Expectation(random): 69.3730/100 = 0.6937\n",
      "\n",
      "[Selection ratsql prediction score]\n",
      "First: 67.7936/100 = 0.6779\n",
      "Expectation(random): 67.3080/100 = 0.6731\n",
      "Oracle: 79.7952/100 = 0.7980\n",
      "\n",
      "[Selection ratsql prediction exact]\n",
      "First: 35.0000/100 = 0.3500\n",
      "Expectation(random): 35.0992/100 = 0.3510\n",
      "Oracle: 49.0000/100 = 0.4900\n",
      "\n",
      "[BLEU score]\n",
      "First: 0.6934\n",
      "Oracle: 0.7070\n",
      "All: 0.5973\n"
     ]
    }
   ],
   "source": [
    "print('[Selection @1 accuracy]')\n",
    "print('First: {}/{} = {:.4f}'.format(first_corr, len(eval_ids), first_corr / len(eval_ids)))\n",
    "print('Expectation(random): {:.4f}/{} = {:.4f}'.format(expect_corr, len(eval_ids), expect_corr / len(eval_ids)))\n",
    "print()\n",
    "print('[Selection ratsql prediction score]')\n",
    "print('First: {:.4f}/{} = {:.4f}'.format(first_score_sum, len(eval_ids), first_score_sum / len(eval_ids)))\n",
    "print('Expectation(random): {:.4f}/{} = {:.4f}'.format(expect_score_sum, len(eval_ids), expect_score_sum / len(eval_ids)))\n",
    "print('Oracle: {:.4f}/{} = {:.4f}'.format(gold_score_sum, len(eval_ids), gold_score_sum / len(eval_ids)))\n",
    "print()\n",
    "print('[Selection ratsql prediction exact]')\n",
    "print('First: {:.4f}/{} = {:.4f}'.format(first_exact_sum, len(eval_ids), first_exact_sum / len(eval_ids)))\n",
    "print('Expectation(random): {:.4f}/{} = {:.4f}'.format(expect_exact_sum, len(eval_ids), expect_exact_sum / len(eval_ids)))\n",
    "print('Oracle: {:.4f}/{} = {:.4f}'.format(gold_exact_sum, len(eval_ids), gold_exact_sum / len(eval_ids)))\n",
    "print()\n",
    "print('[BLEU score]')\n",
    "print(f'First: {bleu_first:.4f}')\n",
    "print(f'Oracle: {bleu_oracle:.4f}')\n",
    "print(f'All: {bleu_all:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dev_fname = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/dev.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(original_dev_fname, 'r') as f:\n",
    "    original_dev = json.load(f)\n",
    "len(original_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(911,\n",
       "  'What are the names of high schoolers who have a grade of over 5 and have 2 or more friends?')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, d['question']) for i, d in enumerate(original_dev) if '2 or more friends' in d['question']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3030,\n",
       "  0.003166439477354288,\n",
       "  'What are the names of high schoolers who have a great of over five and have two or more friends ?'),\n",
       " (3031,\n",
       "  1.1134460464745644e-08,\n",
       "  \"What are the names of high schoolers who have a great of over five and have to ? We're more friends .\"),\n",
       " (3032,\n",
       "  0.00015574961435049772,\n",
       "  'What are the names of high schoolers who have a great of over five and have two were more friends ?'),\n",
       " (3033,\n",
       "  3.5951459722127765e-05,\n",
       "  'what are the names of high schoolers who have a great of over five and have to wear more friends ?'),\n",
       " (3034,\n",
       "  1.1044487280287285e-07,\n",
       "  \"What are the names of high schoolers who have a great of over five and have two ? We're more friends .\"),\n",
       " (3035,\n",
       "  0.00010368470248067752,\n",
       "  'What are the names of high schoolers who have a great of over five and have to worm or friends ?'),\n",
       " (3036,\n",
       "  1.2194815326438402e-06,\n",
       "  'what are the names of high schoolers who have a great of over five and have to were more friends ?'),\n",
       " (3037,\n",
       "  0.0002859074738807976,\n",
       "  'What are the names of high schoolers who have a great of over five and have to , or more friends ?'),\n",
       " (3038,\n",
       "  3.766036024899222e-05,\n",
       "  'What are the names of high schoolers who have a great of over five and have to arm or friends ?'),\n",
       " (3039,\n",
       "  0.007398915942758322,\n",
       "  'What are the names of high schoolers who have a great of over five and have , too , were more friends ?')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, p['score_preds'], p['question']) for i, p in enumerate(predicts) if p['original_id'] == 911]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2355, 0.49413105845451355, 'What are the names of high schoolers who have a great of over five and have two or more friends ?')\n",
      "(2356, 0.4690669775009155, \"What are the names of high schoolers who have a great of over five and have to ? We're more friends .\")\n",
      "(2357, 0.47279447317123413, 'What are the names of high schoolers who have a great of over five and have two were more friends ?')\n",
      "(2358, 0.4957186281681061, 'what are the names of high schoolers who have a great of over five and have to wear more friends ?')\n",
      "(2359, 0.4678690731525421, \"What are the names of high schoolers who have a great of over five and have two ? We're more friends .\")\n",
      "(2360, 0.46797066926956177, 'What are the names of high schoolers who have a great of over five and have to worm or friends ?')\n",
      "(2361, 0.4689886271953583, 'what are the names of high schoolers who have a great of over five and have to were more friends ?')\n",
      "(2362, 0.4720613658428192, 'What are the names of high schoolers who have a great of over five and have to , or more friends ?')\n",
      "(2363, 0.43726152181625366, 'What are the names of high schoolers who have a great of over five and have to arm or friends ?')\n",
      "(2364, 0.42050808668136597, 'What are the names of high schoolers who have a great of over five and have , too , were more friends ?')\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join([str((i, p['score_preds'], p['question'])) for i, p in enumerate(predicts) if p['original_id'] == 911]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{45,\n",
       " 46,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 56,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 62,\n",
       " 64,\n",
       " 67,\n",
       " 68,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 82,\n",
       " 84,\n",
       " 85,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 188,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 214,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 231,\n",
       " 235,\n",
       " 237,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 257,\n",
       " 258,\n",
       " 299,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 327,\n",
       " 328,\n",
       " 333,\n",
       " 335,\n",
       " 338,\n",
       " 339,\n",
       " 345,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 375,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 391,\n",
       " 392,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 405,\n",
       " 406,\n",
       " 410,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 420,\n",
       " 421,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 428,\n",
       " 429,\n",
       " 430,\n",
       " 431,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 442,\n",
       " 444,\n",
       " 445,\n",
       " 447,\n",
       " 448,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 482,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 490,\n",
       " 687,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 699,\n",
       " 701,\n",
       " 702,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 714,\n",
       " 716,\n",
       " 717,\n",
       " 720,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 725,\n",
       " 726,\n",
       " 728,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 734,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 741,\n",
       " 743,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 751,\n",
       " 752,\n",
       " 753,\n",
       " 754,\n",
       " 756,\n",
       " 757,\n",
       " 758,\n",
       " 759,\n",
       " 760,\n",
       " 763,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 772,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 779,\n",
       " 780,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 784,\n",
       " 785,\n",
       " 786,\n",
       " 788,\n",
       " 790,\n",
       " 793,\n",
       " 794,\n",
       " 795,\n",
       " 796,\n",
       " 797,\n",
       " 798,\n",
       " 800,\n",
       " 801,\n",
       " 802,\n",
       " 804,\n",
       " 805,\n",
       " 806,\n",
       " 808,\n",
       " 809,\n",
       " 811,\n",
       " 812,\n",
       " 814,\n",
       " 817,\n",
       " 818,\n",
       " 819,\n",
       " 820,\n",
       " 821,\n",
       " 822,\n",
       " 823,\n",
       " 825,\n",
       " 826,\n",
       " 827,\n",
       " 828,\n",
       " 829,\n",
       " 830,\n",
       " 831,\n",
       " 832,\n",
       " 834,\n",
       " 835,\n",
       " 840,\n",
       " 841,\n",
       " 842,\n",
       " 843,\n",
       " 844,\n",
       " 845,\n",
       " 846,\n",
       " 847,\n",
       " 848,\n",
       " 850,\n",
       " 852,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 858,\n",
       " 859,\n",
       " 860,\n",
       " 861,\n",
       " 862,\n",
       " 863,\n",
       " 864,\n",
       " 865,\n",
       " 867,\n",
       " 868,\n",
       " 869,\n",
       " 871,\n",
       " 872,\n",
       " 873,\n",
       " 874,\n",
       " 875,\n",
       " 876,\n",
       " 877,\n",
       " 878,\n",
       " 879,\n",
       " 880,\n",
       " 881,\n",
       " 884,\n",
       " 885,\n",
       " 887,\n",
       " 888,\n",
       " 890,\n",
       " 892,\n",
       " 893,\n",
       " 895,\n",
       " 896,\n",
       " 897,\n",
       " 898,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 902,\n",
       " 903,\n",
       " 904,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 908,\n",
       " 909,\n",
       " 910,\n",
       " 911,\n",
       " 912,\n",
       " 917}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([p['original_id'] for i, p in enumerate(predicts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allennlp features test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['single_id',\n",
       " 'openai_transformer_byte_pair',\n",
       " 'dependency_label',\n",
       " 'ner_tag',\n",
       " 'pos_tag',\n",
       " 'characters',\n",
       " 'elmo_characters',\n",
       " 'bert-pretrained',\n",
       " 'spacy',\n",
       " 'pretrained_transformer']"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TokenIndexer.list_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [listx,\n",
       "  thex,\n",
       "  namex,\n",
       "  bornx,\n",
       "  statex,\n",
       "  andx,\n",
       "  agex,\n",
       "  ofx,\n",
       "  thex,\n",
       "  headsx,\n",
       "  ofx,\n",
       "  departmentsx,\n",
       "  orderedx,\n",
       "  byx,\n",
       "  agex,\n",
       "  .x],\n",
       " '_token_indexers': {'bert': <allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer at 0x152f1e750>},\n",
       " '_indexed_tokens': None,\n",
       " '_indexer_name_to_indexed_token': None,\n",
       " '_token_index_to_indexer_name': None}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_sentence = train_dataset[0]['sentence']\n",
    "vars(instance_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (vocab: allennlp.data.vocabulary.Vocabulary)>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature(instance_sentence.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_token_min_padding_length', 'vocab', 'wordpiece_tokenizer', '_namespace', '_added_to_vocabulary', 'max_pieces', 'use_starting_offsets', '_do_lowercase', '_truncate_long_sequences', '_warned_about_truncation', '_never_lowercase', '_start_piece_ids', '_end_piece_ids', '_separator_ids'])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_indexer = token_indexers['bert']\n",
    "bert_indexer.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (tokens: Dict[str, List[int]], desired_num_tokens: Dict[str, int], padding_lengths: Dict[str, int]) -> Dict[str, torch.Tensor]>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature(bert_indexer.as_padded_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 82456.83it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(train_dataset + dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_padding_token': '@@PADDING@@',\n",
       " '_oov_token': '@@UNKNOWN@@',\n",
       " '_non_padded_namespaces': {'*labels', '*tags'},\n",
       " '_token_to_index': _TokenToIndexDefaultDict(None, {}),\n",
       " '_index_to_token': _IndexToTokenDefaultDict(None, {}),\n",
       " '_retained_counter': {}}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [listx,\n",
       "  thex,\n",
       "  namex,\n",
       "  bornx,\n",
       "  statex,\n",
       "  andx,\n",
       "  agex,\n",
       "  ofx,\n",
       "  thex,\n",
       "  headsx,\n",
       "  ofx,\n",
       "  departmentsx,\n",
       "  orderedx,\n",
       "  byx,\n",
       "  agex,\n",
       "  .x],\n",
       " '_token_indexers': {'bert': <allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer at 0x152f1e750>},\n",
       " '_indexed_tokens': {'bert': [101,\n",
       "   2862,\n",
       "   2595,\n",
       "   1996,\n",
       "   2595,\n",
       "   2171,\n",
       "   2595,\n",
       "   2141,\n",
       "   2595,\n",
       "   2110,\n",
       "   2595,\n",
       "   1998,\n",
       "   2595,\n",
       "   2287,\n",
       "   2595,\n",
       "   1997,\n",
       "   2595,\n",
       "   1996,\n",
       "   2595,\n",
       "   4641,\n",
       "   2595,\n",
       "   1997,\n",
       "   2595,\n",
       "   7640,\n",
       "   2595,\n",
       "   3641,\n",
       "   2595,\n",
       "   2011,\n",
       "   2595,\n",
       "   2287,\n",
       "   2595,\n",
       "   1012,\n",
       "   2595,\n",
       "   102],\n",
       "  'bert-offsets': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32],\n",
       "  'bert-type-ids': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]},\n",
       " '_indexer_name_to_indexed_token': {'bert': ['bert',\n",
       "   'bert-offsets',\n",
       "   'bert-type-ids',\n",
       "   'mask']},\n",
       " '_token_index_to_indexer_name': {'bert': 'bert',\n",
       "  'bert-offsets': 'bert',\n",
       "  'bert-type-ids': 'bert',\n",
       "  'mask': 'bert'}}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a sentence, token_indexers: {Bert: 1-dim; Word: 1-dim; Char: 2-dim}\n",
    "instance_sentence.index(vocab)\n",
    "vars(instance_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "bert_config = BertConfig.from_pretrained(bert_model_name, finetuning_task='reranking')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name, do_lower_case=True)\n",
    "bert_model = BertModel.from_pretrained(bert_model_name, from_tf=False, config=bert_config)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['single_id',\n",
       " 'openai_transformer_byte_pair',\n",
       " 'dependency_label',\n",
       " 'ner_tag',\n",
       " 'pos_tag',\n",
       " 'characters',\n",
       " 'elmo_characters',\n",
       " 'bert-pretrained',\n",
       " 'spacy',\n",
       " 'pretrained_transformer']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TokenIndexer.list_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TokenIndexer.by_name('bert-pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer at 0x15bab9490>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TokenIndexer.by_name('bert-pretrained')('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils_bert_pa.convert_examples_to_features() <- need to modify this (labels?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1307bb84f6e143f6878abe76b494aefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'quick', 'brown', 'fox', '##x', 'jumped', 'over', 'the', 'old', 'dogg']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('A quick brown foxx jumped over the old dogg, ohhh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_indexer = TokenIndexer.by_name('bert-pretrained')('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_token_min_padding_length', 'vocab', 'wordpiece_tokenizer', '_namespace', '_added_to_vocabulary', 'max_pieces', 'use_starting_offsets', '_do_lowercase', '_truncate_long_sequences', '_warned_about_truncation', '_never_lowercase', '_start_piece_ids', '_end_piece_ids', '_separator_ids'])"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_indexer.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([A,\n",
       "  quick,\n",
       "  brown,\n",
       "  foxx,\n",
       "  jumped,\n",
       "  over,\n",
       "  the,\n",
       "  old,\n",
       "  dogg,,\n",
       "  ohhh,\n",
       "  [SEP],\n",
       "  another,\n",
       "  sentence,\n",
       "  &,\n",
       "  another,\n",
       "  sentence],\n",
       " 16)"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [Token(w) for w in 'A quick brown foxx jumped over the old dogg , ohhh [SEP] another sentence & another sentence'.split(' ')]\n",
    "tokens, len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert': tensor([[  101,  1037,  4248,  2829,  4419,  2595,  5598,  2058,  1996,  2214,\n",
       "          28844,   102,  2178,  6251,  1004,  2178,  6251,   102]]),\n",
       " 'bert-offsets': tensor([[ 1,  2,  3,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16]]),\n",
       " 'bert-type-ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]]),\n",
       " 'mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_indexed = token_indexer.tokens_to_indices(tokens, vocab, 'bert')\n",
    "token_indexed_tensor = {k : torch.LongTensor([v]) for k, v in token_indexed.items()}\n",
    "token_indexed_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[CLS]', 0),\n",
       " ('a', 0),\n",
       " ('quick', 0),\n",
       " ('brown', 0),\n",
       " ('fox', 0),\n",
       " ('##x', 0),\n",
       " ('jumped', 0),\n",
       " ('over', 0),\n",
       " ('the', 0),\n",
       " ('old', 0),\n",
       " ('dogg', 0),\n",
       " ('[SEP]', 0),\n",
       " ('another', 1),\n",
       " ('sentence', 1),\n",
       " ('&', 1),\n",
       " ('another', 1),\n",
       " ('sentence', 1),\n",
       " ('[SEP]', 1)]"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2w = vocab.get_index_to_token_vocabulary('bert')\n",
    "[(id2w[token_indexed['bert'][i]], token_indexed['bert-type-ids'][i]) for i in range(len(token_indexed['bert']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 768])"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = bert_embedder(token_indexed_tensor)\n",
    "embedding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18])"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_indexed_tensor['bert'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'perpetrator': {'people': <__main__.Table at 0x13b3b10d0>,\n",
       "  'perpetrator': <__main__.Table at 0x13b3b1110>},\n",
       " 'college_2': {'prereq': <__main__.Table at 0x13b3b1850>,\n",
       "  'classroom': <__main__.Table at 0x13b3b1890>,\n",
       "  'department': <__main__.Table at 0x13b3b1a50>,\n",
       "  'course': <__main__.Table at 0x13b3b1c10>,\n",
       "  'instructor': <__main__.Table at 0x13b3b1e50>,\n",
       "  'section': <__main__.Table at 0x13b3b40d0>,\n",
       "  'teaches': <__main__.Table at 0x13b3b44d0>,\n",
       "  'student': <__main__.Table at 0x13b3b47d0>,\n",
       "  'takes': <__main__.Table at 0x13b3b4a10>,\n",
       "  'advisor': <__main__.Table at 0x13b3b4d90>,\n",
       "  'time_slot': <__main__.Table at 0x13b3b4ed0>},\n",
       " 'flight_company': {'flight': <__main__.Table at 0x13b3b6590>,\n",
       "  'airport': <__main__.Table at 0x13b3b65d0>,\n",
       "  'operate_company': <__main__.Table at 0x13b3b6950>},\n",
       " 'icfp_1': {'Authorship': <__main__.Table at 0x13b3b80d0>,\n",
       "  'Inst': <__main__.Table at 0x13b3b8110>,\n",
       "  'Authors': <__main__.Table at 0x13b3b82d0>,\n",
       "  'Papers': <__main__.Table at 0x13b3b8490>},\n",
       " 'body_builder': {'people': <__main__.Table at 0x13b3b8890>,\n",
       "  'body_builder': <__main__.Table at 0x13b3b88d0>},\n",
       " 'storm_record': {'affected_region': <__main__.Table at 0x13b3b8f10>,\n",
       "  'storm': <__main__.Table at 0x13b3b8f50>,\n",
       "  'region': <__main__.Table at 0x13b3ba2d0>},\n",
       " 'pilot_record': {'pilot_record': <__main__.Table at 0x13b3ba610>,\n",
       "  'aircraft': <__main__.Table at 0x13b3ba650>,\n",
       "  'pilot': <__main__.Table at 0x13b3baa50>},\n",
       " 'race_track': {'track': <__main__.Table at 0x13b3bc150>,\n",
       "  'race': <__main__.Table at 0x13b3bc190>},\n",
       " 'academic': {'cite': <__main__.Table at 0x13b3bc790>,\n",
       "  'author': <__main__.Table at 0x13b3bc7d0>,\n",
       "  'conference': <__main__.Table at 0x13b3bca10>,\n",
       "  'domain': <__main__.Table at 0x13b3bcbd0>,\n",
       "  'domain_author': <__main__.Table at 0x13b3bcd10>,\n",
       "  'domain_conference': <__main__.Table at 0x13b3bce50>,\n",
       "  'journal': <__main__.Table at 0x13b3bcf90>,\n",
       "  'domain_journal': <__main__.Table at 0x13b3be190>,\n",
       "  'keyword': <__main__.Table at 0x13b3be2d0>,\n",
       "  'domain_keyword': <__main__.Table at 0x13b3be410>,\n",
       "  'publication': <__main__.Table at 0x13b3be550>,\n",
       "  'domain_publication': <__main__.Table at 0x13b3be9d0>,\n",
       "  'organization': <__main__.Table at 0x13b3beb10>,\n",
       "  'publication_keyword': <__main__.Table at 0x13b3bed50>,\n",
       "  'writes': <__main__.Table at 0x13b3bee90>},\n",
       " 'department_store': {'Staff_Department_Assignments': <__main__.Table at 0x13b3c0590>,\n",
       "  'Addresses': <__main__.Table at 0x13b3c05d0>,\n",
       "  'Staff': <__main__.Table at 0x13b3c0710>,\n",
       "  'Suppliers': <__main__.Table at 0x13b3c08d0>,\n",
       "  'Department_Store_Chain': <__main__.Table at 0x13b3c0a90>,\n",
       "  'Customers': <__main__.Table at 0x13b3c0b50>,\n",
       "  'Products': <__main__.Table at 0x13b3c0ed0>,\n",
       "  'Supplier_Addresses': <__main__.Table at 0x13b3c3110>,\n",
       "  'Customer_Addresses': <__main__.Table at 0x13b3c3350>,\n",
       "  'Customer_Orders': <__main__.Table at 0x13b3c3590>,\n",
       "  'Department_Stores': <__main__.Table at 0x13b3c3790>,\n",
       "  'Departments': <__main__.Table at 0x13b3c3ad0>,\n",
       "  'Order_Items': <__main__.Table at 0x13b3c3c90>,\n",
       "  'Product_Suppliers': <__main__.Table at 0x13b3c3e50>},\n",
       " 'music_4': {'music_festival': <__main__.Table at 0x13b3c2390>,\n",
       "  'artist': <__main__.Table at 0x13b3c23d0>,\n",
       "  'volume': <__main__.Table at 0x13b3c2690>},\n",
       " 'insurance_fnol': {'Settlements': <__main__.Table at 0x13b3c2d10>,\n",
       "  'Customers': <__main__.Table at 0x13b3c2d50>,\n",
       "  'Services': <__main__.Table at 0x13b3c2e90>,\n",
       "  'Available_Policies': <__main__.Table at 0x13b3c2fd0>,\n",
       "  'Customers_Policies': <__main__.Table at 0x13b3c7190>,\n",
       "  'First_Notification_of_Loss': <__main__.Table at 0x13b3c73d0>,\n",
       "  'Claims': <__main__.Table at 0x13b3c7610>},\n",
       " 'cinema': {'schedule': <__main__.Table at 0x13b3c79d0>,\n",
       "  'film': <__main__.Table at 0x13b3c7a10>,\n",
       "  'cinema': <__main__.Table at 0x13b3c7d90>},\n",
       " 'decoration_competition': {'round': <__main__.Table at 0x13b3c9390>,\n",
       "  'college': <__main__.Table at 0x13b3c93d0>,\n",
       "  'member': <__main__.Table at 0x13b3c95d0>},\n",
       " 'phone_market': {'phone_market': <__main__.Table at 0x13b3c99d0>,\n",
       "  'phone': <__main__.Table at 0x13b3c9a10>,\n",
       "  'market': <__main__.Table at 0x13b3c9d10>},\n",
       " 'store_product': {'store_district': <__main__.Table at 0x13b3cc1d0>,\n",
       "  'product': <__main__.Table at 0x13b3cc210>,\n",
       "  'store': <__main__.Table at 0x13b3cc5d0>,\n",
       "  'district': <__main__.Table at 0x13b3cc910>,\n",
       "  'store_product': <__main__.Table at 0x13b3ccbd0>},\n",
       " 'assets_maintenance': {'Skills_Required_To_Fix': <__main__.Table at 0x13b3cce90>,\n",
       "  'Third_Party_Companies': <__main__.Table at 0x13b3cced0>,\n",
       "  'Maintenance_Contracts': <__main__.Table at 0x13b3cd1d0>,\n",
       "  'Parts': <__main__.Table at 0x13b3cd390>,\n",
       "  'Skills': <__main__.Table at 0x13b3cd610>,\n",
       "  'Staff': <__main__.Table at 0x13b3cd790>,\n",
       "  'Assets': <__main__.Table at 0x13b3cd990>,\n",
       "  'Asset_Parts': <__main__.Table at 0x13b3cdbd0>,\n",
       "  'Maintenance_Engineers': <__main__.Table at 0x13b3cde50>,\n",
       "  'Engineer_Skills': <__main__.Table at 0x13b3d1190>,\n",
       "  'Fault_Log': <__main__.Table at 0x13b3d12d0>,\n",
       "  'Engineer_Visits': <__main__.Table at 0x13b3d1510>,\n",
       "  'Part_Faults': <__main__.Table at 0x13b3d1810>,\n",
       "  'Fault_Log_Parts': <__main__.Table at 0x13b3d1a50>},\n",
       " 'student_assessment': {'Candidate_Assessments': <__main__.Table at 0x13b3d1ed0>,\n",
       "  'Addresses': <__main__.Table at 0x13b3d1f10>,\n",
       "  'People': <__main__.Table at 0x13b3d4310>,\n",
       "  'Students': <__main__.Table at 0x13b3d4750>,\n",
       "  'Courses': <__main__.Table at 0x13b3d4890>,\n",
       "  'People_Addresses': <__main__.Table at 0x13b3d4a90>,\n",
       "  'Student_Course_Registrations': <__main__.Table at 0x13b3d4d50>,\n",
       "  'Student_Course_Attendance': <__main__.Table at 0x13b3d4ed0>,\n",
       "  'Candidates': <__main__.Table at 0x13b3d6090>},\n",
       " 'dog_kennels': {'Treatments': <__main__.Table at 0x13b3d6350>,\n",
       "  'Breeds': <__main__.Table at 0x13b3d6390>,\n",
       "  'Charges': <__main__.Table at 0x13b3d64d0>,\n",
       "  'Sizes': <__main__.Table at 0x13b3d6690>,\n",
       "  'Treatment_Types': <__main__.Table at 0x13b3d6790>,\n",
       "  'Owners': <__main__.Table at 0x13b3d6850>,\n",
       "  'Dogs': <__main__.Table at 0x13b3d6d90>,\n",
       "  'Professionals': <__main__.Table at 0x13b3da490>},\n",
       " 'music_1': {'song': <__main__.Table at 0x13b3dad90>,\n",
       "  'genre': <__main__.Table at 0x13b3dadd0>,\n",
       "  'artist': <__main__.Table at 0x13b3daf90>,\n",
       "  'files': <__main__.Table at 0x13b3dc210>},\n",
       " 'company_employee': {'employment': <__main__.Table at 0x13b3dca50>,\n",
       "  'people': <__main__.Table at 0x13b3dca90>,\n",
       "  'company': <__main__.Table at 0x13b3dcd50>},\n",
       " 'farm': {'competition_record': <__main__.Table at 0x13b3de290>,\n",
       "  'city': <__main__.Table at 0x13b3de2d0>,\n",
       "  'farm': <__main__.Table at 0x13b3de650>,\n",
       "  'farm_competition': <__main__.Table at 0x13b3deb90>},\n",
       " 'solvency_ii': {'Assets_in_Events': <__main__.Table at 0x13b3e10d0>,\n",
       "  'Addresses': <__main__.Table at 0x13b3e1110>,\n",
       "  'Locations': <__main__.Table at 0x13b3e1250>,\n",
       "  'Products': <__main__.Table at 0x13b3e1390>,\n",
       "  'Parties': <__main__.Table at 0x13b3e1590>,\n",
       "  'Assets': <__main__.Table at 0x13b3e16d0>,\n",
       "  'Channels': <__main__.Table at 0x13b3e1810>,\n",
       "  'Finances': <__main__.Table at 0x13b3e1950>,\n",
       "  'Events': <__main__.Table at 0x13b3e1a90>,\n",
       "  'Products_in_Events': <__main__.Table at 0x13b3e1e10>,\n",
       "  'Parties_in_Events': <__main__.Table at 0x13b3e1f90>,\n",
       "  'Agreements': <__main__.Table at 0x13b3e3190>},\n",
       " 'city_record': {'hosting_city': <__main__.Table at 0x13b3e34d0>,\n",
       "  'city': <__main__.Table at 0x13b3e3510>,\n",
       "  'match': <__main__.Table at 0x13b3e3850>,\n",
       "  'temperature': <__main__.Table at 0x13b3e3bd0>},\n",
       " 'swimming': {'record': <__main__.Table at 0x13b3e5490>,\n",
       "  'swimmer': <__main__.Table at 0x13b3e54d0>,\n",
       "  'stadium': <__main__.Table at 0x13b3e5a90>,\n",
       "  'event': <__main__.Table at 0x13b3e5e10>},\n",
       " 'flight_2': {'flights': <__main__.Table at 0x13b3e7350>,\n",
       "  'airlines': <__main__.Table at 0x13b3e7390>,\n",
       "  'airports': <__main__.Table at 0x13b3e75d0>},\n",
       " 'election': {'election': <__main__.Table at 0x13b3e7ad0>,\n",
       "  'county': <__main__.Table at 0x13b3e7b10>,\n",
       "  'party': <__main__.Table at 0x13b3e7d50>},\n",
       " 'manufactory_1': {'Products': <__main__.Table at 0x13b3e9550>,\n",
       "  'Manufacturers': <__main__.Table at 0x13b3e9590>},\n",
       " 'debate': {'debate_people': <__main__.Table at 0x13b3e9a90>,\n",
       "  'people': <__main__.Table at 0x13b3e9ad0>,\n",
       "  'debate': <__main__.Table at 0x13b3e9dd0>},\n",
       " 'network_2': {'PersonFriend': <__main__.Table at 0x13b3ec210>,\n",
       "  'Person': <__main__.Table at 0x13b3ec250>},\n",
       " 'local_govt_in_alabama': {'Participants_in_Events': <__main__.Table at 0x13b3ec750>,\n",
       "  'Services': <__main__.Table at 0x13b3ec790>,\n",
       "  'Participants': <__main__.Table at 0x13b3ec890>,\n",
       "  'Events': <__main__.Table at 0x13b3ec9d0>},\n",
       " 'climbing': {'climber': <__main__.Table at 0x13b3eccd0>,\n",
       "  'mountain': <__main__.Table at 0x13b3ecd10>},\n",
       " 'e_learning': {'Student_Tests_Taken': <__main__.Table at 0x13b3ee410>,\n",
       "  'Course_Authors_and_Tutors': <__main__.Table at 0x13b3ee450>,\n",
       "  'Students': <__main__.Table at 0x13b3ee6d0>,\n",
       "  'Subjects': <__main__.Table at 0x13b3eecd0>,\n",
       "  'Courses': <__main__.Table at 0x13b3eee10>,\n",
       "  'Student_Course_Enrolment': <__main__.Table at 0x13b3f1110>},\n",
       " 'scientist_1': {'AssignedTo': <__main__.Table at 0x13b3f1510>,\n",
       "  'Scientists': <__main__.Table at 0x13b3f1550>,\n",
       "  'Projects': <__main__.Table at 0x13b3f1690>},\n",
       " 'ship_1': {'Ship': <__main__.Table at 0x13b3f19d0>,\n",
       "  'captain': <__main__.Table at 0x13b3f1a10>},\n",
       " 'entertainment_awards': {'nomination': <__main__.Table at 0x13b3f3150>,\n",
       "  'festival_detail': <__main__.Table at 0x13b3f3190>,\n",
       "  'artwork': <__main__.Table at 0x13b3f3510>},\n",
       " 'allergy_1': {'Student': <__main__.Table at 0x13b3f3850>,\n",
       "  'Allergy_Type': <__main__.Table at 0x13b3f3890>,\n",
       "  'Has_Allergy': <__main__.Table at 0x13b3f39d0>},\n",
       " 'imdb': {'written_by': <__main__.Table at 0x13b3f3f90>,\n",
       "  'actor': <__main__.Table at 0x13b3f3fd0>,\n",
       "  'copyright': <__main__.Table at 0x13b3f5390>,\n",
       "  'cast': <__main__.Table at 0x13b3f5550>,\n",
       "  'genre': <__main__.Table at 0x13b3f5790>,\n",
       "  'classification': <__main__.Table at 0x13b3f58d0>,\n",
       "  'company': <__main__.Table at 0x13b3f5a90>,\n",
       "  'director': <__main__.Table at 0x13b3f5c50>,\n",
       "  'producer': <__main__.Table at 0x13b3f5fd0>,\n",
       "  'directed_by': <__main__.Table at 0x13b3f8390>,\n",
       "  'keyword': <__main__.Table at 0x13b3f8550>,\n",
       "  'made_by': <__main__.Table at 0x13b3f8690>,\n",
       "  'movie': <__main__.Table at 0x13b3f8850>,\n",
       "  'tags': <__main__.Table at 0x13b3f8b50>,\n",
       "  'tv_series': <__main__.Table at 0x13b3f8d10>,\n",
       "  'writer': <__main__.Table at 0x13b3f9150>},\n",
       " 'products_for_hire': {'View_Product_Availability': <__main__.Table at 0x13b3f9990>,\n",
       "  'Discount_Coupons': <__main__.Table at 0x13b3f99d0>,\n",
       "  'Customers': <__main__.Table at 0x13b3f9b90>,\n",
       "  'Bookings': <__main__.Table at 0x13b3f9f90>,\n",
       "  'Products_for_Hire': <__main__.Table at 0x13b3fb3d0>,\n",
       "  'Payments': <__main__.Table at 0x13b3fb650>,\n",
       "  'Products_Booked': <__main__.Table at 0x13b3fba50>},\n",
       " 'candidate_poll': {'people': <__main__.Table at 0x13b3fbf90>,\n",
       "  'candidate': <__main__.Table at 0x13b3fbfd0>},\n",
       " 'chinook_1': {'Track': <__main__.Table at 0x13b3fe7d0>,\n",
       "  'Album': <__main__.Table at 0x13b3fe810>,\n",
       "  'Artist': <__main__.Table at 0x13b3fe9d0>,\n",
       "  'Customer': <__main__.Table at 0x13b3feb10>,\n",
       "  'Employee': <__main__.Table at 0x13b400210>,\n",
       "  'Genre': <__main__.Table at 0x13b4009d0>,\n",
       "  'Invoice': <__main__.Table at 0x13b400b10>,\n",
       "  'InvoiceLine': <__main__.Table at 0x13b400dd0>,\n",
       "  'MediaType': <__main__.Table at 0x13b4032d0>,\n",
       "  'Playlist': <__main__.Table at 0x13b403410>,\n",
       "  'PlaylistTrack': <__main__.Table at 0x13b403550>},\n",
       " 'flight_4': {'airlines': <__main__.Table at 0x13b403c50>,\n",
       "  'routes': <__main__.Table at 0x13b403c90>,\n",
       "  'airports': <__main__.Table at 0x13b405150>},\n",
       " 'pets_1': {'Pets': <__main__.Table at 0x13b405a90>,\n",
       "  'Student': <__main__.Table at 0x13b405ad0>,\n",
       "  'Has_Pet': <__main__.Table at 0x13b405f50>},\n",
       " 'dorm_1': {'Lives_in': <__main__.Table at 0x13b407350>,\n",
       "  'Student': <__main__.Table at 0x13b407390>,\n",
       "  'Dorm': <__main__.Table at 0x13b407810>,\n",
       "  'Dorm_amenity': <__main__.Table at 0x13b407a10>,\n",
       "  'Has_amenity': <__main__.Table at 0x13b407b50>},\n",
       " 'journal_committee': {'journal_committee': <__main__.Table at 0x13b407ed0>,\n",
       "  'journal': <__main__.Table at 0x13b407f10>,\n",
       "  'editor': <__main__.Table at 0x13b409190>},\n",
       " 'flight_1': {'certificate': <__main__.Table at 0x13b4094d0>,\n",
       "  'flight': <__main__.Table at 0x13b409510>,\n",
       "  'aircraft': <__main__.Table at 0x13b409990>,\n",
       "  'employee': <__main__.Table at 0x13b409b50>},\n",
       " 'medicine_enzyme_interaction': {'medicine_enzyme_interaction': <__main__.Table at 0x13b409ed0>,\n",
       "  'medicine': <__main__.Table at 0x13b409f10>,\n",
       "  'enzyme': <__main__.Table at 0x13b40b190>},\n",
       " 'local_govt_and_lot': {'Timed_Locations_of_Things': <__main__.Table at 0x13b40b750>,\n",
       "  'Customers': <__main__.Table at 0x13b40b790>,\n",
       "  'Properties': <__main__.Table at 0x13b40b890>,\n",
       "  'Residents': <__main__.Table at 0x13b40ba50>,\n",
       "  'Organizations': <__main__.Table at 0x13b40bd50>,\n",
       "  'Services': <__main__.Table at 0x13b40be90>,\n",
       "  'Residents_Services': <__main__.Table at 0x13b40e0d0>,\n",
       "  'Things': <__main__.Table at 0x13b40e4d0>,\n",
       "  'Customer_Events': <__main__.Table at 0x13b40e750>,\n",
       "  'Customer_Event_Notes': <__main__.Table at 0x13b40ea90>,\n",
       "  'Timed_Status_of_Things': <__main__.Table at 0x13b40ed50>},\n",
       " 'station_weather': {'weekly_weather': <__main__.Table at 0x13b410150>,\n",
       "  'train': <__main__.Table at 0x13b410190>,\n",
       "  'station': <__main__.Table at 0x13b410590>,\n",
       "  'route': <__main__.Table at 0x13b4107d0>},\n",
       " 'shop_membership': {'purchase': <__main__.Table at 0x13b410cd0>,\n",
       "  'member': <__main__.Table at 0x13b410d10>,\n",
       "  'branch': <__main__.Table at 0x13b412050>,\n",
       "  'membership_register_branch': <__main__.Table at 0x13b412390>},\n",
       " 'driving_school': {'Lessons': <__main__.Table at 0x13b412750>,\n",
       "  'Addresses': <__main__.Table at 0x13b412790>,\n",
       "  'Staff': <__main__.Table at 0x13b412a90>,\n",
       "  'Vehicles': <__main__.Table at 0x13b412d10>,\n",
       "  'Customers': <__main__.Table at 0x13b416050>,\n",
       "  'Customer_Payments': <__main__.Table at 0x13b4164d0>},\n",
       " 'concert_singer': {'singer_in_concert': <__main__.Table at 0x13b416ad0>,\n",
       "  'stadium': <__main__.Table at 0x13b416b10>,\n",
       "  'singer': <__main__.Table at 0x13b416f10>,\n",
       "  'concert': <__main__.Table at 0x13b418310>},\n",
       " 'music_2': {'Vocals': <__main__.Table at 0x13b418710>,\n",
       "  'Songs': <__main__.Table at 0x13b418750>,\n",
       "  'Albums': <__main__.Table at 0x13b418890>,\n",
       "  'Band': <__main__.Table at 0x13b418b90>,\n",
       "  'Instruments': <__main__.Table at 0x13b418d50>,\n",
       "  'Performance': <__main__.Table at 0x13b418f10>,\n",
       "  'Tracklists': <__main__.Table at 0x13b41b110>},\n",
       " 'sports_competition': {'competition_result': <__main__.Table at 0x13b41b650>,\n",
       "  'club': <__main__.Table at 0x13b41b690>,\n",
       "  'club_rank': <__main__.Table at 0x13b41b8d0>,\n",
       "  'player': <__main__.Table at 0x13b41bc50>,\n",
       "  'competition': <__main__.Table at 0x13b41d110>},\n",
       " 'railway': {'railway_manage': <__main__.Table at 0x13b41d610>,\n",
       "  'railway': <__main__.Table at 0x13b41d650>,\n",
       "  'train': <__main__.Table at 0x13b41da50>,\n",
       "  'manager': <__main__.Table at 0x13b41ddd0>},\n",
       " 'inn_1': {'Reservations': <__main__.Table at 0x13b41f2d0>,\n",
       "  'Rooms': <__main__.Table at 0x13b41f310>},\n",
       " 'museum_visit': {'visit': <__main__.Table at 0x13b41fbd0>,\n",
       "  'museum': <__main__.Table at 0x13b41fc10>,\n",
       "  'visitor': <__main__.Table at 0x13b41fe50>},\n",
       " 'browser_web': {'accelerator_compatible_browser': <__main__.Table at 0x13b4222d0>,\n",
       "  'Web_client_accelerator': <__main__.Table at 0x13b422310>,\n",
       "  'browser': <__main__.Table at 0x13b4225d0>},\n",
       " 'baseball_1': {'team_half': <__main__.Table at 0x13b422910>,\n",
       "  'all_star': <__main__.Table at 0x13b422950>,\n",
       "  'appearances': <__main__.Table at 0x13b422dd0>,\n",
       "  'manager_award': <__main__.Table at 0x13b4248d0>,\n",
       "  'player_award': <__main__.Table at 0x13b424c50>,\n",
       "  'manager_award_vote': <__main__.Table at 0x13b424fd0>,\n",
       "  'player_award_vote': <__main__.Table at 0x13b426410>,\n",
       "  'batting': <__main__.Table at 0x13b426810>,\n",
       "  'batting_postseason': <__main__.Table at 0x13b428390>,\n",
       "  'player_college': <__main__.Table at 0x13b428ed0>,\n",
       "  'fielding': <__main__.Table at 0x13b42a0d0>,\n",
       "  'fielding_outfield': <__main__.Table at 0x13b42aa10>,\n",
       "  'fielding_postseason': <__main__.Table at 0x13b42ad90>,\n",
       "  'hall_of_fame': <__main__.Table at 0x13b42c690>,\n",
       "  'home_game': <__main__.Table at 0x13b42c950>,\n",
       "  'manager': <__main__.Table at 0x13b42ce10>,\n",
       "  'manager_half': <__main__.Table at 0x13b42e590>,\n",
       "  'player': <__main__.Table at 0x13b42ead0>,\n",
       "  'park': <__main__.Table at 0x13b431750>,\n",
       "  'pitching': <__main__.Table at 0x13b431ad0>,\n",
       "  'pitching_postseason': <__main__.Table at 0x13b433a50>,\n",
       "  'salary': <__main__.Table at 0x13b4349d0>,\n",
       "  'college': <__main__.Table at 0x13b434cd0>,\n",
       "  'postseason': <__main__.Table at 0x13b434fd0>,\n",
       "  'team': <__main__.Table at 0x13b437290>,\n",
       "  'team_franchise': <__main__.Table at 0x13b439cd0>},\n",
       " 'architecture': {'mill': <__main__.Table at 0x13b43a5d0>,\n",
       "  'architect': <__main__.Table at 0x13b43a610>,\n",
       "  'bridge': <__main__.Table at 0x13b43a850>},\n",
       " 'csu_1': {'faculty': <__main__.Table at 0x13b43d050>,\n",
       "  'Campuses': <__main__.Table at 0x13b43d090>,\n",
       "  'csu_fees': <__main__.Table at 0x13b43d390>,\n",
       "  'degrees': <__main__.Table at 0x13b43d550>,\n",
       "  'discipline_enrollments': <__main__.Table at 0x13b43d710>,\n",
       "  'enrollments': <__main__.Table at 0x13b43da10>},\n",
       " 'tracking_orders': {'Shipment_Items': <__main__.Table at 0x13b43ded0>,\n",
       "  'Customers': <__main__.Table at 0x13b43df10>,\n",
       "  'Invoices': <__main__.Table at 0x13b43f0d0>,\n",
       "  'Orders': <__main__.Table at 0x13b43f290>,\n",
       "  'Products': <__main__.Table at 0x13b43f550>,\n",
       "  'Order_Items': <__main__.Table at 0x13b43f710>,\n",
       "  'Shipments': <__main__.Table at 0x13b43f990>},\n",
       " 'insurance_policies': {'Payments': <__main__.Table at 0x13b43fe10>,\n",
       "  'Customers': <__main__.Table at 0x13b43fe50>,\n",
       "  'Customer_Policies': <__main__.Table at 0x13b43ff50>,\n",
       "  'Claims': <__main__.Table at 0x13b442250>,\n",
       "  'Settlements': <__main__.Table at 0x13b442590>},\n",
       " 'gas_company': {'station_company': <__main__.Table at 0x13b442b90>,\n",
       "  'company': <__main__.Table at 0x13b442bd0>,\n",
       "  'gas_station': <__main__.Table at 0x13b442e90>},\n",
       " 'e_government': {'Party_Services': <__main__.Table at 0x13b444510>,\n",
       "  'Addresses': <__main__.Table at 0x13b444550>,\n",
       "  'Services': <__main__.Table at 0x13b444850>,\n",
       "  'Forms': <__main__.Table at 0x13b444a10>,\n",
       "  'Individuals': <__main__.Table at 0x13b444d50>,\n",
       "  'Organizations': <__main__.Table at 0x13b444fd0>,\n",
       "  'Parties': <__main__.Table at 0x13b446210>,\n",
       "  'Organization_Contact_Individuals': <__main__.Table at 0x13b446410>,\n",
       "  'Party_Addresses': <__main__.Table at 0x13b446610>,\n",
       "  'Party_Forms': <__main__.Table at 0x13b446890>},\n",
       " 'school_bus': {'school_bus': <__main__.Table at 0x13b446d50>,\n",
       "  'driver': <__main__.Table at 0x13b446d90>,\n",
       "  'school': <__main__.Table at 0x13b44a0d0>},\n",
       " 'machine_repair': {'repair_assignment': <__main__.Table at 0x13b44a5d0>,\n",
       "  'repair': <__main__.Table at 0x13b44a610>,\n",
       "  'machine': <__main__.Table at 0x13b44a850>,\n",
       "  'technician': <__main__.Table at 0x13b44ac50>},\n",
       " 'theme_gallery': {'exhibition_record': <__main__.Table at 0x13b44c110>,\n",
       "  'artist': <__main__.Table at 0x13b44c150>,\n",
       "  'exhibition': <__main__.Table at 0x13b44c450>},\n",
       " 'film_rank': {'film_market_estimation': <__main__.Table at 0x13b44c8d0>,\n",
       "  'film': <__main__.Table at 0x13b44c910>,\n",
       "  'market': <__main__.Table at 0x13b44cc10>},\n",
       " 'party_people': {'party_events': <__main__.Table at 0x13b44e210>,\n",
       "  'region': <__main__.Table at 0x13b44e250>,\n",
       "  'party': <__main__.Table at 0x13b44e5d0>,\n",
       "  'member': <__main__.Table at 0x13b44e950>},\n",
       " 'hospital_1': {'Undergoes': <__main__.Table at 0x13b44edd0>,\n",
       "  'Physician': <__main__.Table at 0x13b44ee10>,\n",
       "  'Department': <__main__.Table at 0x13b451090>,\n",
       "  'Affiliated_With': <__main__.Table at 0x13b451250>,\n",
       "  'Procedures': <__main__.Table at 0x13b4513d0>,\n",
       "  'Trained_In': <__main__.Table at 0x13b451590>,\n",
       "  'Patient': <__main__.Table at 0x13b451750>,\n",
       "  'Nurse': <__main__.Table at 0x13b451ad0>,\n",
       "  'Appointment': <__main__.Table at 0x13b451dd0>,\n",
       "  'Medication': <__main__.Table at 0x13b453210>,\n",
       "  'Prescribes': <__main__.Table at 0x13b453450>,\n",
       "  'Block': <__main__.Table at 0x13b4537d0>,\n",
       "  'Room': <__main__.Table at 0x13b453910>,\n",
       "  'On_Call': <__main__.Table at 0x13b453c10>,\n",
       "  'Stay': <__main__.Table at 0x13b453f10>},\n",
       " 'customers_campaigns_ecommerce': {'Order_Items': <__main__.Table at 0x13b456850>,\n",
       "  'Premises': <__main__.Table at 0x13b456890>,\n",
       "  'Products': <__main__.Table at 0x13b456a50>,\n",
       "  'Customers': <__main__.Table at 0x13b456bd0>,\n",
       "  'Mailshot_Campaigns': <__main__.Table at 0x13b456fd0>,\n",
       "  'Customer_Addresses': <__main__.Table at 0x13b458250>,\n",
       "  'Customer_Orders': <__main__.Table at 0x13b4584d0>,\n",
       "  'Mailshot_Customers': <__main__.Table at 0x13b458790>},\n",
       " 'gymnast': {'people': <__main__.Table at 0x13b458c50>,\n",
       "  'gymnast': <__main__.Table at 0x13b458c90>},\n",
       " 'restaurants': {'LOCATION': <__main__.Table at 0x13b45b310>,\n",
       "  'GEOGRAPHIC': <__main__.Table at 0x13b45b350>,\n",
       "  'RESTAURANT': <__main__.Table at 0x13b45b510>},\n",
       " 'mountain_photos': {'photos': <__main__.Table at 0x13b45ba10>,\n",
       "  'mountain': <__main__.Table at 0x13b45ba50>,\n",
       "  'camera_lens': <__main__.Table at 0x13b45bdd0>},\n",
       " 'battle_death': {'death': <__main__.Table at 0x13b45d450>,\n",
       "  'battle': <__main__.Table at 0x13b45d490>,\n",
       "  'ship': <__main__.Table at 0x13b45d7d0>},\n",
       " 'cre_Doc_Control_Systems': {'Documents_Mailed': <__main__.Table at 0x13b45de90>,\n",
       "  'Ref_Document_Types': <__main__.Table at 0x13b45ded0>,\n",
       "  'Roles': <__main__.Table at 0x13b45df90>,\n",
       "  'Addresses': <__main__.Table at 0x13b45f0d0>,\n",
       "  'Ref_Document_Status': <__main__.Table at 0x13b45f210>,\n",
       "  'Ref_Shipping_Agents': <__main__.Table at 0x13b45f2d0>,\n",
       "  'Documents': <__main__.Table at 0x13b45f3d0>,\n",
       "  'Employees': <__main__.Table at 0x13b45f710>,\n",
       "  'Document_Drafts': <__main__.Table at 0x13b45f950>,\n",
       "  'Draft_Copies': <__main__.Table at 0x13b45fb10>,\n",
       "  'Circulation_History': <__main__.Table at 0x13b45fcd0>},\n",
       " 'tracking_share_transactions': {'Transactions_Lots': <__main__.Table at 0x13b4620d0>,\n",
       "  'Investors': <__main__.Table at 0x13b462110>,\n",
       "  'Lots': <__main__.Table at 0x13b462210>,\n",
       "  'Ref_Transaction_Types': <__main__.Table at 0x13b4623d0>,\n",
       "  'Transactions': <__main__.Table at 0x13b462490>,\n",
       "  'Sales': <__main__.Table at 0x13b4627d0>,\n",
       "  'Purchases': <__main__.Table at 0x13b4628d0>},\n",
       " 'apartment_rentals': {'View_Unit_Status': <__main__.Table at 0x13b462ad0>,\n",
       "  'Apartment_Buildings': <__main__.Table at 0x13b462b10>,\n",
       "  'Apartments': <__main__.Table at 0x13b462dd0>,\n",
       "  'Apartment_Facilities': <__main__.Table at 0x13b465210>,\n",
       "  'Guests': <__main__.Table at 0x13b465350>,\n",
       "  'Apartment_Bookings': <__main__.Table at 0x13b465610>},\n",
       " 'student_transcripts_tracking': {'Transcript_Contents': <__main__.Table at 0x13b465b10>,\n",
       "  'Addresses': <__main__.Table at 0x13b465b50>,\n",
       "  'Courses': <__main__.Table at 0x13b465e10>,\n",
       "  'Departments': <__main__.Table at 0x13b4681d0>,\n",
       "  'Degree_Programs': <__main__.Table at 0x13b4683d0>,\n",
       "  'Sections': <__main__.Table at 0x13b468610>,\n",
       "  'Semesters': <__main__.Table at 0x13b4688d0>,\n",
       "  'Students': <__main__.Table at 0x13b468ad0>,\n",
       "  'Student_Enrolment': <__main__.Table at 0x13b468fd0>,\n",
       "  'Student_Enrolment_Courses': <__main__.Table at 0x13b46a290>,\n",
       "  'Transcripts': <__main__.Table at 0x13b46a3d0>},\n",
       " 'cre_Docs_and_Epenses': {'Accounts': <__main__.Table at 0x13b46a650>,\n",
       "  'Ref_Document_Types': <__main__.Table at 0x13b46a690>,\n",
       "  'Ref_Budget_Codes': <__main__.Table at 0x13b46a790>,\n",
       "  'Projects': <__main__.Table at 0x13b46a850>,\n",
       "  'Documents': <__main__.Table at 0x13b46a990>,\n",
       "  'Statements': <__main__.Table at 0x13b46ad10>,\n",
       "  'Documents_with_Expenses': <__main__.Table at 0x13b46ae10>},\n",
       " 'ship_mission': {'ship': <__main__.Table at 0x13b46e110>,\n",
       "  'mission': <__main__.Table at 0x13b46e150>},\n",
       " 'company_office': {'Office_locations': <__main__.Table at 0x13b46e850>,\n",
       "  'buildings': <__main__.Table at 0x13b46e890>,\n",
       "  'Companies': <__main__.Table at 0x13b46ec10>},\n",
       " 'tracking_software_problems': {'Problems': <__main__.Table at 0x13b46f290>,\n",
       "  'Problem_Category_Codes': <__main__.Table at 0x13b46f2d0>,\n",
       "  'Problem_Log': <__main__.Table at 0x13b46f390>,\n",
       "  'Problem_Status_Codes': <__main__.Table at 0x13b46f590>,\n",
       "  'Product': <__main__.Table at 0x13b46f7d0>,\n",
       "  'Staff': <__main__.Table at 0x13b46f990>},\n",
       " 'products_gen_characteristics': {'Product_Characteristics': <__main__.Table at 0x13b46fed0>,\n",
       "  'Ref_Characteristic_Types': <__main__.Table at 0x13b46ff10>,\n",
       "  'Ref_Colors': <__main__.Table at 0x13b46ffd0>,\n",
       "  'Ref_Product_Categories': <__main__.Table at 0x13b473110>,\n",
       "  'Characteristics': <__main__.Table at 0x13b473250>,\n",
       "  'Products': <__main__.Table at 0x13b473410>},\n",
       " 'coffee_shop': {'happy_hour_member': <__main__.Table at 0x13b473850>,\n",
       "  'shop': <__main__.Table at 0x13b473890>,\n",
       "  'member': <__main__.Table at 0x13b473b90>,\n",
       "  'happy_hour': <__main__.Table at 0x13b473f10>},\n",
       " 'riding_club': {'match_result': <__main__.Table at 0x13b477310>,\n",
       "  'player': <__main__.Table at 0x13b477350>,\n",
       "  'club': <__main__.Table at 0x13b4777d0>,\n",
       "  'coach': <__main__.Table at 0x13b477a10>,\n",
       "  'player_coach': <__main__.Table at 0x13b477d10>},\n",
       " 'customers_card_transactions': {'Financial_Transactions': <__main__.Table at 0x13b479390>,\n",
       "  'Accounts': <__main__.Table at 0x13b4793d0>,\n",
       "  'Customers': <__main__.Table at 0x13b4795d0>,\n",
       "  'Customers_Cards': <__main__.Table at 0x13b4798d0>},\n",
       " 'county_public_safety': {'city': <__main__.Table at 0x13b479e90>,\n",
       "  'county_public_safety': <__main__.Table at 0x13b479fd0>},\n",
       " 'performance_attendance': {'member_attendance': <__main__.Table at 0x13b47c710>,\n",
       "  'member': <__main__.Table at 0x13b47c950>,\n",
       "  'performance': <__main__.Table at 0x13b47cb90>},\n",
       " 'club_1': {'Member_of_club': <__main__.Table at 0x13b47e050>,\n",
       "  'Student': <__main__.Table at 0x13b47e090>,\n",
       "  'Club': <__main__.Table at 0x13b47e510>},\n",
       " 'singer': {'song': <__main__.Table at 0x13b47e950>,\n",
       "  'singer': <__main__.Table at 0x13b47e990>},\n",
       " 'culture_company': {'culture_company': <__main__.Table at 0x13b47eed0>,\n",
       "  'book_club': <__main__.Table at 0x13b47ef10>,\n",
       "  'movie': <__main__.Table at 0x13b481310>},\n",
       " 'cre_Doc_Template_Mgt': {'Paragraphs': <__main__.Table at 0x13b4819d0>,\n",
       "  'Ref_Template_Types': <__main__.Table at 0x13b481a10>,\n",
       "  'Templates': <__main__.Table at 0x13b481ad0>,\n",
       "  'Documents': <__main__.Table at 0x13b481d50>},\n",
       " 'musical': {'actor': <__main__.Table at 0x13b483250>,\n",
       "  'musical': <__main__.Table at 0x13b483290>},\n",
       " 'world_1': {'countrylanguage': <__main__.Table at 0x13b483a10>,\n",
       "  'city': <__main__.Table at 0x13b483a50>,\n",
       "  'sqlite_sequence': <__main__.Table at 0x13b483d50>,\n",
       "  'country': <__main__.Table at 0x13b483e90>},\n",
       " 'device': {'stock': <__main__.Table at 0x13b486910>,\n",
       "  'device': <__main__.Table at 0x13b486950>,\n",
       "  'shop': <__main__.Table at 0x13b486c90>},\n",
       " 'tracking_grants_for_research': {'Tasks': <__main__.Table at 0x13b488190>,\n",
       "  'Document_Types': <__main__.Table at 0x13b4881d0>,\n",
       "  'Documents': <__main__.Table at 0x13b488290>,\n",
       "  'Grants': <__main__.Table at 0x13b488590>,\n",
       "  'Organisation_Types': <__main__.Table at 0x13b4888d0>,\n",
       "  'Organisations': <__main__.Table at 0x13b488990>,\n",
       "  'Project_Outcomes': <__main__.Table at 0x13b488ad0>,\n",
       "  'Project_Staff': <__main__.Table at 0x13b488c90>,\n",
       "  'Projects': <__main__.Table at 0x13b48b050>,\n",
       "  'Research_Outcomes': <__main__.Table at 0x13b48b210>,\n",
       "  'Research_Staff': <__main__.Table at 0x13b48b310>,\n",
       "  'Staff_Roles': <__main__.Table at 0x13b48b490>},\n",
       " 'employee_hire_evaluation': {'evaluation': <__main__.Table at 0x13b48b790>,\n",
       "  'employee': <__main__.Table at 0x13b48b7d0>,\n",
       "  'shop': <__main__.Table at 0x13b48ba10>,\n",
       "  'hiring': <__main__.Table at 0x13b48bd90>},\n",
       " 'movie_1': {'Rating': <__main__.Table at 0x13b48d1d0>,\n",
       "  'Movie': <__main__.Table at 0x13b48d210>,\n",
       "  'Reviewer': <__main__.Table at 0x13b48d450>},\n",
       " 'network_1': {'Likes': <__main__.Table at 0x13b48d810>,\n",
       "  'Highschooler': <__main__.Table at 0x13b48d850>,\n",
       "  'Friend': <__main__.Table at 0x13b48da10>},\n",
       " 'poker_player': {'people': <__main__.Table at 0x13b48dd50>,\n",
       "  'poker_player': <__main__.Table at 0x13b48dd90>},\n",
       " 'program_share': {'broadcast_share': <__main__.Table at 0x13b4903d0>,\n",
       "  'program': <__main__.Table at 0x13b490410>,\n",
       "  'channel': <__main__.Table at 0x13b490710>,\n",
       "  'broadcast': <__main__.Table at 0x13b490990>},\n",
       " 'aircraft': {'airport_aircraft': <__main__.Table at 0x13b490d10>,\n",
       "  'pilot': <__main__.Table at 0x13b490d50>,\n",
       "  'aircraft': <__main__.Table at 0x13b490f10>,\n",
       "  'match': <__main__.Table at 0x13b494250>,\n",
       "  'airport': <__main__.Table at 0x13b4945d0>},\n",
       " 'restaurant_1': {'Visits_Restaurant': <__main__.Table at 0x13b494ad0>,\n",
       "  'Student': <__main__.Table at 0x13b494b10>,\n",
       "  'Restaurant': <__main__.Table at 0x13b494f90>,\n",
       "  'Type_Of_Restaurant': <__main__.Table at 0x13b496210>,\n",
       "  'Restaurant_Type': <__main__.Table at 0x13b496350>},\n",
       " 'customers_and_invoices': {'Invoice_Line_Items': <__main__.Table at 0x13b496710>,\n",
       "  'Customers': <__main__.Table at 0x13b496750>,\n",
       "  'Orders': <__main__.Table at 0x13b496c90>,\n",
       "  'Invoices': <__main__.Table at 0x13b496e90>,\n",
       "  'Accounts': <__main__.Table at 0x13b499090>,\n",
       "  'Product_Categories': <__main__.Table at 0x13b499310>,\n",
       "  'Products': <__main__.Table at 0x13b499450>,\n",
       "  'Financial_Transactions': <__main__.Table at 0x13b4997d0>,\n",
       "  'Order_Items': <__main__.Table at 0x13b499b10>},\n",
       " 'insurance_and_eClaims': {'Claims_Processing': <__main__.Table at 0x13b49b1d0>,\n",
       "  'Customers': <__main__.Table at 0x13b49b210>,\n",
       "  'Staff': <__main__.Table at 0x13b49b310>,\n",
       "  'Policies': <__main__.Table at 0x13b49b450>,\n",
       "  'Claim_Headers': <__main__.Table at 0x13b49b710>,\n",
       "  'Claims_Documents': <__main__.Table at 0x13b49bb10>,\n",
       "  'Claims_Processing_Stages': <__main__.Table at 0x13b49bcd0>},\n",
       " 'college_1': {'STUDENT': <__main__.Table at 0x13b49f150>,\n",
       "  'CLASS': <__main__.Table at 0x13b49f190>,\n",
       "  'COURSE': <__main__.Table at 0x13b49f510>,\n",
       "  'DEPARTMENT': <__main__.Table at 0x13b49f750>,\n",
       "  'EMPLOYEE': <__main__.Table at 0x13b49fad0>,\n",
       "  'ENROLL': <__main__.Table at 0x13b49fed0>,\n",
       "  'PROFESSOR': <__main__.Table at 0x13b4a10d0>},\n",
       " 'local_govt_mdm': {'Electoral_Register': <__main__.Table at 0x13b4a1a10>,\n",
       "  'Customer_Master_Index': <__main__.Table at 0x13b4a1a50>,\n",
       "  'CMI_Cross_References': <__main__.Table at 0x13b4a1b50>,\n",
       "  'Council_Tax': <__main__.Table at 0x13b4a1c50>,\n",
       "  'Business_Rates': <__main__.Table at 0x13b4a1d50>,\n",
       "  'Benefits_Overpayments': <__main__.Table at 0x13b4a1e10>,\n",
       "  'Parking_Fines': <__main__.Table at 0x13b4a1f10>,\n",
       "  'Rent_Arrears': <__main__.Table at 0x13b4a3050>},\n",
       " 'book_2': {'book': <__main__.Table at 0x13b4a31d0>,\n",
       "  'publication': <__main__.Table at 0x13b4a3210>},\n",
       " 'hr_1': {'locations': <__main__.Table at 0x13b4a3710>,\n",
       "  'regions': <__main__.Table at 0x13b4a3750>,\n",
       "  'countries': <__main__.Table at 0x13b4a3890>,\n",
       "  'departments': <__main__.Table at 0x13b4a3a50>,\n",
       "  'jobs': <__main__.Table at 0x13b4a3c90>,\n",
       "  'employees': <__main__.Table at 0x13b4a3ed0>,\n",
       "  'job_history': <__main__.Table at 0x13b4a64d0>},\n",
       " 'soccer_1': {'Team_Attributes': <__main__.Table at 0x13b4a6b90>,\n",
       "  'Player_Attributes': <__main__.Table at 0x13b4a6bd0>,\n",
       "  'sqlite_sequence': <__main__.Table at 0x13b4ac050>,\n",
       "  'Player': <__main__.Table at 0x13b4ac190>,\n",
       "  'League': <__main__.Table at 0x13b4ac550>,\n",
       "  'Country': <__main__.Table at 0x13b4ac710>,\n",
       "  'Team': <__main__.Table at 0x13b4ac850>},\n",
       " 'sakila_1': {'store': <__main__.Table at 0x13b4ae2d0>,\n",
       "  'actor': <__main__.Table at 0x13b4ae310>,\n",
       "  'address': <__main__.Table at 0x13b4ae550>,\n",
       "  'category': <__main__.Table at 0x13b4ae9d0>,\n",
       "  'city': <__main__.Table at 0x13b4aeb90>,\n",
       "  'country': <__main__.Table at 0x13b4aedd0>,\n",
       "  'customer': <__main__.Table at 0x13b4aef90>,\n",
       "  'film': <__main__.Table at 0x13b4b1290>,\n",
       "  'film_actor': <__main__.Table at 0x13b4b1a90>,\n",
       "  'film_category': <__main__.Table at 0x13b4b1c50>,\n",
       "  'film_text': <__main__.Table at 0x13b4b1e10>,\n",
       "  'inventory': <__main__.Table at 0x13b4b1fd0>,\n",
       "  'language': <__main__.Table at 0x13b4b3250>,\n",
       "  'payment': <__main__.Table at 0x13b4b3410>,\n",
       "  'rental': <__main__.Table at 0x13b4b3810>,\n",
       "  'staff': <__main__.Table at 0x13b4b3c10>},\n",
       " 'real_estate_properties': {'Other_Property_Features': <__main__.Table at 0x13b4b5650>,\n",
       "  'Ref_Feature_Types': <__main__.Table at 0x13b4b5690>,\n",
       "  'Ref_Property_Types': <__main__.Table at 0x13b4b5750>,\n",
       "  'Other_Available_Features': <__main__.Table at 0x13b4b5810>,\n",
       "  'Properties': <__main__.Table at 0x13b4b59d0>},\n",
       " 'college_3': {'Gradeconversion': <__main__.Table at 0x13b4b8710>,\n",
       "  'Student': <__main__.Table at 0x13b4b8750>,\n",
       "  'Faculty': <__main__.Table at 0x13b4b8bd0>,\n",
       "  'Department': <__main__.Table at 0x13b4ba090>,\n",
       "  'Member_of': <__main__.Table at 0x13b4ba410>,\n",
       "  'Course': <__main__.Table at 0x13b4ba5d0>,\n",
       "  'Minor_in': <__main__.Table at 0x13b4ba9d0>,\n",
       "  'Enrolled_in': <__main__.Table at 0x13b4bab10>},\n",
       " 'course_teach': {'course_arrange': <__main__.Table at 0x13b4bafd0>,\n",
       "  'course': <__main__.Table at 0x13b4bc050>,\n",
       "  'teacher': <__main__.Table at 0x13b4bc210>},\n",
       " 'roller_coaster': {'country': <__main__.Table at 0x13b4bc5d0>,\n",
       "  'roller_coaster': <__main__.Table at 0x13b4bc610>},\n",
       " 'customer_deliveries': {'Order_Deliveries': <__main__.Table at 0x13b4bcd50>,\n",
       "  'Products': <__main__.Table at 0x13b4bcd90>,\n",
       "  'Addresses': <__main__.Table at 0x13b4bcf90>,\n",
       "  'Customers': <__main__.Table at 0x13b4be310>,\n",
       "  'Regular_Orders': <__main__.Table at 0x13b4be650>,\n",
       "  'Regular_Order_Products': <__main__.Table at 0x13b4be750>,\n",
       "  'Actual_Orders': <__main__.Table at 0x13b4be850>,\n",
       "  'Actual_Order_Products': <__main__.Table at 0x13b4be9d0>,\n",
       "  'Customer_Addresses': <__main__.Table at 0x13b4beb10>,\n",
       "  'Delivery_Routes': <__main__.Table at 0x13b4bee10>,\n",
       "  'Delivery_Route_Locations': <__main__.Table at 0x13b4bef90>,\n",
       "  'Trucks': <__main__.Table at 0x13b4c11d0>,\n",
       "  'Employees': <__main__.Table at 0x13b4c1350>},\n",
       " 'game_injury': {'injury_accident': <__main__.Table at 0x13b4c1850>,\n",
       "  'stadium': <__main__.Table at 0x13b4c1890>,\n",
       "  'game': <__main__.Table at 0x13b4c1b50>},\n",
       " 'school_finance': {'endowment': <__main__.Table at 0x13b4c4390>,\n",
       "  'School': <__main__.Table at 0x13b4c43d0>,\n",
       "  'budget': <__main__.Table at 0x13b4c4810>},\n",
       " 'scholar': {'writes': <__main__.Table at 0x13b4c4d50>,\n",
       "  'venue': <__main__.Table at 0x13b4c4d90>,\n",
       "  'author': <__main__.Table at 0x13b4c4ed0>,\n",
       "  'dataset': <__main__.Table at 0x13b4c6050>,\n",
       "  'journal': <__main__.Table at 0x13b4c6190>,\n",
       "  'keyphrase': <__main__.Table at 0x13b4c62d0>,\n",
       "  'paper': <__main__.Table at 0x13b4c6410>,\n",
       "  'cite': <__main__.Table at 0x13b4c6810>,\n",
       "  'paperDataset': <__main__.Table at 0x13b4c6950>,\n",
       "  'paperKeyphrase': <__main__.Table at 0x13b4c6a90>},\n",
       " 'voter_1': {'VOTES': <__main__.Table at 0x13b4c6e50>,\n",
       "  'AREA_CODE_STATE': <__main__.Table at 0x13b4c6e90>,\n",
       "  'CONTESTANTS': <__main__.Table at 0x13b4c6fd0>},\n",
       " 'match_season': {'player': <__main__.Table at 0x13b4c9390>,\n",
       "  'country': <__main__.Table at 0x13b4c93d0>,\n",
       "  'team': <__main__.Table at 0x13b4c95d0>,\n",
       "  'match_season': <__main__.Table at 0x13b4c9710>},\n",
       " 'small_bank_1': {'CHECKING': <__main__.Table at 0x13b4c9f90>,\n",
       "  'ACCOUNTS': <__main__.Table at 0x13b4c9fd0>,\n",
       "  'SAVINGS': <__main__.Table at 0x13b4cb150>},\n",
       " 'wta_1': {'rankings': <__main__.Table at 0x13b4cb410>,\n",
       "  'players': <__main__.Table at 0x13b4cb450>,\n",
       "  'matches': <__main__.Table at 0x13b4cb7d0>},\n",
       " 'yelp': {'tip': <__main__.Table at 0x13b4cca90>,\n",
       "  'business': <__main__.Table at 0x13b4ccad0>,\n",
       "  'category': <__main__.Table at 0x13b4cf0d0>,\n",
       "  'user': <__main__.Table at 0x13b4cf290>,\n",
       "  'checkin': <__main__.Table at 0x13b4cf450>,\n",
       "  'neighbourhood': <__main__.Table at 0x13b4cf690>,\n",
       "  'review': <__main__.Table at 0x13b4cf810>},\n",
       " 'student_1': {'teachers': <__main__.Table at 0x13b4d1090>,\n",
       "  'list': <__main__.Table at 0x13b4d10d0>},\n",
       " 'manufacturer': {'furniture_manufacte': <__main__.Table at 0x13b4d1490>,\n",
       "  'manufacturer': <__main__.Table at 0x13b4d14d0>,\n",
       "  'furniture': <__main__.Table at 0x13b4d1790>},\n",
       " 'store_1': {'playlist_tracks': <__main__.Table at 0x13b4d1b10>,\n",
       "  'artists': <__main__.Table at 0x13b4d1b50>,\n",
       "  'sqlite_sequence': <__main__.Table at 0x13b4d1c90>,\n",
       "  'albums': <__main__.Table at 0x13b4d1dd0>,\n",
       "  'employees': <__main__.Table at 0x13b4d1f90>,\n",
       "  'customers': <__main__.Table at 0x13b4d4790>,\n",
       "  'genres': <__main__.Table at 0x13b4d4e50>,\n",
       "  'invoices': <__main__.Table at 0x13b4d4f90>,\n",
       "  'media_types': <__main__.Table at 0x13b4d6290>,\n",
       "  'tracks': <__main__.Table at 0x13b4d6590>,\n",
       "  'invoice_lines': <__main__.Table at 0x13b4d6850>,\n",
       "  'playlists': <__main__.Table at 0x13b4d6d50>},\n",
       " 'train_station': {'train_station': <__main__.Table at 0x13b4d8290>,\n",
       "  'station': <__main__.Table at 0x13b4d82d0>,\n",
       "  'train': <__main__.Table at 0x13b4d8650>},\n",
       " 'document_management': {'Document_Sections_Images': <__main__.Table at 0x13b4d89d0>,\n",
       "  'Roles': <__main__.Table at 0x13b4d8a10>,\n",
       "  'Users': <__main__.Table at 0x13b4d8b10>,\n",
       "  'Document_Structures': <__main__.Table at 0x13b4d8e10>,\n",
       "  'Functional_Areas': <__main__.Table at 0x13b4d8f10>,\n",
       "  'Images': <__main__.Table at 0x13b4db050>,\n",
       "  'Documents': <__main__.Table at 0x13b4db290>,\n",
       "  'Document_Functional_Areas': <__main__.Table at 0x13b4db510>,\n",
       "  'Document_Sections': <__main__.Table at 0x13b4db610>},\n",
       " 'formula_1': {'lapTimes': <__main__.Table at 0x13b4dba50>,\n",
       "  'circuits': <__main__.Table at 0x13b4dba90>,\n",
       "  'races': <__main__.Table at 0x13b4dbd50>,\n",
       "  'drivers': <__main__.Table at 0x13b4dd410>,\n",
       "  'status': <__main__.Table at 0x13b4dd6d0>,\n",
       "  'seasons': <__main__.Table at 0x13b4dda10>,\n",
       "  'constructors': <__main__.Table at 0x13b4ddb50>,\n",
       "  'constructorStandings': <__main__.Table at 0x13b4dde50>,\n",
       "  'results': <__main__.Table at 0x13b4e0250>,\n",
       "  'driverStandings': <__main__.Table at 0x13b4e0b90>,\n",
       "  'constructorResults': <__main__.Table at 0x13b4e0f50>,\n",
       "  'qualifying': <__main__.Table at 0x13b4e1250>,\n",
       "  'pitStops': <__main__.Table at 0x13b4e1510>},\n",
       " 'game_1': {'SportsInfo': <__main__.Table at 0x13b4e3050>,\n",
       "  'Student': <__main__.Table at 0x13b4e3090>,\n",
       "  'Video_Games': <__main__.Table at 0x13b4e3510>,\n",
       "  'Plays_Games': <__main__.Table at 0x13b4e36d0>},\n",
       " 'loan_1': {'loan': <__main__.Table at 0x13b4e3bd0>,\n",
       "  'bank': <__main__.Table at 0x13b4e3c10>,\n",
       "  'customer': <__main__.Table at 0x13b4e3f10>},\n",
       " 'bike_1': {'weather': <__main__.Table at 0x13b4e6710>,\n",
       "  'station': <__main__.Table at 0x13b4e6750>,\n",
       "  'status': <__main__.Table at 0x13b4e6b10>,\n",
       "  'trip': <__main__.Table at 0x13b4e6d50>},\n",
       " 'entrepreneur': {'people': <__main__.Table at 0x13b4e8ad0>,\n",
       "  'entrepreneur': <__main__.Table at 0x13b4e8b10>},\n",
       " 'orchestra': {'show': <__main__.Table at 0x13b4eb110>,\n",
       "  'conductor': <__main__.Table at 0x13b4eb150>,\n",
       "  'orchestra': <__main__.Table at 0x13b4eb450>,\n",
       "  'performance': <__main__.Table at 0x13b4eb790>},\n",
       " 'cre_Drama_Workshop_Groups': {'Invoice_Items': <__main__.Table at 0x13b4ebe10>,\n",
       "  'Ref_Payment_Methods': <__main__.Table at 0x13b4ebe50>,\n",
       "  'Ref_Service_Types': <__main__.Table at 0x13b4ebf10>,\n",
       "  'Addresses': <__main__.Table at 0x13b4ed050>,\n",
       "  'Products': <__main__.Table at 0x13b4ed3d0>,\n",
       "  'Marketing_Regions': <__main__.Table at 0x13b4ed650>,\n",
       "  'Clients': <__main__.Table at 0x13b4ed7d0>,\n",
       "  'Drama_Workshop_Groups': <__main__.Table at 0x13b4edb10>,\n",
       "  'Performers': <__main__.Table at 0x13b4eded0>,\n",
       "  'Customers': <__main__.Table at 0x13b4ef250>,\n",
       "  'Stores': <__main__.Table at 0x13b4ef590>,\n",
       "  'Bookings': <__main__.Table at 0x13b4ef910>,\n",
       "  'Performers_in_Bookings': <__main__.Table at 0x13b4efb90>,\n",
       "  'Customer_Orders': <__main__.Table at 0x13b4efe10>,\n",
       "  'Order_Items': <__main__.Table at 0x13b4f2190>,\n",
       "  'Invoices': <__main__.Table at 0x13b4f2450>,\n",
       "  'Services': <__main__.Table at 0x13b4f27d0>,\n",
       "  'Bookings_Services': <__main__.Table at 0x13b4f2ad0>},\n",
       " 'car_1': {'cars_data': <__main__.Table at 0x13b4f2fd0>,\n",
       "  'continents': <__main__.Table at 0x13b4f5050>,\n",
       "  'countries': <__main__.Table at 0x13b4f5190>,\n",
       "  'car_makers': <__main__.Table at 0x13b4f5350>,\n",
       "  'model_list': <__main__.Table at 0x13b4f5590>,\n",
       "  'car_names': <__main__.Table at 0x13b4f5750>},\n",
       " 'geo': {'river': <__main__.Table at 0x13b4f5d90>,\n",
       "  'state': <__main__.Table at 0x13b4f5dd0>,\n",
       "  'city': <__main__.Table at 0x13b4f8190>,\n",
       "  'border_info': <__main__.Table at 0x13b4f83d0>,\n",
       "  'highlow': <__main__.Table at 0x13b4f8510>,\n",
       "  'lake': <__main__.Table at 0x13b4f8790>,\n",
       "  'mountain': <__main__.Table at 0x13b4f89d0>},\n",
       " 'behavior_monitoring': {'Students_in_Detention': <__main__.Table at 0x13b4f8dd0>,\n",
       "  'Ref_Address_Types': <__main__.Table at 0x13b4f8e10>,\n",
       "  'Ref_Detention_Type': <__main__.Table at 0x13b4f8ed0>,\n",
       "  'Ref_Incident_Type': <__main__.Table at 0x13b4f8f90>,\n",
       "  'Addresses': <__main__.Table at 0x13b4fa090>,\n",
       "  'Students': <__main__.Table at 0x13b4fa350>,\n",
       "  'Teachers': <__main__.Table at 0x13b4fa910>,\n",
       "  'Assessment_Notes': <__main__.Table at 0x13b4fabd0>,\n",
       "  'Behavior_Incident': <__main__.Table at 0x13b4ff150>,\n",
       "  'Detention': <__main__.Table at 0x13b4ff4d0>,\n",
       "  'Student_Addresses': <__main__.Table at 0x13b4ff7d0>},\n",
       " 'cre_Doc_Tracking_DB': {'Documents_to_be_Destroyed': <__main__.Table at 0x13b4ffc90>,\n",
       "  'Ref_Document_Types': <__main__.Table at 0x13b4ffcd0>,\n",
       "  'Ref_Calendar': <__main__.Table at 0x13b4ffdd0>,\n",
       "  'Ref_Locations': <__main__.Table at 0x13b4fff10>,\n",
       "  'Roles': <__main__.Table at 0x13b5010d0>,\n",
       "  'All_Documents': <__main__.Table at 0x13b501250>,\n",
       "  'Employees': <__main__.Table at 0x13b501550>,\n",
       "  'Document_Locations': <__main__.Table at 0x13b5018d0>},\n",
       " 'university_basketball': {'university': <__main__.Table at 0x13b501d10>,\n",
       "  'basketball_match': <__main__.Table at 0x13b501d50>},\n",
       " 'soccer_2': {'Tryout': <__main__.Table at 0x13b504750>,\n",
       "  'College': <__main__.Table at 0x13b504790>,\n",
       "  'Player': <__main__.Table at 0x13b504950>},\n",
       " 'activity_1': {'Faculty': <__main__.Table at 0x13b504e10>,\n",
       "  'Activity': <__main__.Table at 0x13b504e50>,\n",
       "  'Participates_in': <__main__.Table at 0x13b504f90>,\n",
       "  'Faculty_Participates_in': <__main__.Table at 0x13b507110>,\n",
       "  'Student': <__main__.Table at 0x13b507250>},\n",
       " 'cre_Theme_park': {'Tourist_Attraction_Features': <__main__.Table at 0x13b507c10>,\n",
       "  'Ref_Hotel_Star_Ratings': <__main__.Table at 0x13b507c50>,\n",
       "  'Locations': <__main__.Table at 0x13b507d10>,\n",
       "  'Ref_Attraction_Types': <__main__.Table at 0x13b507f50>,\n",
       "  'Visitors': <__main__.Table at 0x13b509050>,\n",
       "  'Features': <__main__.Table at 0x13b509190>,\n",
       "  'Hotels': <__main__.Table at 0x13b5092d0>,\n",
       "  'Tourist_Attractions': <__main__.Table at 0x13b509550>,\n",
       "  'Street_Markets': <__main__.Table at 0x13b509910>,\n",
       "  'Shops': <__main__.Table at 0x13b509a50>,\n",
       "  'Museums': <__main__.Table at 0x13b509b90>,\n",
       "  'Royal_Family': <__main__.Table at 0x13b509cd0>,\n",
       "  'Theme_Parks': <__main__.Table at 0x13b509dd0>,\n",
       "  'Visits': <__main__.Table at 0x13b509ed0>,\n",
       "  'Photos': <__main__.Table at 0x13b50c1d0>,\n",
       "  'Staff': <__main__.Table at 0x13b50c510>},\n",
       " 'twitter_1': {'user_profiles': <__main__.Table at 0x13b50c7d0>,\n",
       "  'follows': <__main__.Table at 0x13b50c810>,\n",
       "  'tweets': <__main__.Table at 0x13b50c950>},\n",
       " 'election_representative': {'representative': <__main__.Table at 0x13b50ce50>,\n",
       "  'election': <__main__.Table at 0x13b50ce90>},\n",
       " 'voter_2': {'Voting_record': <__main__.Table at 0x13b50f510>,\n",
       "  'Student': <__main__.Table at 0x13b50f550>},\n",
       " 'wedding': {'wedding': <__main__.Table at 0x13b50ff10>,\n",
       "  'people': <__main__.Table at 0x13b50ff50>,\n",
       "  'church': <__main__.Table at 0x13b512290>},\n",
       " 'news_report': {'news_report': <__main__.Table at 0x13b512790>,\n",
       "  'event': <__main__.Table at 0x13b5127d0>,\n",
       "  'journalist': <__main__.Table at 0x13b512a90>},\n",
       " 'wine_1': {'wine': <__main__.Table at 0x13b512f50>,\n",
       "  'grapes': <__main__.Table at 0x13b512f90>,\n",
       "  'appellations': <__main__.Table at 0x13b514190>},\n",
       " 'customers_and_addresses': {'Order_Items': <__main__.Table at 0x13b514ad0>,\n",
       "  'Addresses': <__main__.Table at 0x13b514b10>,\n",
       "  'Products': <__main__.Table at 0x13b514e90>,\n",
       "  'Customers': <__main__.Table at 0x13b514fd0>,\n",
       "  'Customer_Addresses': <__main__.Table at 0x13b516290>,\n",
       "  'Customer_Contact_Channels': <__main__.Table at 0x13b516550>,\n",
       "  'Customer_Orders': <__main__.Table at 0x13b516810>},\n",
       " 'protein_institute': {'protein': <__main__.Table at 0x13b516c90>,\n",
       "  'building': <__main__.Table at 0x13b516cd0>,\n",
       "  'Institution': <__main__.Table at 0x13b519050>},\n",
       " 'school_player': {'player': <__main__.Table at 0x13b5197d0>,\n",
       "  'school': <__main__.Table at 0x13b519810>,\n",
       "  'school_details': <__main__.Table at 0x13b519d10>,\n",
       "  'school_performance': <__main__.Table at 0x13b51b0d0>},\n",
       " 'phone_1': {'phone': <__main__.Table at 0x13b51b650>,\n",
       "  'chip_model': <__main__.Table at 0x13b51b690>,\n",
       "  'screen_mode': <__main__.Table at 0x13b51ba90>},\n",
       " 'tvshow': {'Cartoon': <__main__.Table at 0x13b51e190>,\n",
       "  'TV_Channel': <__main__.Table at 0x13b51e1d0>,\n",
       "  'TV_series': <__main__.Table at 0x13b51e490>},\n",
       " 'wrestler': {'Elimination': <__main__.Table at 0x13b51ee50>,\n",
       "  'wrestler': <__main__.Table at 0x13b51ee90>},\n",
       " 'customer_complaints': {'Complaints': <__main__.Table at 0x13b520550>,\n",
       "  'Staff': <__main__.Table at 0x13b520590>,\n",
       "  'Customers': <__main__.Table at 0x13b520910>,\n",
       "  'Products': <__main__.Table at 0x13b520d50>},\n",
       " 'department_management': {'management': <__main__.Table at 0x13b522450>,\n",
       "  'department': <__main__.Table at 0x13b522490>,\n",
       "  'head': <__main__.Table at 0x13b5227d0>},\n",
       " 'customers_and_products_contacts': {'Order_Items': <__main__.Table at 0x13b522b90>,\n",
       "  'Addresses': <__main__.Table at 0x13b522bd0>,\n",
       "  'Products': <__main__.Table at 0x13b522ed0>,\n",
       "  'Customers': <__main__.Table at 0x13b526110>,\n",
       "  'Contacts': <__main__.Table at 0x13b526490>,\n",
       "  'Customer_Address_History': <__main__.Table at 0x13b526810>,\n",
       "  'Customer_Orders': <__main__.Table at 0x13b526a50>},\n",
       " 'company_1': {'dept_locations': <__main__.Table at 0x13b526e50>,\n",
       "  'works_on': <__main__.Table at 0x13b526e90>,\n",
       "  'employee': <__main__.Table at 0x13b528090>,\n",
       "  'department': <__main__.Table at 0x13b5285d0>,\n",
       "  'project': <__main__.Table at 0x13b528810>,\n",
       "  'dependent': <__main__.Table at 0x13b528a50>},\n",
       " 'workshop_paper': {'Acceptance': <__main__.Table at 0x13b528e50>,\n",
       "  'workshop': <__main__.Table at 0x13b528e90>,\n",
       "  'submission': <__main__.Table at 0x13b52b110>},\n",
       " 'epinions_1': {'trust': <__main__.Table at 0x13b52b4d0>,\n",
       "  'item': <__main__.Table at 0x13b52b510>,\n",
       "  'review': <__main__.Table at 0x13b52b650>,\n",
       "  'useracct': <__main__.Table at 0x13b52b950>},\n",
       " 'party_host': {'party_host': <__main__.Table at 0x13b52bd10>,\n",
       "  'party': <__main__.Table at 0x13b52bd50>,\n",
       "  'host': <__main__.Table at 0x13b52d110>},\n",
       " 'product_catalog': {'Catalog_Contents_Additional_Attributes': <__main__.Table at 0x13b52d510>,\n",
       "  'Attribute_Definitions': <__main__.Table at 0x13b52d550>,\n",
       "  'Catalogs': <__main__.Table at 0x13b52d6d0>,\n",
       "  'Catalog_Structure': <__main__.Table at 0x13b52d910>,\n",
       "  'Catalog_Contents': <__main__.Table at 0x13b52da50>}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = read_dataset_schema('/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/tables.json')\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': <__main__.Table at 0x13b3b10d0>,\n",
       " 'perpetrator': <__main__.Table at 0x13b3b1110>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema['perpetrator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'perpetrator',\n",
       " 'text': 'perpetrator',\n",
       " 'columns': [<__main__.TableColumn at 0x13b3b1190>,\n",
       "  <__main__.TableColumn at 0x13b3b1210>,\n",
       "  <__main__.TableColumn at 0x13b3b1290>,\n",
       "  <__main__.TableColumn at 0x13b3b1310>,\n",
       "  <__main__.TableColumn at 0x13b3b1390>,\n",
       "  <__main__.TableColumn at 0x13b3b1450>,\n",
       "  <__main__.TableColumn at 0x13b3b14d0>,\n",
       "  <__main__.TableColumn at 0x13b3b1550>]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(schema['perpetrator']['perpetrator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'perpetrator_id',\n",
       "  'text': 'perpetrator id',\n",
       "  'column_type': 'number',\n",
       "  'is_primary_key': True,\n",
       "  'foreign_key': None},\n",
       " {'name': 'people_id',\n",
       "  'text': 'people id',\n",
       "  'column_type': 'number',\n",
       "  'is_primary_key': False,\n",
       "  'foreign_key': 'people:people_id'},\n",
       " {'name': 'date',\n",
       "  'text': 'date',\n",
       "  'column_type': 'text',\n",
       "  'is_primary_key': False,\n",
       "  'foreign_key': None},\n",
       " {'name': 'year',\n",
       "  'text': 'year',\n",
       "  'column_type': 'number',\n",
       "  'is_primary_key': False,\n",
       "  'foreign_key': None},\n",
       " {'name': 'location',\n",
       "  'text': 'location',\n",
       "  'column_type': 'text',\n",
       "  'is_primary_key': False,\n",
       "  'foreign_key': None},\n",
       " {'name': 'country',\n",
       "  'text': 'country',\n",
       "  'column_type': 'text',\n",
       "  'is_primary_key': False,\n",
       "  'foreign_key': None},\n",
       " {'name': 'killed',\n",
       "  'text': 'killed',\n",
       "  'column_type': 'number',\n",
       "  'is_primary_key': False,\n",
       "  'foreign_key': None},\n",
       " {'name': 'injured',\n",
       "  'text': 'injured',\n",
       "  'column_type': 'number',\n",
       "  'is_primary_key': False,\n",
       "  'foreign_key': None}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vars(schema['perpetrator']['perpetrator'].columns[i]) for i in range(len(schema['perpetrator']['perpetrator'].columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'people : people id , name , height , weight , home town . perpetrator : perpetrator id , people id , date , year , location , country , killed , injured .'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_db_id = 'perpetrator'\n",
    "_db_tokens = []\n",
    "for table_name, table in schema[_db_id].items():\n",
    "    _db_tokens.append(table.text)\n",
    "    _db_tokens.append(':')\n",
    "    for column in table.columns:\n",
    "        _db_tokens.append(column.text)\n",
    "        _db_tokens.append(',')\n",
    "    _db_tokens[-1] = '.'\n",
    "' '.join(_db_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "department_store ['staff', 'department', 'assignments', ':', 'staff', 'id', ',', 'department', 'id', ',', 'date', 'assigned', 'from', ',', 'job', 'title', 'code', ',', 'date', 'assigned', 'to', '.', 'addresses', ':', 'address', 'id', ',', 'address', 'details', '.', 'staff', ':', 'staff', 'id', ',', 'staff', 'gender', ',', 'staff', 'name', '.', 'suppliers', ':', 'supplier', 'id', ',', 'supplier', 'name', ',', 'supplier', 'phone', '.', 'department', 'store', 'chain', ':', 'department', 'store', 'chain', 'id', ',', 'department', 'store', 'chain', 'name', '.', 'customers', ':', 'customer', 'id', ',', 'payment', 'method', 'code', ',', 'customer', 'code', ',', 'customer', 'name', ',', 'customer', 'address', ',', 'customer', 'phone', ',', 'customer', 'email', '.', 'products', ':', 'product', 'id', ',', 'product', 'type', 'code', ',', 'product', 'name', ',', 'product', 'price', '.', 'supplier', 'addresses', ':', 'supplier', 'id', ',', 'address', 'id', ',', 'date', 'from', ',', 'date', 'to', '.', 'customer', 'addresses', ':', 'customer', 'id', ',', 'address', 'id', ',', 'date', 'from', ',', 'date', 'to', '.', 'customer', 'orders', ':', 'order', 'id', ',', 'customer', 'id', ',', 'order', 'status', 'code', ',', 'order', 'date', '.', 'department', 'stores', ':', 'department', 'store', 'id', ',', 'department', 'store', 'chain', 'id', ',', 'store', 'name', ',', 'store', 'address', ',', 'store', 'phone', ',', 'store', 'email', '.', 'departments', ':', 'department', 'id', ',', 'department', 'store', 'id', ',', 'department', 'name', '.', 'order', 'items', ':', 'order', 'item', 'id', ',', 'order', 'id', ',', 'product', 'id', '.', 'product', 'suppliers', ':', 'product', 'id', ',', 'supplier', 'id', ',', 'date', 'supplied', 'from', ',', 'date', 'supplied', 'to', ',', 'total', 'amount', 'purchased', ',', 'total', 'value', 'purchased', '.']\n"
     ]
    }
   ],
   "source": [
    "for db_id in schema:\n",
    "    db_tokens = dbToTokens(schema[db_id])\n",
    "    if len(db_tokens) == 225:\n",
    "        print(db_id, db_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many singers do we have ?\t0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "What is the total number of singers ?\t0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "show name Country age for all singers ordered by age from the oldest to the youngest .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "what are the names , countries and ages for every singer in descending order of age ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "what is the average minimum and maximum age of all singers from France ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "what is the average minimum and maximum age for all French singers ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "show the name and the release year of the song by the youngest singer .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "whatever names and release years for all the songs of the youngest singer .\t1 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "what are all distinct countries where singers above age 20 year from\t0 0 0 0 0 0 0 0 0 0 1 0\tconcert_singer\n",
      "\n",
      "what are the different countries with singers above age 20 ?\t0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "show all countries in the number of singers in each country .\t0 0 0 1 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "how many singers air from each country .\t0 0 0 1 0 0 0 0\tconcert_singer\n",
      "\n",
      "list all song names by singers above the average age .\t0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "what are all the song names by singers who are older than average ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "show location and name for all stadiums , with the capacity between 5000 and 10,000 .\t0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\tconcert_singer\n",
      "\n",
      "what are the locations and names of all stations with capacity between 5000 and 10,000 .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tconcert_singer\n",
      "\n",
      "what is the average in the maximum capacity of all stadiums ?\t0 0 0 0 1 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "what is the average in maximum capacities for all stations ?\t0 0 0 0 1 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "what is the name and capacity for the stadium with highest average attendance ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "what is the name and capacity for the stadium with the highest average attendance ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "how many concerts are there in year 2014 or 2015 .\t0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "how many concerts occurred in 2014 or 2015 .\t0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "show the stadium name and the number of concerts in each stadium .\t0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "for each stadium . How many concerts play there ?\t0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "show the stadium name and capacity with most number of concerts in year 2014 or after .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "what is the name and capacity of the stadium with the most concerts after 2013 ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "which year has most number of concerts .\t0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "what is the year that had the most concerts ?\t0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "show the stadium names without any concert .\t0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "What are the names of the stadiums without any concerts ?\t0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "show countries where a singer above age 40 and a singer below 30 year from\t0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tconcert_singer\n",
      "\n",
      "show names for all stadiums except for stadiums having a concert in year 2014 .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "What are the names of all stadiums that did not have a concert in 2014 ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "show the name and theme brawl , concerts and the number of singers in each concert .\t0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "What are the names , themes , a number of singers for each and every concert .\t0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "list . Singer names a number of concerts for each singer .\t0 0 0 0 1 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "what are the names of the singers and number of concerts for each person ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "list fell singer names and concerts and year 2014 .\t0 1 0 0 1 0 1 0 0 0\tconcert_singer\n",
      "\n",
      "What are the names of the singers who performed in a concert in 2014 ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "What is the name ? A nation of the singer who have a song having hey in its name .\t0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "what is the name and country of origin of every singer who has a song with the word hey in its title ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "find the name and location of the stadiums , which some concerts happened in the years of both 2014 and 2015 .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "what are the names and locations of the stadium's that had concerts that occurred in both 2014 and 2015 ?\t0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "find the number of concerts happened in the stadium with the highest capacity .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "what have a number of concerts that occurred in the stadium with the largest capacity .\t0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\tconcert_singer\n",
      "\n",
      "find the number of pets whose weight is heavier than 10 .\t0 0 0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "how many pets have a greater weight than 10 .\t0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "find the weight of the youngest dog .\t0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "How much does the youngest doc way ?\t0 0 0 0 0 1 1 0\tpets_1\n",
      "\n",
      "find the maximum weight for each type of pet list , the maximum weight and pet type .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "list the maximum weight and type for each type of pet .\t0 0 0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "find number of pets owned by students who are older than 20 .\t0 0 0 0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "how many pets are owned by students that have an H greater than 20 .\t0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\tpets_1\n",
      "\n",
      "find the number of dog pets that are raised by female students with sex F .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "how many Doug pets are raised by female students .\t0 0 1 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "find the number of distinct type of pets .\t0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "how many different types of Petr there .\t0 0 0 0 0 1 0 0\tpets_1\n",
      "\n",
      "find the first name of students who have cat or dog pet .\t0 0 0 0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "What are the first names of every student who has a cat or a dog as a pet ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\tpets_1\n",
      "\n",
      "find the name of students who have both Captain Doug pets .\t0 0 0 0 0 0 0 0 1 1 0 0\tpets_1\n",
      "\n",
      "What are the students first names who have both cats and dogs , says pets .\t0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\tpets_1\n",
      "\n",
      "find the major in age of students who do not have a cat pet .\t0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "What Major is Every student who does not own a cat is a pet . And also how old are they ?\t0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "find the idea of students who do not have a cat pet .\t0 0 1 0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "what are the odds of the students who do not own cats as pets ?\t0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "find the first name and age of students who have a dog but do not have a cat is a pet .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\tpets_1\n",
      "\n",
      "What is the first name of every student who has a dog that does not have a cat ?\t0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "find the type and weight of the youngest pet .\t0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "What type of pet is the youngest animal , and how much does it weigh ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "find the idea in weight of all pets whose ages older than one .\t0 0 1 1 0 0 0 0 0 1 0 0 1 0\tpets_1\n",
      "\n",
      "What is the idea ? In weight of every pet who is older than one .\t0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\tpets_1\n",
      "\n",
      "find the average and maximum age for each type of pet .\t0 0 0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "what is the average in maximum age for each pet type ?\t0 0 0 0 1 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "find the average weight for each pet type .\t0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "what is the average way for each type of pet ?\t0 0 0 0 1 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "find the first name and age of students who have a pet .\t0 0 0 0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "what are the different first names and ages of the students who do have pets ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "find the idea of the pet owned by student whose last name is Smith .\t0 0 1 0 0 0 0 0 0 0 0 0 1 1 0\tpets_1\n",
      "\n",
      "What is the idea of the pet owned by the student whose last name is Smith ?\t0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "find the number of pets for each student who has any pet and student i . D .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "for students who have pets . How many pets does each student has ?\t0 0 0 0 0 0 0 0 0 0 0 0 1 0\tpets_1\n",
      "\n",
      "find the first name and gender of students who have more than one pet .\t0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "what is the first name and gender of the all the students who have more than one pitch ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tpets_1\n",
      "\n",
      "find the last name of the student who has a cat that his age three .\t0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\tpets_1\n",
      "\n",
      "What is the last name of the student who has a cat that is three years old ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\tpets_1\n",
      "\n",
      "find the average age of students who do not have any pets .\t0 0 0 0 0 0 0 0 0 0 0 1 0\tpets_1\n",
      "\n",
      "what is the average age for all students who do not own any pets ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tpets_1\n",
      "\n",
      "how many continents are there ?\t0 0 0 0 0 0\tcar_1\n",
      "\n",
      "What is the number of continents ?\t0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "How many countries does each continent have list the Continent I D Continent name and the number of countries ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "for each continent list its I D name and how many countries it has .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "how many countries are listed .\t0 0 0 0 0 0\tcar_1\n",
      "\n",
      "how many countries exist .\t0 0 0 0 0\tcar_1\n",
      "\n",
      "How many models does each car maker produce ? List maker . Full name I D in the number .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\tcar_1\n",
      "\n",
      "what is the full name of each car maker , along with its Saudi and how many models it produces ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "which model of the car has the minimum horsepower .\t0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "what is the model of the car with the smallest amount of horsepower ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "find the model of the car , whose weight is below the average weight .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "what is the model for the car with a weight smaller than the average ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "find the name of the makers that produced some cars in the year of 1970 .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "What is the name of the different car makers who produced a car in 1970 ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "find the making production time of the cars that were produced in the earliest year .\t0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "What is the maker of the car produced in the earliest year ? In what year was it ?\t0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\tcar_1\n",
      "\n",
      "which distinct car models are the produced after 1980 .\t0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "What are the different models for the cards produced after 1980 .\t0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "How many carmakers are there in each continents lives the continent name in the count .\t0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0\tcar_1\n",
      "\n",
      "What is the name of each continent and how many carmakers are there in each one ?\t0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "which of the country's has the most carmakers list the country name .\t0 0 0 1 0 0 0 1 0 0 0 0 0\tcar_1\n",
      "\n",
      "What is the name of the country with the most carmakers ?\t0 0 0 0 0 0 0 0 0 0 1 0\tcar_1\n",
      "\n",
      "how many car models are produced by each maker . List the count on the maker full name .\t0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\tcar_1\n",
      "\n",
      "what is the number of car models that are produced by each maker and what is the idea and full name of each maker ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "What is the accelerator ? The car make AMC Hornet sport about S W .\t0 0 0 1 1 0 0 0 0 0 1 1 1 1 0\tcar_1\n",
      "\n",
      "How much does the car accelerate that makes AMC Hornet sport about S W .\t0 0 0 0 0 0 0 0 0 0 1 1 1 1 0\tcar_1\n",
      "\n",
      "how many carmakers are there in France .\t0 0 1 0 0 0 0 0\tcar_1\n",
      "\n",
      "What is the number of makers of care in France ?\t0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "how many car models are produced in the U . S . A .\t0 0 0 0 0 0 0 0 1 0 1 0 1 0\tcar_1\n",
      "\n",
      "what is the count of the car models produced in the United States ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "what is the average mpg mpg of the cars with four cylinders ?\t0 0 0 0 1 1 0 0 0 0 1 0 0\tcar_1\n",
      "\n",
      "what is the average miles per gallon of all the cards with four cylinders ?\t0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\tcar_1\n",
      "\n",
      "what is the smallest weight of the car produced with eight cylinders on 1974 ?\t0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\tcar_1\n",
      "\n",
      "what is the minimum weight of the car with eight cylinders produced in 1974 ?\t0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\tcar_1\n",
      "\n",
      "What are all the makers and models ?\t0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "what are the makers and models ?\t0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "What are the country's having ? At least one carmaker list name and I . D .\t0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "whatever names and deeds of all countries with at least one car maker .\t1 0 0 1 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "what is the number of the cars with horsepower more than 150 ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "What is the number of cars with the horse power greater than 150 ?\t0 0 0 0 0 0 0 1 1 1 0 0 0 0\tcar_1\n",
      "\n",
      "what is the average weight of cars each year ?\t0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "what is the average weight and year for each year ?\t0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "which countries in Europe have at least three car manufacturers .\t0 0 0 0 0 0 0 1 0 0 0\tcar_1\n",
      "\n",
      "what are the names of all European countries with at least three manufacturers ?\t0 0 0 0 0 0 0 0 0 0 0 1 0 0\tcar_1\n",
      "\n",
      "what is the maximum horsepower in the make of the car models with three cylinders ?\t0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\tcar_1\n",
      "\n",
      "What is the largest amount of horsepower for the models with three cylinders and what make is it ?\t0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "which model saves the most gasoline , that is to say , have the maximum miles per gallon .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "What is the car model with the highest mpg ?\t0 0 0 0 1 0 0 0 0 0\tcar_1\n",
      "\n",
      "What is the average horsepower of the cars before 1980 ?\t0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "What is the average horsepower for all cards produced before 1980 ?\t0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "What is the average epistle of the cars of model Valvo ?\t0 0 0 0 1 0 0 0 0 0 1 0\tcar_1\n",
      "\n",
      "What is the average editable for all Volvos ?\t0 0 0 0 1 0 0 0 0\tcar_1\n",
      "\n",
      "what is the maximum accelerate for different number of cylinders ?\t0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "what is the maximum accelerate for all the different cylinders ?\t0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "which model has the most version make of cars .\t0 0 0 0 0 1 1 0 0 0\tcar_1\n",
      "\n",
      "what model has the most different versions ?\t0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "how many cars have more than four cylinders ?\t0 0 0 0 0 0 1 0 0\tcar_1\n",
      "\n",
      "what is the number of cars with more than four cylinders ?\t0 0 0 0 0 0 0 0 0 1 0 0\tcar_1\n",
      "\n",
      "how many cars were produced in 1980 .\t0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "in 1980 How many cars were made .\t0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "how many car models were produced by the maker with full name American Motor Company .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "what is the number of car models created by the carmaker American Motor Company ?\t0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\tcar_1\n",
      "\n",
      "which makers designed more than three car models , list full name and the I . D .\t0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "whatever names and deeds of all makers with more than three models .\t1 0 0 1 0 0 0 0 0 0 1 0 0\tcar_1\n",
      "\n",
      "which distinctive models are produced by maker , with the full name General Motors Air weighing more than 3500 .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\tcar_1\n",
      "\n",
      "What are the different models created by either the carmaker ? General Motors Air weighed more than 3500 .\t0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0\tcar_1\n",
      "\n",
      "in which years cars were produced weighing no less than 3000 and no more than 4000 .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "what are the different years in which there were cars produced that weighed less than 4000 and also cars that waited more than 3000 ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\tcar_1\n",
      "\n",
      "what is the horsepower of the car with the largest accelerate ?\t0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "What is the horsepower of the car with the greatest accelerate ?\t0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "for Modeled , although how many cylinders does the car with the least accelerate have ?\t0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "for a Volvo model . How many cylinders does the version with least accelerate have ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "how many cars have a larger accelerate than the car with the largest horsepower .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "what is the number of cars with a greater accelerate than the one with the most horsepower ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "how many countries has more than two carmakers .\t0 0 0 0 0 0 1 1 0\tcar_1\n",
      "\n",
      "what is the number of countries with more than two carmakers ?\t0 0 0 0 0 0 0 0 0 1 1 0\tcar_1\n",
      "\n",
      "how many cars has over six cylinders ?\t0 0 0 0 0 1 0 0\tcar_1\n",
      "\n",
      "What is the number of cars ? W with over six cylinders .\t0 0 0 0 0 1 0 1 1 0 1 0 0\tcar_1\n",
      "\n",
      "for the cars with four cylinders , which model has the largest horsepower .\t0 0 0 0 1 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "for all of the four cylinder cars , which model has the most horsepower ?\t0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "among the cars with more than lowest horsepower , which ones do not have more than three cylinders , list the car , make it and make name .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0\tcar_1\n",
      "\n",
      "among the cars that do not have the minimum horsepower , what are the makings and names of all those with less than four cylinders ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\tcar_1\n",
      "\n",
      "what is the maximum miles per gallon of the car , with eight cylinders air produced before 1980 .\t0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\tcar_1\n",
      "\n",
      "what is the maximum and P G of the cars that had eight cylinders or that were produced before 1980 ?\t0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "which models air lie there than 3500 but not built by the Ford Motor Company .\t0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "What are the different models ? Fatter . Lighter than 3500 but we're not built by the Ford Motor Company .\t0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "what in the name of the countries where there is not a single car maker .\t0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "what are the names of the countries with no car makers ?\t0 0 0 0 0 0 0 0 0 0 0 0\tcar_1\n",
      "\n",
      "which are the carmakers , which produce at least two models in more than three car makes list the idea and the maker .\t0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0\tcar_1\n",
      "\n",
      "what are the odds and makers of all carmakers that produce at least two models and make more than three cars ?\t0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0\tcar_1\n",
      "\n",
      "What are the idea and names of the countries which have more than three carmakers ? Air produced the featured model .\t0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0\tcar_1\n",
      "\n",
      "what are the names of all countries that either have more than three car makers or produced Viets ?\t0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0\tcar_1\n",
      "\n",
      "which country does airline JetBlue Airways belong to ?\t0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "what country is JetBlue Airways affiliated with ?\t0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "what is the abbreviation of airline JetBlue Airways ?\t0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "which abbreviation corresponds to check Blue Airways .\t0 0 0 0 1 1 0 0\tflight_2\n",
      "\n",
      "list all airline names and they're abbreviations in U . S . A .\t0 0 0 0 0 1 0 0 1 0 1 0 1 0\tflight_2\n",
      "\n",
      "What are the airline names and abbreviations for airlines in the U . S . A .\t0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0\tflight_2\n",
      "\n",
      "list the airport code , a name in the city of Anthony .\t0 0 0 0 0 1 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "give the airport code an airport named Cora sounding to the city Anthony .\t0 0 0 0 1 0 1 1 1 0 0 0 0 0\tflight_2\n",
      "\n",
      "how many airlines do we have ?\t0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "What is the total number of airlines ?\t0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "how many airports do we have ?\t0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "returned the number of airports .\t1 0 0 0 0 0\tflight_2\n",
      "\n",
      "how many flights do we have ?\t0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "returned the number of flights .\t1 0 0 0 0 0\tflight_2\n",
      "\n",
      "which airline has abbreviation you'il ?\t0 0 0 0 1 0\tflight_2\n",
      "\n",
      "give the airline with abbreviation You'll\t0 0 0 0 0 1\tflight_2\n",
      "\n",
      "how many airlines air from U . S . A .\t0 0 0 1 0 1 0 1 0 1 0\tflight_2\n",
      "\n",
      "return the number of airlines in the U . S . A .\t0 0 0 0 0 0 0 1 0 1 0 1 0\tflight_2\n",
      "\n",
      "which city and country is the often airport at ?\t0 0 0 0 0 0 1 0 0 0\tflight_2\n",
      "\n",
      "give the city and country for the Alton Airport .\t0 0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "What is the airport name for Airport taco ?\t0 0 0 0 0 0 0 1 0\tflight_2\n",
      "\n",
      "return the name of the airport with co doc . Oh .\t0 0 0 0 0 0 0 1 1 0 1 0\tflight_2\n",
      "\n",
      "what are airport names at City Aberdeen ?\t0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "What are the names of airports in Aberdeen ?\t0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "how many flights depart from a PG .\t0 0 0 0 0 1 1 0\tflight_2\n",
      "\n",
      "count the number of flights departing from a PG .\t0 0 0 0 0 0 0 1 1 0\tflight_2\n",
      "\n",
      "how many flights have destination Auto ?\t0 0 0 0 0 1 0\tflight_2\n",
      "\n",
      "count the number of flights into auto .\t0 0 0 0 0 0 1 0\tflight_2\n",
      "\n",
      "how many flights depart from City Aberdeen .\t0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "return the number of flights departing from Aberdeen .\t0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "how many flights arriving in Aberdeen City .\t0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "returned the number of flights arriving in Aberdeen .\t1 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "how many flights depart from city Aberdeen and have destination city Ashley .\t0 0 0 0 0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "how many flights fly from Aberdeen to Ashley .\t0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "How many flights does airline JetBlue Airways has ?\t0 0 0 0 0 0 0 1 0\tflight_2\n",
      "\n",
      "give the number of JetBlue Airways flights .\t0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "how many United Airlines flights go to airport Asi .\t0 0 0 0 0 0 0 0 1 0\tflight_2\n",
      "\n",
      "count the number of United Airlines flights arriving in a Yes . Why Airport ?\t0 0 0 0 0 0 0 0 0 1 1 0 1 1 0\tflight_2\n",
      "\n",
      "how many United Airlines flights depart from airport HD .\t0 0 0 0 0 0 0 0 1 0\tflight_2\n",
      "\n",
      "return the number of United Airlines flights leaving from a HD airport .\t0 0 0 0 0 0 0 0 0 1 1 0 0\tflight_2\n",
      "\n",
      "how many United Airlines flights go to City Aberdeen .\t0 0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "count the number of United Airlines flights that derive in Aberdeen .\t0 0 0 0 0 0 0 0 1 0 0 0\tflight_2\n",
      "\n",
      "which city has most number of arriving flights .\t0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "which city has the most frequent destination airport .\t0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "which city has most number of departing flights .\t0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "which city is the most frequent source airport .\t0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "What is the code of airport that has the highest number of flights ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "What is the airport code of the airport with the most flights ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "What is the code of airport that has fewest number of flights ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "give the code of the airport with the least flights .\t0 0 0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "which airline has most number of flights .\t0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "what airline serves the most flights .\t0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "find the abbreviation and country of the airline that has fewest number of flights .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "What is the abbreviation of the airline Has the fewest flights in what country is it in ?\t0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "What are airlines that have some flight departing from airport HD ?\t0 0 0 0 0 0 0 0 0 0 1 0\tflight_2\n",
      "\n",
      "which airlines have a flight with Source Airport HD .\t0 0 0 0 0 0 0 0 1 0\tflight_2\n",
      "\n",
      "what airlines that have flights arriving at airport HD .\t1 0 0 0 0 0 0 0 1 0\tflight_2\n",
      "\n",
      "which airlines have a flight with destination airport HD .\t0 0 0 0 0 0 0 0 1 0\tflight_2\n",
      "\n",
      "find out airlines that have flights from both airports , a PG and CBO .\t0 1 0 0 0 0 0 0 0 0 1 1 0 1 0\tflight_2\n",
      "\n",
      "which airlines have departing flights from both a PG and CBO airports .\t0 0 0 0 0 0 0 1 1 0 1 0 0\tflight_2\n",
      "\n",
      "find all airlines that have flights from airport CDO , but not from a PG .\t0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\tflight_2\n",
      "\n",
      "which airlines have departures from CBO but not from a PG airports .\t0 0 0 0 0 1 0 0 0 1 1 0 0\tflight_2\n",
      "\n",
      "find all airlines that have at least 10 flights .\t0 0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "which airlines have at least 10 flights .\t0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "find all airlines that have fewer than 200 flights .\t0 0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "which airlines have less than 200 flights .\t0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "what air flight numbers of airline United Airlines .\t0 1 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "which flight numbers correspond to United Airlines flights .\t0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "Twitter flight numbers of flights departing from airport A PG\t1 0 0 0 0 0 0 0 1 1\tflight_2\n",
      "\n",
      "give the flight numbers of flights leaving from a PG .\t0 0 0 0 0 0 0 0 1 1 0\tflight_2\n",
      "\n",
      "Twitter flight numbers of flights arriving at airports a PG\t1 0 0 0 0 0 0 1 1 1\tflight_2\n",
      "\n",
      "give the flight numbers of flights landing at a PG .\t0 0 0 0 0 0 0 0 1 1 0\tflight_2\n",
      "\n",
      "Twitter flight numbers of flights departing from city Aberdeen .\t1 0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "give the flight numbers of flights leaving from Aberdeen .\t0 0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "Twitter flight numbers of flights arriving at city Aberdeen .\t1 0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "give the flight numbers of flights arriving in Aberdeen .\t0 0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "find the number of flights landing in the city of Aberdeen or Abilene .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "how many flights land in Aberdeen or Abilene .\t0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "find the name of airports which do not have any flight in and out .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "which airports do not have departing or arriving flights .\t0 0 0 0 0 0 0 0 0 0\tflight_2\n",
      "\n",
      "how many employees are there ?\t0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "count the number of employees .\t0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "sort employee names by their age in ascending order .\t0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "list the names of employees and sword in ascending order of age .\t0 0 0 0 0 0 1 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "What is the number of employees from each city ?\t0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "count the number of employees for each city .\t0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "which cities do more than one employee under age 30 come from .\t0 0 0 0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "find the cities that have more than one employee under age 30 .\t0 0 0 0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "find the number of shops in each location .\t0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "how many shops are there in each location ?\t0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "find the manager name and district of the shop , whose number of products is the largest .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "what are the manager name and district of the shop that sells the largest number of products ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "find the minimum and maximum number of products of all stores .\t0 0 0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "what are the minimum and maximum number of products across all the shops ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "return the name , location and district of all shops in descending order of number of products .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "sort all the shops by number of products in descending order and return the name , location and district of each shop .\t0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "find the names of stores whose number products is more than the average number of products .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "which shops number products is above the average . Give me the shop names .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "find the name of employee who was awarded the most times in the evaluation .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "which employees received the most awards and evaluations Give me the employee name .\t0 1 0 0 0 0 1 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "find the name of the employees who got the highest one time bonus .\t0 0 0 0 0 1 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "which employees received the biggest bonus . Give me the employee name .\t0 1 0 0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "find the names of employees who never won any award in the evaluation .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "what are the names of the employees who never received any evaluation ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "what is the name of the shop that is hiring the largest number of employees ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "Which shop has the most employees ? Give me the shop name .\t0 0 0 0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "find the name of the shops that do not hire any employee .\t0 0 0 0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "which shops run with no employees , find the shop names .\t0 0 0 0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "find the number of employees hired Anethe shop show the shop name as well .\t0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "for each shop returned the number of employees working there in the name of the shop .\t0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "what is total bonus given in all evaluations .\t0 0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "find the total amount of bone is given in all the evaluations .\t0 0 0 0 0 1 1 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "give me all the information about hiring .\t0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "What is all the information about hiring ?\t0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "which district has both stores with less than 3000 products in stores with more than 10,000 products .\t0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\temployee_hire_evaluation\n",
      "\n",
      "find the district's , in which there are both shops selling less than 3000 products and shops selling more than 10,000 products .\t0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\temployee_hire_evaluation\n",
      "\n",
      "how many different store locations air there .\t0 0 0 0 0 1 0 0\temployee_hire_evaluation\n",
      "\n",
      "count the number of distinct store locations .\t0 0 0 0 0 0 0 0\temployee_hire_evaluation\n",
      "\n",
      "how many documents do we have ?\t0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "count the number of documents .\t0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "list documents , id's document names and document descriptions for all documents .\t0 1 0 1 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "What are the IDs ? Names and descriptions for all documents ?\t0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "What is the document ? Naming templates . I d for document with description with the letter W in it .\t0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "returned the names and template . It's for documents that contained the letter w in their description .\t1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "What is the document ? I d 10 put idea and description for document named Robin CV .\t0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "return the documents . I d template I d and description for the document with the name Robin CV .\t0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "how many different templates dual document use .\t0 0 0 0 1 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "count the number of different templates used for documents .\t0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "how many documents are using the template with type code PPT .\t0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "count the number of documents that use the P p T template type .\t0 0 0 0 0 0 0 0 1 1 1 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "show all template . It's a number of documents using each template .\t0 0 0 0 1 1 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "what are all different template is used for documents , and how many times were each of them used ?\t0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "what is the idea and type code for the template used by the most documents ?\t0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "return the idea and type code of the template that is used for the greatest number of documents .\t0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "showings for all templates that are used by more than one document .\t1 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "what are the template IDs of any templates used in more than a single document ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "show . It's for all templates not used by any document .\t0 0 1 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "what are the ? It's for templates that are not used in any documents .\t0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "how many templates do we have ?\t0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "count the number of templates .\t0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "show template IDs , version numbers and template type codes for all templates .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "what are the IDs ? Version numbers and type codes for each template .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "show all distinct template type coats for all templates .\t0 0 0 0 0 1 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "what are the different template type codes ?\t0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "What are the odds of templates with template type code P P or P P . T .\t0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "return the IDs of templates that have the code peop e or a P P T .\t0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "how many templates of temperate type code CV ?\t0 0 0 1 1 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "count the number of templates of the type CD .\t0 0 0 0 0 0 0 0 1 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "what is the version , number and template type code for the template , with version number later than five .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "return the version numbers and template type codes of templates with a version number greater than five .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "show all template type codes and number of templates for each .\t0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "what are the different template type codes and how many templates correspond to each ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "which template type coat his most number of templates .\t0 0 0 1 1 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "return the type code of the template type that the most templates belonged to .\t0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "show all template type coats with less than three templates .\t0 0 0 0 1 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "what are the coats of template types that have fewer than three templates ?\t0 0 0 1 0 0 0 0 0 0 0 1 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "with the smallest version number in its template type code .\t1 0 0 0 0 1 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "return the lowest version number along with its corresponding template type code .\t0 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "what is the template type code of the template used by document with the name database ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "returned the template type code of the template that is used by a document named Database .\t1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "show all document names using templates with template type code B K .\t0 0 0 0 0 0 0 0 0 0 1 1 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "What are the names of documents that use templates with the code B K .\t0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "show all template type codes in the number of documents using each type .\t0 0 0 0 0 1 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "what are the different template type codes and how many documents use each type ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "which template type code is used by most number of documents .\t0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "return the code of the template type that is most commonly used in documents .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "show all template type codes that are not used by any document .\t0 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "what are the coats of template types that are not used for any document ?\t0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "show all template type codes and descriptions .\t0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "whatever type codes and descriptions for all template types .\t1 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "What is the template type descriptions for template type code 80 .\t0 0 0 0 0 0 0 0 0 0 1 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "return the template type description of the template type of the code 80 .\t0 0 0 0 0 0 0 0 0 1 0 0 1 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "What is the template type code for template type description book .\t0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "returned the type code of the template type of the description book .\t1 0 0 0 0 0 0 0 1 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "what are the distinct template type descriptions for the templates ever used by any document ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "returned a different descriptions for templates that have been used in a document .\t1 1 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "what do the template ? It's with template type description , presentation .\t0 1 0 0 0 1 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "returning its corresponding to templates with the description presentation .\t1 1 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "how many paragraphs in total ?\t0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "count the number of paragraphs .\t0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "how many paragraphs for the document with named Summer Show ?\t0 0 0 0 0 0 0 1 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "count the number of paragraphs in the document named Summer Show .\t0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "show paragraph details for paragraph with text . Korea\t0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "whatever details for the paragraph that includes the text Korea .\t1 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "show all paragraph , it's and texts for the document with name Welcome to N . Y .\t0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "what are the odds and texts of paragraphs in the document titled Welcome to N . Y .\t0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "show all paragraph texts for the document customer reviews .\t0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "What are the paragraph texts for the document with the name customer reviews .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "show all documented in the number of paragraphs in each document order by document I . D .\t0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "returned a different document IDs , along with the number of paragraphs corresponding to each ordered by I . D .\t1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "show all document IDs , names in the number of paragraphs in each document .\t0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "what are the names of each document , as well as the number of paragraphs in each ?\t0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "list , all documented with at least two paragraphs .\t0 0 0 1 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "what are the odds of documents that have two or more paragraphs ?\t0 0 0 1 0 0 0 0 1 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "What is the document Idea ? Name with greatest number of paragraphs .\t0 0 0 0 1 1 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "return the idea name of the document with the most paragraphs .\t0 0 1 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "What is the document ? I d with least number of paragraphs .\t0 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "return the idea of the document with the fewest paragraphs .\t0 0 1 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "What is the document idea with 1 to 2 paragraphs .\t0 0 0 0 1 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "give the IDs of documents that have between one and two paragraphs .\t0 0 0 0 0 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "show the document idea with paragraph text . Brazil and Ireland .\t0 0 0 1 0 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "What are the odds of documents that contained the paragraph Text Brazil and Ireland .\t0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\tcre_Doc_Template_Mgt\n",
      "\n",
      "how many teachers are there ?\t0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "What is the total count of teachers ?\t0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "list the names of teachers in ascending order of age .\t0 0 0 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "What are the names of the teachers ordered by ascending age ?\t0 0 0 0 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "What are the agent ? Hometown of teachers ?\t0 0 0 1 1 0 0 0 0\tcourse_teach\n",
      "\n",
      "What is the agent ? Hometown of every teacher ?\t0 0 0 1 1 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "list the name of teachers whose hometown is not little lever Urban district .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "What are the names of the teachers whose hometown is not little ever urban district ?\t0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\tcourse_teach\n",
      "\n",
      "show the name of teachers aged either 32 or 33 .\t0 0 0 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "What are the names of the teachers who are aged either 32 or 33 ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "what is the hometown of the youngest teacher ?\t0 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "Where is the youngest teacher from ?\t0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "show different hometown of teachers in the number of teachers from each hometown .\t0 0 0 0 0 1 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "for each hometown . How many teachers are there ?\t0 0 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "list the most common hometown of teachers .\t0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "what is the most common hometowns for teachers ?\t0 0 0 0 1 0 0 0 0\tcourse_teach\n",
      "\n",
      "show the hometown shared by at least two teachers .\t0 0 1 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "What are the towns from which at least two teachers come from ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "show names of teachers in the courses they are arranged to teach .\t0 0 0 0 1 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "What is the name of each teacher and what course they teach ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "show names of teachers in the courses they arranged to teach in ascending alphabetical order of the teacher's name .\t0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0\tcourse_teach\n",
      "\n",
      "What are the names of the teachers and the courses they teach in ascending alphabetical order by the name of the teacher ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "show the name of the teacher for the math course .\t0 0 0 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "What are the names of the people who teach math courses ?\t0 0 0 0 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "show names of teachers in the number of courses they teach .\t0 0 0 0 1 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "What are the names of the teachers , and how many courses do they teach ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "show names of teachers that teach at least two courses .\t0 0 0 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "What are the names of the teachers who teach at least two courses ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "list the names of teachers who have not been arranged to teach courses .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "what are the names of the teachers whose courses have not been arranged ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tcourse_teach\n",
      "\n",
      "how many visitors below age 30 year there .\t0 0 0 0 0 0 1 0 0\tmuseum_visit\n",
      "\n",
      "find the names of the visitors whose membership level is higher than four and order the results by the level from Hyde Alot .\t0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0\tmuseum_visit\n",
      "\n",
      "what is the average age of the visitors , whose membership level is not higher than four ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tmuseum_visit\n",
      "\n",
      "find the name and membership level of the visitors , whose membership level is higher than four and sword by their age from old to young .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\tmuseum_visit\n",
      "\n",
      "find the idea name of the museum that has the most staff members .\t0 0 1 0 0 0 0 0 0 0 0 0 0 0\tmuseum_visit\n",
      "\n",
      "find the average number of staff working for the museums that were open before 2009 .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tmuseum_visit\n",
      "\n",
      "What are the opening year in staff number of the museum named Plaza Museum .\t0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\tmuseum_visit\n",
      "\n",
      "find the names of museums , which have more staff than the minimum staff . Number of all museums opened after 2010 .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tmuseum_visit\n",
      "\n",
      "find the I d . Name and age for visitors who visited some museums more than once .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tmuseum_visit\n",
      "\n",
      "what are the I D name and membership level of visitors who have spent the largest amount of money in total in all museum tickets ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tmuseum_visit\n",
      "\n",
      "What are the idea ? Name of the museum visited most times .\t0 0 0 1 1 0 0 0 0 0 0 0 0\tmuseum_visit\n",
      "\n",
      "What is the name of the museum that had no visitor yet ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\tmuseum_visit\n",
      "\n",
      "find the name and age of the visitor who bought the most tickets at once .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tmuseum_visit\n",
      "\n",
      "what are the average in maximum number of tickets spot in all visits .\t0 0 0 0 1 0 0 0 0 1 0 0 0 0\tmuseum_visit\n",
      "\n",
      "what is the total ticket expense of the visitors , whose membership level is one ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tmuseum_visit\n",
      "\n",
      "What is the name of the visitor who visited both ? The museum opened before 2009 and a museum opened after 2011 .\t0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\tmuseum_visit\n",
      "\n",
      "find the number of visitors who did not visit any museum opened after 2010 .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tmuseum_visit\n",
      "\n",
      "how many museums were opened after 2013 or before 2008 .\t0 0 0 0 0 0 0 0 0 0 0\tmuseum_visit\n",
      "\n",
      "find the total number of players .\t0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "how many players are there ?\t0 0 0 0 0 0\twta_1\n",
      "\n",
      "find the total number of matches .\t0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "count the number of matches .\t0 0 0 0 0 0\twta_1\n",
      "\n",
      "list the first name and birth date of all players from the country with code U . S . A .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0\twta_1\n",
      "\n",
      "What are the first names and birth dates of players from the U . S . A .\t0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0\twta_1\n",
      "\n",
      "find the average age of losers and winners of all matches .\t0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "what are the average ages of losers and winners across matches ?\t0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "find the average rank of winners in all matches .\t0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "what is the average rank for winners in all matches ?\t0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "find the highest rank of losers in all matches .\t0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "what is the best rank of losers across all matches ?\t0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "find the number of distinct country codes of all players .\t0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "how many distinct countries do players come from ?\t0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "find the number of distinct name of losers .\t0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "how many different lose their names are there ?\t0 0 0 1 1 0 0 0 0\twta_1\n",
      "\n",
      "find the name of Terni that has more than 10 matches .\t0 0 0 0 1 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "what are the names of tournaments that have more than 10 matches ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "list the names of all winners who played in both 2013 and 2016 .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "What are the names of players you want in both 2013 and 2016 ?\t0 0 0 0 0 0 1 1 0 0 0 0 0 0\twta_1\n",
      "\n",
      "list the number of all matches who played in years of 2013 or 2016 .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "how many matches were played in 2013 or 2016 .\t0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "What are the country code and first name of the players who won in both Attorney w th Championships in Australian Open .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0\twta_1\n",
      "\n",
      "what are the first names and country coats for players who won both the W th championships and the Australian Open ?\t0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0\twta_1\n",
      "\n",
      "find the first name and country code of the oldest player .\t0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "what is the first name and country code of the oldest player ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "list the first and last name of all players in the order of birthdate .\t0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\twta_1\n",
      "\n",
      "What are the full names of all players sorted by birth date ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "list the first and last name of all players who are left . L hand in the order of birth date .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "what other full names of all left handed players in order of birth date .\t0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "find the first name and country code of the player who did the most number of tours .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "what is the first name and country code of the player with the most tours ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "find the year that has the most number of matches .\t0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "which year had the most matches .\t0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "find the name and rank points of the winner who won the most times .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "What is the name of the winner who has won the most matches and how many rank points does this player have ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "find the name of the winner , who has the highest rank points and participated in the Australian Open tourney .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "what is the name of the winner with the most rank points who participated in the Australian Open tournament ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "find the names of looser and winner who played in the match with greatest number of minutes .\t0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "what are the names of the winner and loser who played in the longest match ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "find the average ranking for each player in their first name .\t0 0 0 0 0 0 0 1 0 0 0 0\twta_1\n",
      "\n",
      "what are the first names of all players and they're average rankings .\t0 0 0 0 0 0 0 0 0 1 0 0 0\twta_1\n",
      "\n",
      "find the total ranking points for each player in their first name .\t0 0 0 0 0 0 0 0 1 0 0 0 0\twta_1\n",
      "\n",
      "what are the first names of all players and they're total ranking points .\t0 0 0 0 0 0 0 0 0 1 0 0 0 0\twta_1\n",
      "\n",
      "find the number of players for each country .\t0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "how many players air from each country .\t0 0 0 1 0 0 0 0\twta_1\n",
      "\n",
      "find the code of the country . Where has the greatest number of players ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "What is the code of the country with the most players ?\t0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "find the coats of countries that have more than 50 players .\t0 0 1 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "what are the codes of countries with more than 50 players ?\t0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "find the total number of tours for each ranking date .\t0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "how many total tourists were there for each ranking date .\t0 0 0 1 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "find the number of matches happened in each year .\t0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "how many matches were played in each year .\t0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "find the name and rank of the three youngest winners across all matches .\t0 0 0 0 0 0 0 1 0 0 0 0 0 0\twta_1\n",
      "\n",
      "whatever names and ranks of the three youngest winners across all matches .\t1 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "how many different winners both participated in the W th championships and were left handed .\t0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\twta_1\n",
      "\n",
      "find the number of left handed winners who participated in the w th championships .\t0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\twta_1\n",
      "\n",
      "find the first name , country code and birth date of the winner , who has the highest rank points in all matches .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "what is the first name , country code and birth date of the player with the most winner rank points across all matches .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "find the number of players for each hand type .\t0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "how many players are there for each hand type ?\t0 0 0 0 0 0 0 0 0 0\twta_1\n",
      "\n",
      "how many ships ended up being captured .\t0 0 0 0 0 0 0 0\tbattle_death\n",
      "\n",
      "list the name and tonnage ordered by in descending alphabetical order for the names .\t0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\tbattle_death\n",
      "\n",
      "list the name , date and result of each battle .\t0 0 0 0 0 0 0 0 0 0 0\tbattle_death\n",
      "\n",
      "what is maximum and minimum death toll caused each time .\t0 0 0 0 0 0 0 0 0 0 0\tbattle_death\n",
      "\n",
      "what is the average number of injuries caused each time ?\t0 0 0 0 0 0 0 0 0 0 0\tbattle_death\n",
      "\n",
      "What are the death and injury situations caused by the ship with tonnage T .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tbattle_death\n",
      "\n",
      "whatever name and results of the battles when the Bulgarian commander is not boil .\t1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tbattle_death\n",
      "\n",
      "what are the different IDs and names of the battles that lost any breed type shapes ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\tbattle_death\n",
      "\n",
      "what are the names of the battles that led to more than 10 people killed in total ?\t0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tbattle_death\n",
      "\n",
      "What is the ship idea ? Name that caused most total injuries .\t0 0 0 0 1 1 0 0 0 0 0 0 0\tbattle_death\n",
      "\n",
      "What are the distinct battle names , which are between Bulgarian Commander Colleen and Latin commander Baldwin , the first .\t0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0\tbattle_death\n",
      "\n",
      "how many different results are there for the battles ?\t0 0 0 0 0 0 0 0 0 0\tbattle_death\n",
      "\n",
      "how many battles did not lose any ship with tonnage 225 .\t0 0 0 0 0 0 0 0 0 0 0 0\tbattle_death\n",
      "\n",
      "list the name and date the battle that has lost the ship named Lettuce in the ship named H . M S Atlanta .\t0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0\tbattle_death\n",
      "\n",
      "show names results in Bulgarian commanders of the battles , with no ships lost in the English Channel .\t0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tbattle_death\n",
      "\n",
      "What are the notes of the death events , which has sub string east ?\t0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\tbattle_death\n",
      "\n",
      "what are all the addresses , including Line one in line to .\t0 0 0 0 0 0 0 0 1 1 0 1 0\tstudent_transcripts_tracking\n",
      "\n",
      "what is the first and second line for all addresses ?\t0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "how many courses in total are listed .\t0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "how many courses air there ?\t0 0 0 1 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "How is the math course described ?\t0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What are the descriptions for all the math courses ?\t0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is the zip code of the address in the city ? Poor Chelsea ?\t0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is the ZIP code for poor Chelsea ?\t0 0 0 0 0 0 1 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "which department offers the most number of degrees list , department name and I . D .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "for each department . I d What is the name of the department with the most number of degrees ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "how many departments offer any degree .\t0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "how many different departments offer degrees .\t0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "how many different degree names are offered .\t0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "how many different degrees air offered .\t0 0 0 0 1 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "how many degrees does the engineering department offer ?\t0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "how many degrees does the engineering department have ?\t0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "whatever names and descriptions of all the sections .\t1 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "whatever names and descriptions for all the sections .\t1 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "whatever names and idea , of course , is having at most two sections .\t1 0 0 1 1 0 1 0 1 0 0 0 1 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "whatever names and deeds of every course with less than two sections .\t1 0 0 1 0 0 0 0 0 0 1 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "list the section Underscore name and reversed lexical graphical order .\t0 0 1 1 1 1 0 1 1 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What are the names of the sections in reverse Alphabetical order .\t0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is this semester ? Which most student registered in show ? Both the name and the I . D .\t0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "for each semester . What is the name ? An idea of the one with the most students registered .\t0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is the description of the department whose name has the sub string the computer ?\t0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is the department description for the one whose name has the word computer ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "who are enrolled in two degree programs in one semester . List the first name , middle name and last name on the I . D .\t0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "what are the first middle and last names , along with the IDs of all students who enrolled in two degree programs in one semester ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "who is enrolled in a bachelor degree program list the first name middle name , last name .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What are the first middle and last names for everybody enrolled in a bachelor's program ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "find the kind of program which most number of students are enrolled in .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is the degree ? Summary name that has the most number of students enrolled .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "find the program , which most number of students are enrolled in list , both the i D in the summary .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is the program I d in the summary of the degree that has the most students enrolled .\t0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "which student has enrolled for the most times in any program list . The I D first name Middle name , last name , the number of enrollments and student I . D .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "what is the first middle and last name , along with the idea number of enrollments for the student who enrolled the most in any program ?\t0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "which semesters do not have any student enrolled Liz the semester name .\t0 0 0 0 0 0 0 0 1 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is the name of the semester with no students enrolled ?\t0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "what are all the course names of the courses which ever have students enrolled in ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "whatever names of all courses that have some students enrolled .\t1 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "what's the name of the course with most number of enrollments ?\t1 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is the name of the course with the most students enrolled ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "find the last name of the students who currently live in the state of North Carolina but have not registered in any degree program .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "what are the last name of the students who live in North Carolina but have not registered in any degree programs ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "show the date and I d of the transcript with at least two course results .\t0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is the date ? An idea of the transcript with at least two courses listed .\t0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is the phone number of the men with the first name Timothy in the last name Ward ?\t0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is the mobile phone number of the student named Timothy Ward ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "who is the first student to register list the first name , middle name and last name .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "what is the first middle and last name of the first student ? The register .\t0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "who is the earliest graduate of the school list , the first name , middle name and last name .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "what is the first middle and last name of the earliest school graduate ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "whose permanent address is different from his or her current address list , his or her first name .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "what is the first name of the student whose permanent address is different from his or her current one ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "which address holds the most number of students currently . Lisbie address idea No lines .\t0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "what is the i d ? Line one and line two of the address with the most students .\t0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "on average when we're the transcripts printed .\t0 0 0 1 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is the average transcript ? Eight .\t0 0 0 0 1 0 1 0\tstudent_transcripts_tracking\n",
      "\n",
      "When is the first transcript released ? List the date and details .\t0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is the earliest date of the transcript release ? And what details can you tell me ?\t0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "how many transcripts are released .\t0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "how many transcripts are listed .\t0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is the last transcript released ? Eight .\t0 0 0 0 0 1 0 1 0\tstudent_transcripts_tracking\n",
      "\n",
      "When was the last transcript released ?\t0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "how many times at most can , of course , enrollment results show in different transcripts also show the course enrollment i . D .\t0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is the maximum number of times that , of course , shows up in different transcripts ? And what is that ? Courses ? Enrollment I . D .\t0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "show the date of the transcript , which shows the least number of results also list the idee .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is the date ? An idea of the transcript with the least number of results .\t0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "find the semester when both master students and bachelor students got enrolled in .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is the idea of the semester that had both masters and bachelor students enrolled ?\t0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "how many different addresses do the students currently live ?\t0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What are the different addresses that have students living there ?\t0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "list all the student details and reversed lexical graphical order .\t0 0 0 0 0 1 0 1 1 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "What other details can you tell me about students in reverse alphabetical order ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tstudent_transcripts_tracking\n",
      "\n",
      "describe the section age .\t0 0 0 1 0\tstudent_transcripts_tracking\n",
      "\n",
      "What is the description for the section named Age ?\t0 0 0 0 0 0 0 0 1 0\tstudent_transcripts_tracking\n",
      "\n",
      "find the first name of the students who permanently live in the country Haiti , or have the cell phone number 097 oo 166582\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\tstudent_transcripts_tracking\n",
      "\n",
      "What are the first names of the students who live in Haiti permanently ? Or have the cell phone number ? 097 OO 166582\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1\tstudent_transcripts_tracking\n",
      "\n",
      "list the title of all cartoons in alphabetical order .\t0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "What are the titles of the cartoons sorted alphabetically ?\t0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "list All cartoon Directed by Ben Jones .\t0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "What are the names of all cartoons ? Directed by Ben Jones ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "how many cartoons were written by Joseph Kir .\t0 0 0 0 0 0 0 1 0\ttvshow\n",
      "\n",
      "What is the number of cartoons written by Joseph Kir ?\t0 0 0 0 0 1 0 0 0 1 0\ttvshow\n",
      "\n",
      "list all cartoon titles in their director's ordered by the rare date .\t0 0 0 0 1 0 1 0 0 1 1 0 0\ttvshow\n",
      "\n",
      "what is the name and directors of all the cartoons that are ordered by air date ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "list the title of all cartoon , directed by Ben Jones or Brandon Vietti .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "What are the titles of all cartoons ? Directed by Ben Jones or Brandon Vietti ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "which country has the most of TV channels list the country and number of TV channels it has .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "What is the country with the most number of TV channels , and how many does it have ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "list the number of different Siri's names and contents in the TV Channel table .\t0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "how many different Siri's and contents are listed in the TV Channel table .\t0 0 0 1 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "what is the content of TV channel with cereal named Skye Radio ?\t0 0 0 0 0 0 0 0 1 1 1 0 0\ttvshow\n",
      "\n",
      "what is the content of the Siri's Sky Radio ?\t0 0 0 0 0 0 1 0 0 0\ttvshow\n",
      "\n",
      "What is the package option of TV channel with cereal named Skye Radio ?\t0 0 0 0 0 0 0 0 0 1 1 1 0 0\ttvshow\n",
      "\n",
      "What are the package options of the TV channels ? Who Siri's names are Sky Radio .\t0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\ttvshow\n",
      "\n",
      "how many TV channel using language English .\t0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "how many TV channels used the English language .\t0 0 0 0 1 0 0 0 0\ttvshow\n",
      "\n",
      "Mr Language , who's least number of TV channel list language , a number of TV channel .\t1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\ttvshow\n",
      "\n",
      "what are the language is used by the least number of TV channels and how many channels use it .\t0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "list teach language and the number of TV channels using it .\t0 1 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "for each language list the number of TV channels that use it .\t0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "What is the TV channel that shows the cartoon The rise of the Blue Beetle list , the TV channels , Siri's name ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\ttvshow\n",
      "\n",
      "what is the Siri's name of the TV channel that shows the cartoon the rise of the Blue Beetle ?\t0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "list , the title of all cartoons showed on TV channel with Siri's name Skye Radio .\t0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\ttvshow\n",
      "\n",
      "what is the title of all the car tools that are on the TV channel with the Siri's name Skye Radio ?\t0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0\ttvshow\n",
      "\n",
      "list the episode of All TV , Siri's sort it by rating .\t0 0 0 0 0 0 0 1 1 1 0 0 0\ttvshow\n",
      "\n",
      "what are all of the episodes ordered by ratings ?\t0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "List Top three highest rating . TV , Siri's List , the TV Syriza's episode and rating .\t0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0\ttvshow\n",
      "\n",
      "what are three most highly rated episodes in the TV series table , and what were those ratings ?\t0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "what is minimum and maximum share of TV series .\t0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "what is the maximum and minimum share for the TV series ?\t0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "What is the air date of TV series with Episode A Love of a Lifetime .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "When did the episode a love of a Lifetime air ?\t0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "what is weekly rank of TV series with Episode A Love of a Lifetime .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "What is the weekly rank for the episode ? A love of a lifetime .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "What is the TV channel of TV series with Episode A Love of a Lifetime list , the TV channels , Siri's name .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\ttvshow\n",
      "\n",
      "What is the name of the series that has the episode ? A love of a lifetime ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "list , the episode of All TV series showed on TV channel with Siri's name Skye Radio .\t0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\ttvshow\n",
      "\n",
      "what is the episode for the TV series named Skye Radio ?\t0 0 0 0 0 0 0 0 0 1 0 0\ttvshow\n",
      "\n",
      "find the number of cartoons directed by each of the listed directors .\t0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "how many cartoons did each director create ?\t0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "find the production code and channel of the most recently aired cartoon .\t0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "what is the production code and channel of the most recent cartoon ?\t0 0 0 1 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "find the package choice in Siri's name of the TV channel that has high definition TV .\t0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "what are the package options and the name of the series for the TV channel that supports high definition TV ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "which countries TV channels air playing some cartoon written by Todd Casey .\t0 0 0 0 1 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "What are the countries that have cartoons on TV that were written by Todd Casey ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "which countries TV channels are not playing any cartoon written by Todd Casey .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "What are the countries that are not playing ? Cartoons written by Todd Casey .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "find the Siri's name and country of the TV channel that is playing some cartoons . Directed by Ben Jones and Michael Chang .\t0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "what is the Siri's name in country of all TV channels that are playing cartoons , directed by Ben Jones and cartoons directed by Michael Chang .\t0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "find the pixel aspect ratio and nation of the TV channels that do not use English .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "what is the pixel aspect ratio and country of origin for all TV channels that do not use English ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "find idea of the TV channels that from the countries where have more than two TV channels .\t0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "what are the eggs of all TV channels that have more than two TV channels ?\t0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\ttvshow\n",
      "\n",
      "find the idea of TV channels that do not play any cartoon . Directed by Ben Jones .\t0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "What are the odds of the TV channels that do not have any cartoons ? Directed by Ben Jones .\t0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "find the package option of the TV channel that do not have any cartoon directed by Ben Jones .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "What are the package options of all TV channels that are not playing any cartoons ? Directed by Ben Jones .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\ttvshow\n",
      "\n",
      "how many poker players air there .\t0 0 0 0 1 0 0\tpoker_player\n",
      "\n",
      "count the number of poker players .\t0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "list the earnings of poker players in descending order .\t0 0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "What are the earnings of poker players order descending by value .\t0 0 0 0 0 0 0 1 0 0 0 0\tpoker_player\n",
      "\n",
      "list the final tables made in the best finishes of poker players .\t0 0 0 0 0 1 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "What are the final tables made in best finishes for all poker players ?\t0 0 0 0 0 0 1 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "What is the average earnings of poker players ?\t0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "return the average earnings across all poker players .\t0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "What is the money ? Rank of the poker player with the highest turnings ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tpoker_player\n",
      "\n",
      "returned the money rank of the player with the greatest turnings .\t1 0 0 0 0 0 0 0 0 0 1 0\tpoker_player\n",
      "\n",
      "what is the maximum number of final tables made among poker players with earnings less than 200,000 ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tpoker_player\n",
      "\n",
      "return the maximum final tables made across all poker players who have earnings below 200,000 .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tpoker_player\n",
      "\n",
      "What are the names of poker players ?\t0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "return the names of all the poker players .\t0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "whatever names of poker players whose earnings is higher than 300,000 .\t1 0 0 0 0 0 0 0 0 0 1 0\tpoker_player\n",
      "\n",
      "give the names of poker players who have earnings above 300,000 .\t0 0 0 0 0 0 0 0 0 0 1 0\tpoker_player\n",
      "\n",
      "list the names of poker players ordered by the final tables made in ascending order .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "What are the names of poker players order descending by the number of final tables they have made ?\t0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "what is the birth date of the poker player with the lowest turnings ?\t0 0 0 0 0 0 0 0 0 0 0 0 1 0\tpoker_player\n",
      "\n",
      "return the birth date of the poker player with the lowest turnings .\t0 0 0 0 0 0 0 0 0 0 0 1 0\tpoker_player\n",
      "\n",
      "What is the money rank of the tallest poker player ?\t0 0 0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "returned the money rank of the poker player with the greatest height .\t1 0 0 0 0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "what is the average earnings of poker players with Hyde higher than 200 ?\t0 0 0 0 0 0 0 0 0 1 0 0 0 0\tpoker_player\n",
      "\n",
      "give average earnings of poker players who are taller than 200 .\t0 0 0 0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "What are the names of poker players in descending order of earnings ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "returned the names of poker players sorted by , their earnings descending .\t1 0 0 0 0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "what a different nationalities of people in the corresponding number of people from each nation .\t0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "how many people are there of each nationality .\t0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "what is the most common nationality of people ?\t0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "give the nationality that is most common across all people .\t0 0 0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "what are the nationalities that are shared by at least two people ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "return the nationalities for which there are two or more people .\t0 0 0 0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "list the names and birth dates of people in ascending alphabetical order of name .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "what are the names and birth dates of people ordered by their names in alphabetical order ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "show names of people whose nationality is not Russia .\t0 0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "What are the names of people who are not from Russia ?\t0 0 0 0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "list the names of people that are not poker players .\t0 0 0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "What are the names of people who do not play poker ?\t0 0 0 0 0 0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "how many distinct nationalities air there .\t0 0 0 0 1 0 0\tpoker_player\n",
      "\n",
      "count the number of different nationalities .\t0 0 0 0 0 0 0\tpoker_player\n",
      "\n",
      "how many states are there ?\t0 0 0 0 0 0\tvoter_1\n",
      "\n",
      "list the contestant numbers and names ordered by contestant named Descending .\t0 0 0 0 0 0 0 0 0 1 0 0\tvoter_1\n",
      "\n",
      "list the vote IDs phone numbers in states of all votes .\t0 0 0 0 0 0 1 0 0 0 0 0\tvoter_1\n",
      "\n",
      "what do the maximum and minimum values of area codes ?\t0 1 0 0 0 0 0 0 0 0 0\tvoter_1\n",
      "\n",
      "what his last date created . A votes from the state C A .\t0 1 0 0 0 0 1 0 0 0 0 1 1 0\tvoter_1\n",
      "\n",
      "What are the names of the contestants whose names are not Jesse Ala Wai ?\t0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\tvoter_1\n",
      "\n",
      "what are the distinct states and create time of all votes .\t0 0 0 0 0 0 0 0 0 0 0 0\tvoter_1\n",
      "\n",
      "what are the contestant numbers and names of the contestants who had at least two boats ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tvoter_1\n",
      "\n",
      "of all the contestants who got voted , what is the contestant number and name of the contestant who got least votes ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tvoter_1\n",
      "\n",
      "What is the number of votes from state and why or c A .\t0 1 0 0 0 0 0 0 1 1 0 1 1 0\tvoter_1\n",
      "\n",
      "how many contestants did not get voted .\t0 0 0 0 0 0 0 0\tvoter_1\n",
      "\n",
      "what is the area code in which the most voters voted ?\t0 0 0 0 0 0 0 0 0 0 0 0\tvoter_1\n",
      "\n",
      "what do the create dates , states and phone numbers of the votes that were for the contestant named Tabatha gelling ?\t0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tvoter_1\n",
      "\n",
      "list the area codes in which voters voted both for the contestant Tabatha gelling in the contestant Kelly Kloss .\t0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0\tvoter_1\n",
      "\n",
      "return the names the contestants whose names contain the sub string al .\t0 0 0 0 0 0 0 0 0 1 1 0 0\tvoter_1\n",
      "\n",
      "What are the names of all the countries that became independent after 1950 ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "give the names of the nations that were founded after 1950 .\t0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "how many countries have the Republicans their form of government ?\t0 0 0 0 1 1 0 0 0 0 0\tworld_1\n",
      "\n",
      "how many countries have governments that are Republics .\t0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what is the total surface area of the countries in the Caribbean region ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "how much surface area do the countires in the Caribbean cover together ?\t0 0 0 0 0 0 0 0 0 1 0 0 0\tworld_1\n",
      "\n",
      "which continent is angrily in .\t0 0 0 1 0 0\tworld_1\n",
      "\n",
      "what is the continent name , which Anguilla belongs to ?\t0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "which region is the city Kabo located in ?\t0 0 0 0 0 1 0 0 0\tworld_1\n",
      "\n",
      "What region is Kabul in ?\t0 0 0 0 0 0\tworld_1\n",
      "\n",
      "which language is the most popular in Aruba .\t0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what language is predominantly spoken in Aruba .\t0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "What are the population in life expectancies in Brazil ?\t0 0 0 0 1 0 0 0 0 0\tworld_1\n",
      "\n",
      "give me Brazil's population and life expectancies .\t0 0 1 0 0 0 0 0\tworld_1\n",
      "\n",
      "What are the region in population of Angola ?\t0 0 0 0 1 0 0 0 0\tworld_1\n",
      "\n",
      "what region does Angola belong to and what is its population ?\t0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what is the average expected life expectancy for countries in the region of central Africa ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "How long is the people's average life expectancy in central Africa ?\t0 0 0 0 1 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what is the name of country that has the shortest life expectancy in Asia ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "give the name of the country in Asia with the lowest life expectancy .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what is the total population and maximum GNP in Asia ?\t0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "how many people live in Asia and what is the largest GNP among them .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what is the average life expectancy in African countries that are Republics ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "give the average life expectancy for countries in Africa , which are Republics .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what is the total surface area ? The continents , Asia and Europe ?\t0 0 0 0 0 0 1 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "give the total surface area covered by countries in Asia or Europe .\t0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "how many people live in Gelderland District ?\t0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "What is the total population of Gelderland District ?\t0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "What is the average GNP in total population in all nations whose government is U . S territory ?\t0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0\tworld_1\n",
      "\n",
      "give the mean GNP and total population of nations which are considered US territory .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "how many unique languages are spoken in the world .\t0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what is the number of distinct languages used around the world ?\t0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "how many type of governments are in Africa .\t0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "how many different forms of governments are there in Africa .\t0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "What is the total number of languages used in Aruba ?\t0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "how many languages are spoken in Aruba .\t0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "how many official languages does Afghanistan have ?\t0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "how many official languages are spoken in Afghanistan .\t0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what his name of the country that speaks the largest number of languages .\t0 1 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "give the name of the nation that uses the greatest amount of languages .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "which continent has the most diverse languages .\t0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "which continent speaks the most languages .\t0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "how many countries speak both English and Dutch .\t0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what is the number of nations that use English and Dutch ?\t0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what are the names of nations ? Speak both English and French ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "give the names of nations that speak both English and French .\t0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what are the names of nations were both English and French are official languages .\t0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "give the names of countries with English and French is official languages .\t0 0 0 0 0 0 0 0 0 1 0 0 0\tworld_1\n",
      "\n",
      "what is the number of distinct continents where Chinese has spoken ?\t0 0 0 0 0 0 0 0 0 1 0 0\tworld_1\n",
      "\n",
      "how many continents speak Chinese .\t0 0 0 0 0 0\tworld_1\n",
      "\n",
      "What are the regions that use English or Dutch ?\t0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "which region ? Speak that your English .\t0 1 0 0 1 1 0 0\tworld_1\n",
      "\n",
      "what are the countries where either English or Dutch is the official language ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "which countries have either English or duchess , an official language .\t0 0 0 0 0 0 1 1 0 0 0 0\tworld_1\n",
      "\n",
      "which language is the most popular on the Asian continent .\t0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what is the language that is used by the largest number of Asian nations ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "which languages air spoken by only one country in republic governments .\t0 0 1 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what languages are only used by a single country with a republic government .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "find the city with the largest population that uses English .\t0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what is the most populous city that speaks English ?\t0 0 0 0 1 0 0 0 0 0\tworld_1\n",
      "\n",
      "find the name population and expected life length of Asian country with the largest area .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what is the name , population and life expectancy of the largest Asian country by land ?\t0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what is average life expectancy in the countries where English is not the official language ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "give the mean life expectancy of countries in which English is not the official language .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what is the total number of people living in the nations that do not use English ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "how many people live in countries that do not speak English .\t0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "What is the official language spoken in the country , Whose head of state is Beatrix ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "What is the official language used in the country ? The name of who's head of state is via tricks .\t0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\tworld_1\n",
      "\n",
      "what is the total number of unique official languages spoken in the countries that are founded before 1930 ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "for the country's founded before 1930 . What is the total number of distinct official languages ?\t0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what are the countries that have greater surface area than any country in Europe ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "which countries have greater area than that of any country in Europe .\t0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what are the African countries that have a population less than any country in Asia ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "which African countries have a smaller population than that of any country in Asia .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "which Asian countries have a population that is larger than any country in Africa .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what are the Asian countries which have a population larger than that of any country in Africa ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "What are the country codes for countries that do not speak English ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "return the country codes for countries that do not speak English .\t0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what are the country codes of countries where people use languages other than English ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "give the country codes for countries in which people speak land gauges that are not English .\t0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\tworld_1\n",
      "\n",
      "what are the coats of the countries that do not speak English and whose government forms are not republic ?\t0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "return the coats of countries that do not speak English and do not have Republics for governments .\t0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "which cities are in European countries where English is not the official language .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what are the names of cities in Europe for which English is not the official language ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "which unique cities are in Asian countries , where Chinese is the official language .\t1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "return the different names of cities that are in Asia and for which Chinese is the official language .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what is the name , independence year and surface area of the country with the smallest population .\t0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "give the name year of Independence and surface area of the country that has the lowest population .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what is the population name and leader of the country with the largest area ?\t0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "give the name , population and head of state for the country that has the largest area .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "return the country name and the numbers of languages spoken for each country that speaks at least three languages .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\tworld_1\n",
      "\n",
      "what are the names of countries that speak more than two languages , as well as how many languages they speak ?\t0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "find the number of cities in each district whose population is greater than the average population of cities .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "how many cities in each district have a population that is above the average population across all cities .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "find the government form , name and total population for each government form whose average life expectancy is longer than 72 .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what are the different government forms in what is the total population of each for government forms that have an average life expectancy greater than 72 ?\t0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "find the average life expectancy in total population for each continent , where the average life expectancy is shorter than 72 .\t0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "What are the different continents in the total population ? An average life expectancy corresponding to each four continents that have an average life expectancy less than 72 ?\t0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what are the names and areas of countries with the top five largest area ?\t0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\tworld_1\n",
      "\n",
      "returned the names and service areas of the five largest countries .\t1 0 0 0 1 0 0 0 1 0 0 0\tworld_1\n",
      "\n",
      "what are names of countries with the top three largest population .\t0 0 0 0 0 0 0 0 1 0 0 0\tworld_1\n",
      "\n",
      "returned the names of the three most populated countries .\t1 0 0 0 0 1 0 0 0 0\tworld_1\n",
      "\n",
      "what are the names of the nations with the three lowest populations ?\t0 0 0 0 0 0 0 0 0 1 0 0 0\tworld_1\n",
      "\n",
      "returned the names of the three countries with the fewest people .\t1 0 0 0 0 1 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "how many countries are in Asia .\t0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "count the number of countries in Asia .\t0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what are the names of the countries that are in the continent of Europe and have a population of 80,000 ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tworld_1\n",
      "\n",
      "give the names of countries that are in Europe and have a population equal to 80,000 .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tworld_1\n",
      "\n",
      "what is the total population ? An average area of countries in the continent of North America whose area is bigger than 3000 .\t0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\tworld_1\n",
      "\n",
      "give the total population and average surface area corresponding to countries in North America that have a surface area greater than 3000 .\t0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what are the cities whose population is between 160,000 and 900,000 .\t0 0 0 0 0 0 0 0 1 0 1 0\tworld_1\n",
      "\n",
      "return the names of cities that have a population between 160,000 and 900,000 .\t0 0 0 0 0 0 0 0 0 0 1 0 1 0\tworld_1\n",
      "\n",
      "which languages spoken by the largest number of countries .\t0 1 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "give the language that is spoken in the most countries .\t0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "What is the language spoken by the largest percentage of people in each country ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what are the country codes of the different countries and whether the languages spoken by the greatest percentage of people for each .\t0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what is the total number of countries where Spanish is spoken by the largest percentage of people ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "count the number of countries for which Spanish is the predominantly spoken language .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "what are the codes of countries were Spanish is spoken by the largest percentage of people .\t0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "return the coats of countries for which Spanish is the predominantly spoken language .\t0 0 1 0 0 0 0 0 0 0 0 0 0 0\tworld_1\n",
      "\n",
      "how many conductors air there .\t0 0 0 1 0 0\torchestra\n",
      "\n",
      "count the number of conductors .\t0 0 0 0 0 0\torchestra\n",
      "\n",
      "list the names of conductors in ascending order of age .\t0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "What are the names of conductors ordered by age ?\t0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "What are the names of conductors whose nationalities air not U . S . A .\t0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0\torchestra\n",
      "\n",
      "return the names of conductors that do not have the Nationality USA .\t0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "What are the record companies of orchestras in descending order of years in which they were founded ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "returned the record companies of orchestras sort of descending by the years in which they were founded .\t1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "What is the average attendance of shows ?\t0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "return the average attendance across all shows .\t0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "what are the maximum and minimum share of performances whose type is not live final .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "return the maximum and minimum shares for performances that do not have the type live final .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "how many different nationalities do conductors has ?\t0 0 0 0 0 0 1 0\torchestra\n",
      "\n",
      "count the number of different nationalities of conductors .\t0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "list names of conductors in descending order of years of work .\t0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "What are the names of conductors ? Sort of descending by the number of years they have worked .\t0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "list the name of the conductor with the most years of work .\t0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "What is the name of the conductor who has worked the greatest number of years ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "show the names of conductors and the orchestra's they have conducted .\t0 0 0 0 0 0 0 1 0 0 0 0\torchestra\n",
      "\n",
      "what are the names of conductors , as well as the chorus sounding orchestras that they have conducted ?\t0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\torchestra\n",
      "\n",
      "show the names of conductors that have conducted more than one orchestras .\t0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "What are the names of conductors who have conducted at more than one orchestra ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "show the name of the conductor that has conducted the most number of orchestras .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "What is the name of the conductor who has conducted the most orchestras ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "please show the name of the conductor that has conducted orchestras founded after 2008 .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "What are the names of conductors who have conducted orchestras founded after the year 2008 ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "please show the different record companies and the corresponding number of orchestras .\t0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "how many orchestras does each record company manage ?\t0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "please show the record for Mets of orchestras in ascending order of count .\t0 0 0 0 1 1 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "What are the major record for mets of orchestras sorted by their frequency ?\t0 0 0 0 0 1 1 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "list , the record company shared by the most number of orchestras .\t0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "What is the record company used by the greatest number of orchestras ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "list the names of orchestras that have no performance .\t0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "what are the orchestra's that do not have any performances ?\t0 0 0 1 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "show the record companies shared by orchestras founded before 2003 and after 2003 .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "what are the record companies that are used by both orchestras founded before 2003 and those founded after 2003 ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "find the number of orchestras whose record for Mattis CD or DVD .\t0 0 0 0 0 0 0 1 1 0 0 0 0\torchestra\n",
      "\n",
      "count the number of orchestras that have CD or DVD is their record format .\t0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\torchestra\n",
      "\n",
      "show the years in which orchestras that have given more than one performance are founded .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "what a years of founding for orchestras that have had more than a single performance .\t0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\torchestra\n",
      "\n",
      "how many high schoolers air there .\t0 0 0 0 1 0 0\tnetwork_1\n",
      "\n",
      "count the number of high schoolers .\t0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "show the names and grades of each high schooler .\t0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "What are the names and grades for each high schooler ?\t0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "show all the grades of the high schoolers .\t0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "What is the great of each high schooler ?\t0 0 0 1 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "What Greatest Cailan ?\t0 1 1 0\tnetwork_1\n",
      "\n",
      "returned the great for the high schooler named Kyle .\t1 0 1 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "show the names of all high schoolers in Grade 10 .\t0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "What are the names of all high schoolers in Grade 10 ?\t0 0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "show the idea of the high schooler named Kyle .\t0 0 1 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "What is Kyle's idee ?\t0 0 1 1 0\tnetwork_1\n",
      "\n",
      "how many high schoolers are there in grade nine or 10 ?\t0 0 0 0 0 0 0 0 1 0 0 0\tnetwork_1\n",
      "\n",
      "count the number of high schoolers ingrates nine or 10 .\t0 0 0 0 0 0 1 1 0 0 0\tnetwork_1\n",
      "\n",
      "show the number of high schoolers for each grade .\t0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "how many high schoolers Aaron each grade .\t0 0 0 0 1 0 0 0\tnetwork_1\n",
      "\n",
      "which grade has the most high schoolers .\t0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "return the grade that has the greatest number of high schoolers .\t0 0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "show me l grades that have at least four students .\t0 0 1 0 0 0 0 0 1 0 0\tnetwork_1\n",
      "\n",
      "which grades have four more high schoolers .\t0 0 0 1 0 0 0 0\tnetwork_1\n",
      "\n",
      "show the student ID's and numbers of friends corresponding to each .\t0 0 0 1 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "how many friends does each student have ?\t0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "show the names of high school students and their corresponding number of friends .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "What are the names of the high schoolers , and how many friends does he have ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\tnetwork_1\n",
      "\n",
      "What is the name of the high schooler who has the greatest number of friends ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "returned the name of the high school student with the most friends .\t1 0 0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "show the names of high schoolers who have at least three friends .\t0 0 0 0 0 0 0 0 0 0 1 0 0\tnetwork_1\n",
      "\n",
      "What are the names of high schoolers who have three or more friends ?\t0 0 0 0 0 0 0 0 0 1 0 0 0 0\tnetwork_1\n",
      "\n",
      "show the names of all of the high schooler Kyle's friends .\t0 0 0 0 0 0 0 0 0 1 0 0\tnetwork_1\n",
      "\n",
      "return the names of friends of a high school student , Kyle .\t0 0 0 0 0 0 1 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "how many friends does the high school student Kyle have ?\t0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "count the number of friends Kyle has .\t0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "show . It's of all students who do not have any friends .\t0 0 1 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "What are the odds of high school students who do not have friends ?\t0 0 0 1 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "show names of all high school students who do not have any friends .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "whatever names of students who have no friends .\t1 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "show the IDs of high schoolers who have friends and are also liked by someone else .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "what are the odds of students who both have friends and are liked ?\t0 0 0 1 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "show name of all students who have some friends and also are liked by someone else .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "What are the names of high schoolers who both have friends in our life ?\t0 0 0 0 0 0 0 0 0 0 0 1 1 1 0\tnetwork_1\n",
      "\n",
      "count the number of likes for each student i d .\t0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "how many likes correspond to each student , i d .\t0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "show the names of high schoolers who have likes and numbers of Lex for each .\t0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\tnetwork_1\n",
      "\n",
      "what are the names of high schoolers who have likes and how many likes does each have .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "What is the name of the high schooler who has the greatest number of likes ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "give the name of the student with the most likes .\t0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "show the names of students who have at least two likes .\t0 0 0 0 0 0 0 0 0 1 0 0\tnetwork_1\n",
      "\n",
      "whatever names of students who have two or more likes .\t1 0 0 0 0 0 1 0 0 0 0\tnetwork_1\n",
      "\n",
      "show the names of students who have a great higher than five and have at least two friends .\t0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0\tnetwork_1\n",
      "\n",
      "What are the names of high schoolers who have a great of over five and have two or more friends ?\t0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0\tnetwork_1\n",
      "\n",
      "how many likes disk I'll have .\t0 0 0 1 1 0 0\tnetwork_1\n",
      "\n",
      "return the number of likes that the high schooler named Kyle has .\t0 0 0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "find the average grade of all students who have some friends .\t0 0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "what is the average grade of students who have friends ?\t0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "find the minimum grade of students who have no friends .\t0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "what is the lowest grade of students who do not have any friends ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tnetwork_1\n",
      "\n",
      "which states have both owners and professionals living there .\t0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "find the states where both owners and professionals live .\t0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "what is the average age of the dogs who have gone through any treatments ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "find the average age of the dogs who went through treatments .\t0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "which professionals live in the state of Indiana or have done treatment on more than two treatments , List his or her i d last name and cell phone .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "find the I . D last name and cell phone of the professionals who live in the state of Indiana or have performed more than two treatments .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "which dogs have not cost their own or more than 1000 for treatment mist the dog names .\t0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0\tdog_kennels\n",
      "\n",
      "What are the names of the dogs for which the owner spent more than 1000 for treatment ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "which first names air used for professionals or owners but are not used as duck names .\t0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0\tdog_kennels\n",
      "\n",
      "find the first names that are used for professionals or owners but are not used his dog names .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\tdog_kennels\n",
      "\n",
      "which professional did not operate any treatment on dogs , list the professionals i . D . Roland email .\t0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\tdog_kennels\n",
      "\n",
      "give me the I d Roll , an email of the professionals who did not perform any treatment on dogs .\t0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "which owner owns the most dogs list the owner i d first name and last name .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "return the owner i d first name and last name of the owner who has the most dogs .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "which professionals have done at least two treatments . List the professionals I d Roll and first name .\t0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\tdog_kennels\n",
      "\n",
      "what are the I d roll and first name of the professionals who have performed two or more treatments ?\t0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "What is the name of the breed with the most dogs ?\t0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "which for you do the most dogs has give me the breed name .\t0 1 1 0 0 0 0 1 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "which owner has paid for the most treatments on his or her dog's list . The owner , Adi and last name .\t0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\tdog_kennels\n",
      "\n",
      "tell me , the owner , Raidi and last name of the owner who spent the most on treatments of his or her dogs .\t0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "what is the description of the treatment type that costs the least money in total ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "give me the description of the treatment type whose total cost is the lowest .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "which owner has paid the largest amount of money in total for their dogs ,\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\tdog_kennels\n",
      "\n",
      "find the owner i D and zip code of the owner who spent the most money in total for his or her dogs .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "which professionals have done at least two types of treatments .\t0 0 0 0 0 0 0 0 0 1 0\tdog_kennels\n",
      "\n",
      "find the idea and cell phone of the professionals who operate two or more types of treatments .\t0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "what are the first name and last name of the professionals who have done treatment with costs below average ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\tdog_kennels\n",
      "\n",
      "which professionals have operated a treatment that costs less than the average Give me thier first names and last names .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "list the date of each treatment together with the first name of the professional who operated it .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "whatever date in the operating professionals first name of each treatment .\t1 0 1 0 0 1 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "list the cost of each treatment in the corresponding treatment type description .\t0 0 0 0 0 0 1 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "what is the cost and treatment type description of each treatment ?\t0 1 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "list each owner's first name , last name and the size of his for her dog .\t0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "what are each owner's first name , last name and the size of their dog ?\t0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "list pairs of the owners first name in the dog's name .\t0 0 0 0 1 0 0 1 0 1 0 0\tdog_kennels\n",
      "\n",
      "what are each owner's first name and their dog's name ?\t0 0 0 1 0 0 0 0 1 0 0\tdog_kennels\n",
      "\n",
      "list the names of the dogs of the rarest breed in the treatment dates of them .\t0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "which dogs air of the rarest breed show their names and treatment dates .\t0 0 1 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "which dogs are owned by someone who lives in Virginia , list the owner's first name and the dog's name .\t0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\tdog_kennels\n",
      "\n",
      "find the first names of owners living in Virginia and the names of dogs they own .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "What are the arriving date in the departing date of the dogs who have gone through a treatment ?\t0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "find the arriving data and the departing date of the dogs that received the treatment .\t0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0\tdog_kennels\n",
      "\n",
      "list , the last name of the owner owning the youngest dog .\t0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "who owns the youngest dog . Give me his or her last name .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "list the e mails of the professionals who live in the state of Hawaii or the state of Wisconsin .\t0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "What are the e mails that the professionals living in either the state of Hawaii or the state of Wisconsin ?\t0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "What are the arriving date in the departing date of all the dogs ?\t0 0 0 0 0 1 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "list the arrival date in the departure date for all the dogs .\t0 0 0 0 1 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "how many ducks went through any treatments .\t0 0 1 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "count the number of dogs that went through a treatment .\t0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "how many professionals have performed any treatment to dogs .\t0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "find the number of professionals who have ever treated dogs .\t0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "which professionals live in a city containing the sub string West missed his or her role street , city and state .\t0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "find the role street city and state of the professionals living in a city that contains the sub string west .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\tdog_kennels\n",
      "\n",
      "which owners live in the state whose name contains the sub string North list , his first name , last name and email .\t0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "return the first name last name and email of the owner's living in a state whose name contains the sub string north .\t0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0\tdog_kennels\n",
      "\n",
      "how many dogs have an age below the average .\t0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "count the number of dogs of an age below the average .\t0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "how much does the most recent treatment cost ?\t0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "show me the cost of the most recently performed treatment .\t0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "how many dogs have not gone through any treatment .\t0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "tell me the number of ducks that have received any treatment .\t0 0 0 0 0 1 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "how many owners temporarily do not have any dogs .\t0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "find the number of owners who do not own any dogs at this moment .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "how many professionals did not operate any treatment on dogs .\t0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "find the number of professionals who have not treated any dogs .\t0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "list the dog name , age and weight of the dogs who have been abandoned . One stands for yes and zero stands for now .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0\tdog_kennels\n",
      "\n",
      "What are the dog name ? Age and weight of the dogs that were abandoned ? Note that one stands for yes , and zero stands for no in the tables .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "What is the average age of all the dogs ?\t0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "compute the average age of all the dogs .\t0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "What is the age of the oldest dog ?\t0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "tell me the age of the oldest dog .\t0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "How much does each charge type costs list both charge type and amount .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "Let's teach charge type in its amount .\t1 1 0 0 1 0 0 0\tdog_kennels\n",
      "\n",
      "how much does the most expensive charge type costs ?\t0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "What is the charge ? Amount of the most expensive charge type .\t0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "list the email , cell phone and home phone of all the professionals .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "What are the email , cell phone and home phone of each professional ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "what are all the possible breed type and size type combinations ?\t0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "find the distinct breed type and size type combinations for dogs .\t0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "lives the first name of all the professionals , along with the description of the treatment they have done .\t1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "what are each professionals ? First name and description of the treatment they have performed .\t0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\tdog_kennels\n",
      "\n",
      "how many singers air there .\t0 0 0 1 0 0\tsinger\n",
      "\n",
      "What is the count of singers ?\t0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "list the name of singers in ascending order of net worth .\t0 0 0 0 0 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "What are the names of singers ordered by ascending that worth ?\t0 0 0 0 0 0 0 0 0 1 0 0\tsinger\n",
      "\n",
      "what are the birth year and citizenship of singers ?\t0 0 0 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "What are the birth years and citizenships of the singers ?\t0 0 0 0 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "list the name of singers whose citizenship is not France .\t0 0 0 0 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "What are the names of the singers who are not French citizens ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "show the name of singers whose birth years either 1948 or 1949 .\t0 0 0 0 0 0 0 1 0 0 0 0 0\tsinger\n",
      "\n",
      "What are the names of the singers whose birth years are either 1948 or 1949 ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "What is the name of the singer with the largest net worth ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "What is the name of the singer who is worth the most ?\t0 0 0 0 0 0 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "show different citizenship of singers in the number of singers of each citizenship .\t0 0 0 0 0 1 0 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "for each citizenship . How many singers air from that country ?\t0 0 0 0 0 0 0 1 0 0 0 0\tsinger\n",
      "\n",
      "please show the most common citizenship of singers .\t0 0 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "What is them ? Sit common singer citizenship .\t0 0 1 0 1 0 0 0 0\tsinger\n",
      "\n",
      "show different citizenships and the maximum networth of singers of each citizenship .\t0 0 0 0 0 0 1 0 0 0 0 0 0\tsinger\n",
      "\n",
      "for each citizenship . What is the maximum net worth ?\t0 0 0 0 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "show titles of songs and names of singers .\t0 0 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "What are the song titles in singer names ?\t0 0 0 0 0 1 0 0 0\tsinger\n",
      "\n",
      "show distinct names of singers that have songs with sales more than 300,000 .\t0 0 0 0 0 0 0 0 0 0 0 0 1 0\tsinger\n",
      "\n",
      "What are the different names of the singers that have sales more than 300,000 ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\tsinger\n",
      "\n",
      "show the names of singers that have more than one song .\t0 0 0 0 0 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "What are the names of the singers that have more than one songs ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "show the names of singers in the total sales of their songs .\t0 0 0 0 0 1 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "for each singer name . What is the total sales for their songs ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "list the name of singers that do not have any song .\t0 0 0 0 0 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "What is this name of everything that does not have any song ?\t0 0 1 1 0 1 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "show the citizenship shared by singers with birth year before 1945 and after 1955 .\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "What do the citizen ships that are shared by singers with the birth year before 1945 and after 1955 ?\t0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\tsinger\n",
      "\n",
      "how many available features are there in total .\t0 0 0 0 0 0 0 0 0\treal_estate_properties\n",
      "\n",
      "What is the feature type name of feature aircon ?\t0 0 0 0 0 0 0 0 0 0\treal_estate_properties\n",
      "\n",
      "show the property type descriptions of properties belonging to that code .\t0 0 0 0 0 0 0 0 0 0 0 0\treal_estate_properties\n",
      "\n",
      "what are the names of properties that are either houses or apartments with more than one room ?\t0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\treal_estate_properties\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.join('/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my', 'dev')\n",
    "question_diff_fname = os.path.join(dir_path, 'questions_diff_tags.txt')\n",
    "db_id_fname = os.path.join(dir_path, 'db_id.txt')\n",
    "\n",
    "with open(question_diff_fname, 'r') as f1, open(db_id_fname, 'r') as f2:\n",
    "    for l1, l2 in zip(f1, f2):\n",
    "        print(l1.strip() + '\\t' + l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack([np.array(1), np.array(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'a' : 1}\n",
    "b = {'b' : 2}\n",
    "a.update(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(slice(0, 68, None), slice(0, 0, None))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple([slice(0, x) for x in (68, 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.LongTensor(np.array([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "]))\n",
    "a.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_reader': {'type': 'spider_ASR_reranker_reader_v2',\n",
       "  'token_indexers': {'bert': {'type': 'bert-pretrained',\n",
       "    'pretrained_model': 'bert-buncased'}},\n",
       "  'tables_json_fname': 'SPIDER_DIR/tables.json',\n",
       "  'dataset_reranker_dir': 'SPIDER_DIR/my',\n",
       "  'max_sequence_len': 300,\n",
       "  'debug': True}}"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads('{\"dataset_reader\": {\"type\": \"spider_ASR_reranker_reader_v2\", \"token_indexers\": {\"bert\": {\"type\": \"bert-pretrained\", \"pretrained_model\": \"bert-buncased\"}}, \"tables_json_fname\": \"SPIDER_DIR/tables.json\", \"dataset_reranker_dir\": \"SPIDER_DIR/my\", \"max_sequence_len\": 300, \"debug\": true}}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('predicts', 26744),\n",
       " ('original_dev', 9032),\n",
       " ('eval_ids', 4856),\n",
       " ('eval_score_pairs', 4856),\n",
       " ('golds', 4856),\n",
       " ('hyp_list', 4856),\n",
       " ('ref_list', 4856),\n",
       " ('Activation', 1064),\n",
       " ('Attention', 1064),\n",
       " ('BasicTextFieldEmbedder', 1064),\n",
       " ('BertConfig', 1064),\n",
       " ('BertModel', 1064),\n",
       " ('BertPreTrainedModel', 1064),\n",
       " ('BertTokenizer', 1064),\n",
       " ('BucketBatchSampler', 1064),\n",
       " ('CategoricalAccuracy', 1064),\n",
       " ('CnnEncoder', 1064),\n",
       " ('CosineMatrixAttention', 1064),\n",
       " ('DataLoader', 1064),\n",
       " ('DatasetReader', 1064),\n",
       " ('Embedding', 1064),\n",
       " ('GradientDescentTrainer', 1064),\n",
       " ('LinearMatrixAttention', 1064),\n",
       " ('MSELoss', 1064),\n",
       " ('MatrixAttention', 1064),\n",
       " ('MeanAbsoluteError', 1064),\n",
       " ('Model', 1064),\n",
       " ('ModuleList', 1064),\n",
       " ('Params', 1064),\n",
       " ('Predictor', 1064),\n",
       " ('PretrainedTransformerEmbedder', 1064),\n",
       " ('PretrainedTransformerMismatchedEmbedder', 1064),\n",
       " ('PytorchSeq2SeqWrapper', 1064),\n",
       " ('PytorchSeq2VecWrapper', 1064),\n",
       " ('SentenceTaggerPredictor', 1064),\n",
       " ('Seq2SeqEncoder', 1064),\n",
       " ('Seq2SeqPredictor', 1064),\n",
       " ('Seq2VecEncoder', 1064),\n",
       " ('SimpleSeq2Seq', 1064),\n",
       " ('SingleIdTokenIndexer', 1064),\n",
       " ('SpeakQLEncoderV1', 1064),\n",
       " ('SpiderASRRerankerPredictor', 1064),\n",
       " ('SpiderASRRerankerPredictor_Siamese', 1064),\n",
       " ('SpiderASRRerankerReaderV1', 1064),\n",
       " ('SpiderASRRerankerReaderV2', 1064),\n",
       " ('SpiderASRRerankerReaderV2_Siamese', 1064),\n",
       " ('SpiderASRRerankerV0', 1064),\n",
       " ('SpiderASRRerankerV1', 1064),\n",
       " ('SpiderASRRerankerV2', 1064),\n",
       " ('SpiderASRReranker_Siamese', 1064),\n",
       " ('Table', 1064),\n",
       " ('TableColumn', 1064),\n",
       " ('TextFieldEmbedder', 1064),\n",
       " ('TokenEmbedder', 1064),\n",
       " ('TokenIndexer', 1064),\n",
       " ('Tqdm', 1064),\n",
       " ('Vocabulary', 1064),\n",
       " ('ArrayField', 896),\n",
       " ('Instance', 896),\n",
       " ('ListField', 896),\n",
       " ('MetadataField', 896),\n",
       " ('SequenceLabelField', 896),\n",
       " ('TextField', 896),\n",
       " ('Token', 896),\n",
       " ('defaultdict', 400),\n",
       " ('hyp', 232),\n",
       " ('f', 224),\n",
       " ('ref', 200),\n",
       " ('EvaluateSQL', 144),\n",
       " ('cached_path', 144),\n",
       " ('corpus_bleu', 144),\n",
       " ('dbToTokens', 144),\n",
       " ('extractAudioFeatures', 144),\n",
       " ('extractAudioFeatures_NoPooling', 144),\n",
       " ('get_device_of', 144),\n",
       " ('get_lengths_from_binary_sequence_mask', 144),\n",
       " ('get_mask_from_sequence_lengths', 144),\n",
       " ('get_text_field_mask', 144),\n",
       " ('masked_softmax', 144),\n",
       " ('pred_str', 144),\n",
       " ('read_dataset_schema', 144),\n",
       " ('sanitize', 144),\n",
       " ('sentence_bleu', 144),\n",
       " ('sequence_cross_entropy_with_logits', 144),\n",
       " ('signature', 144),\n",
       " ('tensors_equal', 144),\n",
       " ('weighted_sum', 144),\n",
       " ('gold_fname', 126),\n",
       " ('pred_c', 115),\n",
       " ('original_dev_fname', 109),\n",
       " ('curr_golds', 104),\n",
       " ('g', 104),\n",
       " ('gold_scores', 104),\n",
       " ('p', 104),\n",
       " ('pred_scores', 104),\n",
       " ('gold_str', 97),\n",
       " ('F', 88),\n",
       " ('ShortTermFeatures', 88),\n",
       " ('audioBasicIO', 88),\n",
       " ('evaluation', 88),\n",
       " ('np', 88),\n",
       " ('optim', 88),\n",
       " ('process_sql', 88),\n",
       " ('Optional', 80),\n",
       " ('predict_fname', 76),\n",
       " ('curr_preds', 72),\n",
       " ('Dict', 64),\n",
       " ('Iterator', 64),\n",
       " ('JsonDict', 64),\n",
       " ('List', 64),\n",
       " ('VERSION', 56),\n",
       " ('db', 55),\n",
       " ('expect_corr', 32),\n",
       " ('expect_score_sum', 32),\n",
       " ('gold_max', 32),\n",
       " ('gold_score_sum', 32),\n",
       " ('pred_c_id', 32),\n",
       " ('pred_max_id', 32),\n",
       " ('first_corr', 28),\n",
       " ('i', 28),\n",
       " ('model_corr', 28),\n",
       " ('o_id', 28),\n",
       " ('p_id', 28),\n",
       " ('first_score_sum', 24),\n",
       " ('model_score_sum', 24)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 891.11 MiB, increment: 0.40 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
