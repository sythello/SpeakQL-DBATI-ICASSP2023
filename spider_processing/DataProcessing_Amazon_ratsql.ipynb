{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import os, sys\n",
    "import json\n",
    "import sqlite3\n",
    "import traceback\n",
    "import argparse\n",
    "import string\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from spider.process_sql import tokenize, get_schema, get_tables_with_alias, Schema, get_sql\n",
    "from spider import process_sql, evaluation\n",
    "from SpeakQL.Allennlp_models.utils import misc_utils\n",
    "from SpeakQL.Allennlp_models.utils.misc_utils import EvaluateSQL, EvaluateSQL_full, EditDistance\n",
    "\n",
    "import numpy as np\n",
    "from copy import copy, deepcopy\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(process_sql)\n",
    "importlib.reload(evaluation)\n",
    "importlib.reload(misc_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db = 'concert_singer'\n",
    "g_str = \"SELECT count(*) FROM singer WHERE singer.name = 'Joe Sharp'\"\n",
    "p_str = \"SELECT Count(*) FROM singer WHERE singer.Name = 'terminal'\"\n",
    "\n",
    "db, p_str, g_str, EvaluateSQL(p_str, g_str, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index_dev_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/index_dev.txt'\n",
    "split_index_test_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/index_test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect questions (input to Polly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/train.json'\n",
    "dev_json_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/dev.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_json_path, 'r') as f:\n",
    "    train_dataset = json.load(f)\n",
    "with open(dev_json_path, 'r') as f:\n",
    "    dev_dataset = json.load(f)\n",
    "\n",
    "len(train_dataset), len(dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: +train_others.json?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev/test split\n",
    "- Create an index file for official dev set, showing which samples are in dev/test\n",
    "- Do not rerun, since we want to keep the split the same across methods so as to compare fairly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect & split databases \n",
    "official_dev_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/dev.json'\n",
    "with open(official_dev_path, 'r') as f:\n",
    "    offc_dev_dataset = json.load(f)\n",
    "\n",
    "offc_dev_dbs = Counter([d['db_id'] for d in offc_dev_dataset])\n",
    "offc_dev_dbs.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakql_dev_dbs = []\n",
    "speakql_test_dbs = []\n",
    "\n",
    "for i, pair in enumerate(offc_dev_dbs.most_common()):\n",
    "    db_id, cnt = pair\n",
    "    if i % 2 == 1:\n",
    "        speakql_dev_dbs.append(db_id)\n",
    "    else:\n",
    "        speakql_test_dbs.append(db_id)\n",
    "\n",
    "speakql_dev_dbs, speakql_test_dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakql_dev_ids = []\n",
    "speakql_test_ids = []\n",
    "\n",
    "for i, d in enumerate(offc_dev_dataset):\n",
    "    if d['db_id'] in speakql_dev_dbs:\n",
    "        speakql_dev_ids.append(i)\n",
    "    else:\n",
    "        speakql_test_ids.append(i)\n",
    "\n",
    "len(speakql_dev_ids), len(speakql_test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to (over)write these results \n",
    "\n",
    "# with open(split_index_dev_path, 'w') as f:\n",
    "#     for i in speakql_dev_ids:\n",
    "#         f.write('{}\\n'.format(i))\n",
    "\n",
    "# with open(split_index_test_path, 'w') as f:\n",
    "#     for i in speakql_test_ids:\n",
    "#         f.write('{}\\n'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build NLIDB input\n",
    "- Did not modify from IRNet code; the purpose of this part is to generate '{train|dev}_asr_amazon.json', which are dataset files with transcriptions.\n",
    "- The only difference: IRNet needs to skip certain instances, here we don't need to skip\n",
    "- As long as 'train/dev_asr_amazon.json' already exists, we don't have to run this again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'train'\n",
    "\n",
    "dataset_train_json_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/train_spider.json'\n",
    "dataset_dev_json_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/dev.json'\n",
    "dataset_json_path = dataset_train_json_path if DATASET == 'train' else dataset_dev_json_path\n",
    "\n",
    "trans_dir = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/{0}/spider-{0}-batch0/'.format(DATASET)\n",
    "\n",
    "dataset_asr_json_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/{0}/{0}_asr_amazon.json'.format(DATASET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for human test \n",
    "\n",
    "# DATASET = 'human-test-yshao'\n",
    "\n",
    "# dataset_json_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/human_test/human_test.json'\n",
    "\n",
    "# trans_dir = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/human_test/speech/yshao_asr'\n",
    "\n",
    "# dataset_asr_json_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/human_test/human_test_yshao_asr_amazon.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_json_path, 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_asr = []\n",
    "\n",
    "for i, d in tqdm(enumerate(dataset)):\n",
    "    # trans_json_fname = os.path.join(trans_dir, 'Transcription-{}-batch0-{}.wav.json'.format(DATASET, i))\n",
    "    trans_json_fname = os.path.join(trans_dir, 'Transcription-{}-{}.wav.json'.format(DATASET, i))\n",
    "    \n",
    "    trans = json.load(open(trans_json_fname, 'r'))\n",
    "    for alter in trans['results']['segments'][0]['alternatives']:\n",
    "        tokens = []\n",
    "        span_ranges = []\n",
    "        for item in alter['items']:\n",
    "            token = item['content']\n",
    "            if item['type'] == 'punctuation':\n",
    "                st = ed = 0\n",
    "            else:\n",
    "                st = item['start_time']\n",
    "                ed = item['end_time']\n",
    "            tokens.append(token)\n",
    "            span_ranges.append((st, ed))\n",
    "\n",
    "        d_asr = deepcopy(d)\n",
    "        d_asr['question'] = alter['transcript']\n",
    "        d_asr['question_toks'] = tokens\n",
    "        d_asr['span_ranges'] = span_ranges\n",
    "        d_asr['original_id'] = i\n",
    "        \n",
    "        dataset_asr.append(d_asr)\n",
    "\n",
    "len(dataset_asr), dataset_asr[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to (over)write these results \n",
    "\n",
    "# with open(dataset_asr_json_path, 'w') as f:\n",
    "#     json.dump(dataset_asr, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Reranker input\n",
    "- The dataset is a list of list\n",
    "    - Outer list: original samples in Spider\n",
    "    - Inner list: transcription candidates for an original sample\n",
    "- Add evaluated score of ratsql predicted SQL (partial match average)\n",
    "- Group samples by original_id\n",
    "- Split dev/test based on given index files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATASET = 'train' # 'train', 'dev' \n",
    "\n",
    "dataset_in_json_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/{}/{}_asr_amazon_RatsqlPredicted.json'.format(DATASET, DATASET)\n",
    "# gold_path = '/Users/mac/Desktop/syt/Deep-Learning/Repos/IRNet/output/asr_amazon/{}/gold_full.txt'.format(DATASET)\n",
    "# pred_sql_path = '/Users/mac/Desktop/syt/Deep-Learning/Repos/IRNet/output/asr_amazon/{}/output_full.txt'.format(DATASET)\n",
    "\n",
    "original_train_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/train_spider.json'\n",
    "original_dev_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/dev.json'\n",
    "original_dataset_path = original_train_path if DATASET == 'train' else original_dev_path\n",
    "\n",
    "reranker_train_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/train/train_reranker.json'\n",
    "reranker_dev_full_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/dev_reranker(full).json'\n",
    "reranker_dev_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/dev_reranker.json'\n",
    "reranker_test_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/test_reranker.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for human test \n",
    "\n",
    "# DATASET = 'human-test-yshao'\n",
    "\n",
    "# dataset_in_json_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/human_test/human_test_yshao_asr_amazon_RatsqlPredicted.json'\n",
    "\n",
    "# original_dataset_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/human_test/human_test.json'\n",
    "\n",
    "# test_reranker_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/human_test/human_test_yshao_reranker.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_in_json_path, 'r') as f:\n",
    "    dataset_in = json.load(f)\n",
    "# with open(gold_path, 'r') as f:\n",
    "#     gold_list = [l.strip() for l in f.readlines()]\n",
    "# with open(pred_sql_path, 'r') as f:\n",
    "#     pred_sql_list = [l.strip() for l in f.readlines()]\n",
    "\n",
    "with open(original_dataset_path, 'r') as f:\n",
    "    original_samples = json.load(f)\n",
    "    \n",
    "len(dataset_in), len(original_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_in[500].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Construct reranker dataset samples \n",
    "\n",
    "dataset_reranker = defaultdict(list)\n",
    "\n",
    "for i in tqdm(range(len(dataset_in))):\n",
    "\n",
    "    d = deepcopy(dataset_in[i])\n",
    "    o_id = d['original_id']\n",
    "    o_sample = original_samples[o_id]\n",
    "    assert ' '.join(d['query'].split()) == ' '.join(o_sample['query'].split()), \\\n",
    "        '{}:\\n{}\\n{}'.format(i, ' '.join(d['query'].split()), ' '.join(o_sample['query'].split()))\n",
    "    \n",
    "    d['gold_question'] = o_sample['question']\n",
    "    d['gold_question_toks'] = o_sample['question_toks']\n",
    "    \n",
    "    p_str = d['ratsql_pred_sql']\n",
    "    g_str = d['query']\n",
    "    db = d['db_id']\n",
    "    \n",
    "    exact, partial_score = EvaluateSQL(p_str, g_str, db)\n",
    "    d['ratsql_pred_exact'] = exact\n",
    "    d['ratsql_pred_score'] = partial_score\n",
    "    \n",
    "    e_dist, _ = EditDistance(d['question_toks'], d['gold_question_toks'])\n",
    "    d['question_toks_edit_distance'] = int(e_dist)\n",
    "    \n",
    "    dataset_reranker[o_id].append(d)\n",
    "    \n",
    "len(dataset_reranker[80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cand in dataset_reranker[80]:\n",
    "    print('Question (transcription): {}'.format(cand['question']))\n",
    "    print('Question (gold): {}'.format(cand['gold_question']))\n",
    "    print('Gold: {}'.format(cand['query']))\n",
    "    print('Pred: {}'.format(cand['ratsql_pred_sql']))\n",
    "    print('Score: {}'.format(cand['ratsql_pred_score']))\n",
    "    print('Exact: {}'.format(cand['ratsql_pred_exact']))\n",
    "    print('Edit Dist: {}'.format(cand['question_toks_edit_distance']))\n",
    "    print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_reranker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_reranker_list = []\n",
    "\n",
    "N = max(dataset_reranker.keys())\n",
    "for o_id in range(N + 1):\n",
    "    dataset_reranker_list.append(dataset_reranker[o_id])\n",
    "len(dataset_reranker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'train':\n",
    "    with open(reranker_train_path, 'w') as f:\n",
    "        json.dump(dataset_reranker_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'dev':\n",
    "    with open(split_index_dev_path, 'r') as f:\n",
    "        dev_ids = [int(l) for l in f.readlines()]\n",
    "    with open(split_index_test_path, 'r') as f:\n",
    "        test_ids = [int(l) for l in f.readlines()]\n",
    "    \n",
    "    dev_list = [dataset_reranker_list[i] for i in dev_ids]\n",
    "    test_list = [dataset_reranker_list[i] for i in test_ids]\n",
    "    assert len(dev_list) + len(test_list) == len(dataset_reranker_list)\n",
    "    \n",
    "    with open(reranker_dev_path, 'w') as f:\n",
    "        json.dump(dev_list, f, indent=4)\n",
    "    with open(reranker_test_path, 'w') as f:\n",
    "        json.dump(test_list, f, indent=4) \n",
    "    with open(reranker_dev_full_path, 'w') as f:\n",
    "        json.dump(dataset_reranker_list, f, indent=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET.startswith('human-test'):\n",
    "    with open(test_reranker_path, 'w') as f:\n",
    "        json.dump(dataset_reranker_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load samples, write parallel sentences to file \n",
    "\n",
    "DATASET = 'human-test-yshao' # 'train-dev' or 'human-test-*'\n",
    "\n",
    "reranker_train_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/train/train_reranker.json'\n",
    "spider_train_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/train_spider.json'\n",
    "\n",
    "reranker_dev_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/dev_reranker(full).json'\n",
    "spider_dev_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/dev.json'\n",
    "\n",
    "reranker_human_test_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/human_test/human_test_yshao_reranker.json'\n",
    "spider_human_test_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/human_test/human_test.json'\n",
    "\n",
    "parallel_txt_path = 'alignments/human_test/parallel.txt'\n",
    "# parallel_txt_train_path = 'alignments/train_set_only/parallel_train.txt' ## Fully unsupervised aligner, no training and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(reranker_train_path, 'r') as f:\n",
    "    reranker_train_samples = json.load(f)\n",
    "with open(spider_train_path, 'r') as f:\n",
    "    spider_train_samples = json.load(f)\n",
    "with open(reranker_dev_path, 'r') as f:\n",
    "    reranker_dev_samples = json.load(f)\n",
    "with open(spider_dev_path, 'r') as f:\n",
    "    spider_dev_samples = json.load(f)\n",
    "    \n",
    "len(reranker_train_samples), len(spider_train_samples), len(reranker_dev_samples), len(spider_dev_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(reranker_human_test_path, 'r') as f:\n",
    "    reranker_human_test_samples = json.load(f)\n",
    "with open(spider_human_test_path, 'r') as f:\n",
    "    spider_human_test_samples = json.load(f)\n",
    "\n",
    "len(reranker_human_test_samples), len(spider_human_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker_train_samples[0][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_train_samples[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = []\n",
    "for sample, orig_sample in zip(reranker_train_samples, spider_train_samples):\n",
    "    for cand in sample:\n",
    "        src_sen = ' '.join(cand['question_toks'])\n",
    "        tgt_sen = ' '.join(orig_sample['question_toks'])\n",
    "        train_pairs.append((src_sen, tgt_sen))\n",
    "len(train_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_pairs = []\n",
    "for sample, orig_sample in zip(reranker_dev_samples, spider_dev_samples):\n",
    "    for cand in sample:\n",
    "        src_sen = ' '.join(cand['question_toks'])\n",
    "        tgt_sen = ' '.join(orig_sample['question_toks'])\n",
    "        dev_pairs.append((src_sen, tgt_sen))\n",
    "len(dev_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_test_pairs = []\n",
    "for sample, orig_sample in zip(reranker_human_test_samples, spider_human_test_samples):\n",
    "    for cand in sample:\n",
    "        src_sen = ' '.join(cand['question_toks'])\n",
    "        tgt_sen = ' '.join(orig_sample['question_toks'])\n",
    "        human_test_pairs.append((src_sen, tgt_sen))\n",
    "len(human_test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_test_pairs[::100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET.startswith('human-test'):\n",
    "    sentence_pairs = human_test_pairs\n",
    "elif DATASET == 'train-dev':\n",
    "    sentence_pairs = train_pairs + dev_pairs\n",
    "else:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to (over)write these results \n",
    "\n",
    "# with open(parallel_txt_path, 'w') as f:\n",
    "# #     for s, t in train_pairs:\n",
    "# #         f.write(s + ' ||| ' + t + '\\n')\n",
    "# #     for s, t in dev_pairs:\n",
    "# #         f.write(s + ' ||| ' + t + '\\n')\n",
    "\n",
    "#     for s, t in sentence_pairs:\n",
    "#         f.write(s + ' ||| ' + t + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running fast_align and atools, check & load the alignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'human-test-yshao':\n",
    "    alignment_txt_path = 'alignments/human_test_yshao/symmetry.align'\n",
    "elif DATASET == 'train-dev':\n",
    "    alignment_txt_path = 'alignments/symmetry.align'\n",
    "else:\n",
    "    raise\n",
    "\n",
    "with open(alignment_txt_path, 'r') as f:\n",
    "    alignment_lines = f.read().strip().split('\\n')\n",
    "len(alignment_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment_seq_to_dict(seq, src_str, tgt_str):\n",
    "    # Translating an alignment seq (0-0, 1-2, 2-3, ...) into dicts \n",
    "    # Pairs are sorted by src_index \n",
    "    align_items = seq.split(' ')\n",
    "    src_sen = src_str.split(' ')\n",
    "    tgt_sen = tgt_str.split(' ')\n",
    "    \n",
    "    def _span_match(src_span : tuple,\n",
    "                    tgt_span : tuple):\n",
    "        src_span_str = ''.join(src_sen[src_span[0] : src_span[-1] + 1])\n",
    "        tgt_span_str = ''.join(tgt_sen[tgt_span[0] : tgt_span[-1] + 1])\n",
    "        edist, _ = EditDistance(src_span_str, tgt_span_str)\n",
    "        match = max(len(src_span_str), len(tgt_span_str)) - edist\n",
    "        return match\n",
    "    \n",
    "    forward_dict = defaultdict(list)\n",
    "    backward_dict = defaultdict(list)\n",
    "    for align_item in align_items:\n",
    "        i_str, j_str = align_item.split('-')\n",
    "        i = int(i_str)\n",
    "        j = int(j_str)\n",
    "        forward_dict[i].append(j)\n",
    "        backward_dict[j].append(i)\n",
    "    \n",
    "    # Continuous: selecting spans \n",
    "    forward_span_dict = defaultdict(tuple)  # Reconstructed every iteration \n",
    "    backward_span_dict = defaultdict(tuple) # Reconstructed every iteration\n",
    "    forward_dict_2 = copy(forward_dict)     # Maintained over iterations \n",
    "    backward_dict_2 = copy(backward_dict)   # Maintained over iterations \n",
    "\n",
    "#     print('-init-')\n",
    "#     print(forward_dict_2)\n",
    "#     print(backward_dict_2)\n",
    "#     print(forward_span_dict)\n",
    "#     print(backward_span_dict)\n",
    "    \n",
    "    modified = True\n",
    "    \n",
    "    while modified:\n",
    "        modified = False\n",
    "        forward_span_dict.clear()\n",
    "        backward_span_dict.clear()\n",
    "        \n",
    "        for i in range(len(src_sen)):\n",
    "            tgt_ids = forward_dict_2[i]\n",
    "            if len(tgt_ids) == 0:\n",
    "                continue\n",
    "\n",
    "            spans = []\n",
    "            cur_span = []\n",
    "            for j in tgt_ids:\n",
    "                if len(cur_span) == 0:\n",
    "                    cur_span.append(j)\n",
    "                elif j == cur_span[-1] + 1:\n",
    "                    cur_span.append(j)\n",
    "                else:\n",
    "                    spans.append(tuple(cur_span))\n",
    "                    cur_span.clear()\n",
    "                    cur_span.append(j)\n",
    "            if len(cur_span) > 0:\n",
    "                spans.append(tuple(cur_span))\n",
    "                cur_span.clear()\n",
    "                \n",
    "            # Selecting best span \n",
    "            if len(spans) == 1:\n",
    "                best_span = spans[0]\n",
    "            else:\n",
    "                best_span = tuple()\n",
    "                max_match = -np.inf\n",
    "                for span in spans:\n",
    "                    match = _span_match((i,), span)\n",
    "                    if match > max_match:\n",
    "                        best_span = span\n",
    "                        max_match = match\n",
    "\n",
    "            forward_span_dict[i] = best_span\n",
    "            forward_dict_2[i] = list(best_span)\n",
    "            for j in tgt_ids:\n",
    "                if j not in best_span:\n",
    "                    modified = True\n",
    "                    backward_dict_2[j].remove(i)\n",
    "\n",
    "#         print('-1-')\n",
    "#         print(forward_dict_2)\n",
    "#         print(backward_dict_2)\n",
    "#         print(forward_span_dict)\n",
    "#         print(backward_span_dict)\n",
    "\n",
    "        # For backward, use the backward_dict_2 just updated  \n",
    "        for j in range(len(tgt_sen)):\n",
    "            src_ids = backward_dict_2[j]\n",
    "            if len(src_ids) == 0:\n",
    "                continue\n",
    "\n",
    "            spans = []\n",
    "            cur_span = []\n",
    "            for i in src_ids:\n",
    "                if len(cur_span) == 0:\n",
    "                    cur_span.append(i)\n",
    "                elif i == cur_span[-1] + 1:\n",
    "                    cur_span.append(i)\n",
    "                else:\n",
    "                    spans.append(tuple(cur_span))\n",
    "                    cur_span.clear()\n",
    "                    cur_span.append(i)\n",
    "            if len(cur_span) > 0:\n",
    "                spans.append(tuple(cur_span))\n",
    "                cur_span.clear()\n",
    "\n",
    "            # Selecting best span \n",
    "            if len(spans) == 1:\n",
    "                best_span = spans[0]\n",
    "            else:\n",
    "                best_span = tuple()\n",
    "                max_match = -np.inf\n",
    "                for span in spans:\n",
    "                    match = _span_match(span, (j,))\n",
    "                    if match > max_match:\n",
    "                        best_span = span\n",
    "                        max_match = match\n",
    "\n",
    "            backward_span_dict[j] = best_span\n",
    "            backward_dict_2[j] = list(best_span)\n",
    "            for i in src_ids:\n",
    "                if i not in best_span:\n",
    "                    modified = True\n",
    "                    forward_dict_2[i].remove(j)\n",
    "\n",
    "#         print('-2-')\n",
    "#         print(forward_dict_2)\n",
    "#         print(backward_dict_2)\n",
    "#         print(forward_span_dict)\n",
    "#         print(backward_span_dict)\n",
    "    \n",
    "    # Merging overlapping spans \n",
    "    src_spans = [(i,) for i in range(len(src_sen))]   # [i]: span containing i \n",
    "    tgt_spans = [(j,) for j in range(len(tgt_sen))]   # [j]: span containing j \n",
    "    \n",
    "    modified = True\n",
    "    \n",
    "    while modified:\n",
    "        modified = False\n",
    "        for i in range(len(src_sen)):\n",
    "            span = src_spans[i]\n",
    "            span_set = set(span)\n",
    "            for j in forward_dict_2[i]:\n",
    "                for _i in backward_dict_2[j]:\n",
    "                    # merge _i into span with i \n",
    "                    if _i == i or src_spans[_i] == span:\n",
    "                        continue\n",
    "                    span_set.update(src_spans[_i])\n",
    "                    modified = True\n",
    "            \n",
    "            new_span = tuple(sorted(span_set))\n",
    "            if new_span != span:\n",
    "                for _i in new_span:\n",
    "                    src_spans[_i] = new_span\n",
    "                    \n",
    "        for j in range(len(tgt_sen)):\n",
    "            span = tgt_spans[j]\n",
    "            span_set = set(span)\n",
    "            for i in backward_dict_2[j]:\n",
    "                for _j in forward_dict_2[i]:\n",
    "                    # merge _j into span with j \n",
    "                    if _j == j or tgt_spans[_j] == span:\n",
    "                        continue\n",
    "                    span_set.update(tgt_spans[_j])\n",
    "                    modified = True\n",
    "            \n",
    "            new_span = tuple(sorted(span_set))\n",
    "            if new_span != span:\n",
    "                for _j in new_span:\n",
    "                    tgt_spans[_j] = new_span\n",
    "    \n",
    "    # Reconstructing span dict (span to span)\n",
    "    span_dict = defaultdict(tuple)\n",
    "    \n",
    "#     for _, src_span in backward_span_dict.items():\n",
    "#         if len(src_span) == 0:\n",
    "#             continue\n",
    "        \n",
    "#         tgt_span = forward_span_dict[src_span[0]]\n",
    "#         assert len(tgt_span) > 0\n",
    "#         for i in src_span:\n",
    "#             assert forward_span_dict[i] == tgt_span, '{}\\n{}'.format(forward_span_dict, backward_span_dict)\n",
    "        \n",
    "#         span_dict[src_span] = tgt_span\n",
    "\n",
    "    for i in range(len(src_sen)):\n",
    "        if len(forward_dict_2[i]) == 0:\n",
    "            continue\n",
    "            \n",
    "        src_span = src_spans[i]\n",
    "        \n",
    "        if src_spans[i] in span_dict:\n",
    "            continue\n",
    "            \n",
    "        tgt_span = tgt_spans[forward_dict_2[i][0]]\n",
    "        span_dict[src_span] = tgt_span\n",
    "    \n",
    "    # Monotonic \n",
    "    last_src_span = None\n",
    "    for src_span in sorted(span_dict.keys()):\n",
    "        tgt_span = span_dict[src_span]\n",
    "        \n",
    "        if last_src_span is None:\n",
    "            last_src_span = src_span\n",
    "            continue\n",
    "        \n",
    "        last_tgt_span = span_dict[last_src_span]\n",
    "        \n",
    "        if tgt_span[0] > last_tgt_span[-1]:\n",
    "            # no conflict \n",
    "            last_src_span = src_span\n",
    "            continue\n",
    "        \n",
    "        # conflict \n",
    "        match = _span_match(src_span, tgt_span)\n",
    "        last_match = _span_match(last_src_span, last_tgt_span)\n",
    "        \n",
    "        if match > last_match:\n",
    "            del span_dict[last_src_span]\n",
    "            last_src_span = src_span\n",
    "        else:\n",
    "            del span_dict[src_span]\n",
    "    \n",
    "    # N-gram pairs \n",
    "    pairs = []\n",
    "    for src_span, tgt_span in sorted(span_dict.items()):\n",
    "        src_str = ' '.join(src_sen[src_span[0] : src_span[-1] + 1])\n",
    "        tgt_str = ' '.join(tgt_sen[tgt_span[0] : tgt_span[-1] + 1])\n",
    "        pairs.append((src_str, tgt_str))\n",
    "    \n",
    "    return span_dict, pairs\n",
    "    \n",
    "    # TODO?: Forcing monotonic and continuous more wisely \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = 180\n",
    "alignment_lines[idx], human_test_pairs[idx][0], human_test_pairs[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alignment_seq_to_dict(alignment_lines[idx], human_test_pairs[idx][0], human_test_pairs[idx][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alignment_results = []\n",
    "\n",
    "for idx in tqdm(range(len(alignment_lines))):\n",
    "    alignment_results.append(alignment_seq_to_dict(alignment_lines[idx], sentence_pairs[idx][0], sentence_pairs[idx][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alignment_results[540]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Rewriter input\n",
    "- Each sample correspond to a sample in original spider dataset; a list of candidates (like in reranker)\n",
    "- Adding: alignment idx pairs, text span pairs, seq tags, list of rewrites (where edits are needed). Each rewrite has a text span, span st/ed idx, target text span, target st/ed idx (<- target info shouldn't be used in test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'train'   # as in original; 'train' for train, 'dev' for dev + test \n",
    "\n",
    "reranker_paths = {\n",
    "    'train': '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/train/train_reranker.json',\n",
    "    'dev': '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/dev_reranker.json',\n",
    "    'test': '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/test_reranker.json',\n",
    "    'dev-full': '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/dev_reranker(full).json'\n",
    "}\n",
    "\n",
    "original_train_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/train_spider.json'\n",
    "original_dev_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/dev.json'\n",
    "\n",
    "rewriter_paths = {\n",
    "    'train': '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/train/train_rewriter.json',\n",
    "    'dev': '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/dev_rewriter.json',\n",
    "    'test': '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/test_rewriter.json',\n",
    "    'dev-full': '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/dev_rewriter(full).json'\n",
    "}\n",
    "\n",
    "split_index_dev_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/index_dev.txt'\n",
    "split_index_test_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/index_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker_path = reranker_paths['train'] if DATASET == 'train' else reranker_paths['dev-full']\n",
    "original_path = original_train_path if DATASET == 'train' else original_dev_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for human test \n",
    "\n",
    "# DATASET = 'human-test-yshao'\n",
    "\n",
    "# reranker_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/human_test/human_test_yshao_reranker.json'\n",
    "\n",
    "# original_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/human_test/human_test.json'\n",
    "\n",
    "# rewriter_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/human_test/human_test_yshao_rewriter.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(reranker_path, 'r') as f:\n",
    "    reranker_samples = json.load(f)\n",
    "with open(original_path, 'r') as f:\n",
    "    original_samples = json.load(f)\n",
    "\n",
    "len(reranker_samples), len(original_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewriter_samples = []\n",
    "\n",
    "if DATASET == 'train':\n",
    "    global_cand_id = 0\n",
    "elif DATASET == 'dev':\n",
    "    global_cand_id = len(train_pairs)\n",
    "else:\n",
    "    # human test \n",
    "    global_cand_id = 0\n",
    "    \n",
    "global_question_pairs = sentence_pairs\n",
    "\n",
    "for reranker_sample, original_sample in zip(reranker_samples, original_samples):\n",
    "    rewriter_sample = copy(reranker_sample)\n",
    "    for cand in rewriter_sample:\n",
    "        assert ' '.join(cand['question_toks']) == global_question_pairs[global_cand_id][0], \\\n",
    "            '{}:\\n{}\\n{}'.format(global_cand_id, cand, global_question_pairs[global_cand_id])\n",
    "        assert ' '.join(cand['gold_question_toks']) == ' '.join(original_sample['question_toks']) == global_question_pairs[global_cand_id][1], \\\n",
    "            '{}:\\n{}\\n{}'.format(global_cand_id, cand, global_question_pairs[global_cand_id])\n",
    "        \n",
    "        # Skip global_cand_id if skipped by IRNet \n",
    "        while (' '.join(cand['question_toks']), ' '.join(cand['gold_question_toks'])) != global_question_pairs[global_cand_id]:\n",
    "            print('='*10, global_cand_id, '='*10)\n",
    "            print(cand['question'], cand['gold_question'])\n",
    "            print(global_question_pairs[global_cand_id])\n",
    "            global_cand_id += 1\n",
    "            if global_cand_id >= len(global_question_pairs):\n",
    "                raise ValueError\n",
    "        \n",
    "        alignment_span_dict, alignment_text_pairs = alignment_results[global_cand_id]\n",
    "        alignment_span_pairs = sorted(alignment_span_dict.items())\n",
    "        cand['alignment_span_pairs'] = alignment_span_pairs\n",
    "        cand['alignment_text_pairs'] = alignment_text_pairs\n",
    "        \n",
    "        tags = []\n",
    "        edits = []\n",
    "        last_src_idx = -1\n",
    "        for span_pair, text_pair in zip(alignment_span_pairs, alignment_text_pairs):\n",
    "            src_span, tgt_span = span_pair\n",
    "            src_span_txt, tgt_span_txt = text_pair\n",
    "            assert src_span[0] > last_src_idx\n",
    "            if src_span[0] > last_src_idx + 1:\n",
    "                del_span_len = src_span[0] - last_src_idx - 1\n",
    "                if del_span_len == 1:\n",
    "                    tags += ['U-DEL']\n",
    "                else:\n",
    "                    tags += ['B-DEL'] + ['I-DEL'] * (del_span_len - 2) + ['L-DEL']\n",
    "            \n",
    "            if text_pair[0].lower() == text_pair[1].lower():\n",
    "                assert len(span_pair[0]) == len(span_pair[1])\n",
    "                tags += ['O-KEEP'] * len(span_pair[0])\n",
    "            else:\n",
    "                # Edit needed \n",
    "                if len(src_span) == 1:\n",
    "                    tags += ['U-EDIT']\n",
    "                else:\n",
    "                    tags += ['B-EDIT'] + ['I-EDIT'] * (len(src_span) - 2) + ['L-EDIT']\n",
    "                edits.append({\n",
    "                    'src_span': src_span,\n",
    "                    'tgt_span': tgt_span,\n",
    "                    'src_text': src_span_txt,\n",
    "                    'tgt_text': tgt_span_txt\n",
    "                })\n",
    "            last_src_idx = src_span[-1]\n",
    "            \n",
    "        del_span_len = len(cand['question_toks']) - last_src_idx - 1\n",
    "        if del_span_len == 0:\n",
    "            pass\n",
    "        elif del_span_len == 1:\n",
    "            tags += ['U-DEL']\n",
    "        else:\n",
    "            tags += ['B-DEL'] + ['I-DEL'] * (del_span_len - 2) + ['L-DEL']\n",
    "        \n",
    "        assert len(tags) == len(cand['question_toks']), \\\n",
    "            '\\n'.join([str(obj) for obj in (tags, cand['question_toks'], cand['gold_question_toks'], \\\n",
    "                                            alignment_text_pairs, alignment_span_pairs, edits)])\n",
    "        cand['rewriter_tags'] = tags\n",
    "        cand['rewriter_edits'] = edits\n",
    "        \n",
    "        global_cand_id += 1\n",
    "    \n",
    "    rewriter_samples.append(rewriter_sample)\n",
    "\n",
    "len(rewriter_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rewriter_samples[5][1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewriter_samples[5][2]['question'], rewriter_samples[5][2]['gold_question'], \\\n",
    "rewriter_samples[5][2]['rewriter_tags'], rewriter_samples[5][2]['rewriter_edits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'train':\n",
    "    with open(rewriter_paths['train'], 'w') as f:\n",
    "        json.dump(rewriter_samples, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'dev':\n",
    "    with open(split_index_dev_path, 'r') as f:\n",
    "        dev_ids = [int(l) for l in f.readlines()]\n",
    "    with open(split_index_test_path, 'r') as f:\n",
    "        test_ids = [int(l) for l in f.readlines()]\n",
    "    \n",
    "    dev_list = [rewriter_samples[i] for i in dev_ids]\n",
    "    test_list = [rewriter_samples[i] for i in test_ids]\n",
    "    assert len(dev_list) + len(test_list) == len(rewriter_samples)\n",
    "    \n",
    "    with open(rewriter_paths['dev'], 'w') as f:\n",
    "        json.dump(dev_list, f, indent=4)\n",
    "    with open(rewriter_paths['test'], 'w') as f:\n",
    "        json.dump(test_list, f, indent=4)\n",
    "    with open(rewriter_paths['dev-full'], 'w') as f:\n",
    "        json.dump(rewriter_samples, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET.startswith('human-test'):\n",
    "    with open(rewriter_path, 'w') as f:\n",
    "        json.dump(rewriter_samples, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for edits \n",
    "for rewriter_sample in rewriter_samples:\n",
    "    for cand in rewriter_sample:\n",
    "        tags = cand['rewriter_tags']\n",
    "        edits = cand['rewriter_edits']\n",
    "        for edit in edits:\n",
    "            if len(edit['tgt_span']) > 1 and 'B-EDIT' in cand['rewriter_tags']:\n",
    "                print(cand['original_id'])\n",
    "                print(cand['question'])\n",
    "                print(cand['gold_question'])\n",
    "                print(cand['rewriter_tags'])\n",
    "                print(cand['rewriter_edits'])\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a 'fake' spider for BRIDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_dir = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider'\n",
    "bridge_train_dir = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/Bridge-train'\n",
    "bridge_infer_dir = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/Bridge-infer'\n",
    "bridge_infer_asr_dir = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/Bridge-asr-infer'\n",
    "dev_index_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/index_dev.txt'\n",
    "test_index_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/index_test.txt'\n",
    "\n",
    "## Train (orig) dir: train = train, original queries; dev = dev split, original queries \n",
    "## Infer (orig) dir: train = empty; dev = test split, original queries \n",
    "## Infer (asr) dir: train = empty; dev = test split, ASR queries (first cands) \n",
    "\n",
    "os.makedirs(bridge_train_dir, exist_ok=True)\n",
    "os.makedirs(bridge_infer_dir, exist_ok=True)\n",
    "os.makedirs(bridge_infer_asr_dir, exist_ok=True)\n",
    "\n",
    "# in_train_json = os.path.join(spider_dir, 'my/train/train_reranker.json')\n",
    "# in_dev_json = os.path.join(spider_dir, 'my/dev/dev_reranker.json')\n",
    "# in_test_json = os.path.join(spider_dir, 'my/dev/test_reranker.json')\n",
    "\n",
    "# out_train_json = os.path.join(bridge_train_dir, 'train.json')\n",
    "# out_dev_json = os.path.join(bridge_train_dir, 'dev.json')\n",
    "# out_test_json = os.path.join(bridge_infer_dir, 'dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(in_train_json, 'r') as f:\n",
    "#     in_train = json.load(f)\n",
    "# with open(in_dev_json, 'r') as f:\n",
    "#     in_dev = json.load(f)\n",
    "# with open(in_test_json, 'r') as f:\n",
    "#     in_test = json.load(f)\n",
    "    \n",
    "# len(in_train), len(in_dev), len(in_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Orig dev/test \n",
    "with open(dev_index_path, 'r') as f:\n",
    "    dev_indices = [int(l) for l in f.read().strip().split('\\n')]\n",
    "with open(test_index_path, 'r') as f:\n",
    "    test_indices = [int(l) for l in f.read().strip().split('\\n')]\n",
    "with open(os.path.join(spider_dir, 'dev.json'), 'r') as f:\n",
    "    orig_dev = json.load(f)\n",
    "print(len(dev_indices), len(test_indices), len(orig_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BRIDGE only reads 'train.json' and 'dev.json'\n",
    "\n",
    "with open(os.path.join(bridge_train_dir, 'dev.json'), 'w') as f:\n",
    "    json.dump([orig_dev[idx] for idx in dev_indices], f, indent=4)\n",
    "    \n",
    "with open(os.path.join(bridge_infer_dir, 'dev.json'), 'w') as f:\n",
    "    json.dump([orig_dev[idx] for idx in test_indices], f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ASR test  \n",
    "# with open(test_index_path, 'r') as f:\n",
    "#     test_indices = [int(l) for l in f.read().strip().split('\\n')]\n",
    "with open(os.path.join(spider_dir, 'my/dev/test_reranker.json'), 'r') as f:\n",
    "    reranker_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(bridge_infer_asr_dir, 'dev.json'), 'w') as f:\n",
    "    json.dump([d[0] for d in reranker_test], f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split according to indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_full_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/dev_rewriter(full)+phonemes.json'\n",
    "dev_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/dev_rewriter+phonemes.json'\n",
    "test_path = '/Users/mac/Desktop/syt/Deep-Learning/Dataset/spider/my/dev/test_rewriter+phonemes.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dev_full_path, 'r') as f:\n",
    "    dev_full_set = json.load(f)\n",
    "\n",
    "with open(split_index_dev_path, 'r') as f:\n",
    "    dev_ids = [int(l) for l in f]\n",
    "with open(split_index_test_path, 'r') as f:\n",
    "    test_ids = [int(l) for l in f]\n",
    "dev_set = [dev_full_set[i] for i in dev_ids]\n",
    "test_set = [dev_full_set[i] for i in test_ids]\n",
    "assert len(dev_full_set) == len(dev_set) + len(test_set), (len(dev_full_set), len(dev_set), len(test_set))\n",
    "\n",
    "with open(dev_path, 'w') as f:\n",
    "    json.dump(dev_set, f, indent=2)\n",
    "with open(test_path, 'w') as f:\n",
    "    json.dump(test_set, f, indent=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "222px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
